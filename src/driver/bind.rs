/* automatically generated by rust-bindgen */

pub const _FEATURES_H: u32 = 1;
pub const _DEFAULT_SOURCE: u32 = 1;
pub const __USE_ISOC11: u32 = 1;
pub const __USE_ISOC99: u32 = 1;
pub const __USE_ISOC95: u32 = 1;
pub const __USE_POSIX_IMPLICITLY: u32 = 1;
pub const _POSIX_SOURCE: u32 = 1;
pub const _POSIX_C_SOURCE: u32 = 200809;
pub const __USE_POSIX: u32 = 1;
pub const __USE_POSIX2: u32 = 1;
pub const __USE_POSIX199309: u32 = 1;
pub const __USE_POSIX199506: u32 = 1;
pub const __USE_XOPEN2K: u32 = 1;
pub const __USE_XOPEN2K8: u32 = 1;
pub const _ATFILE_SOURCE: u32 = 1;
pub const __USE_MISC: u32 = 1;
pub const __USE_ATFILE: u32 = 1;
pub const __USE_FORTIFY_LEVEL: u32 = 0;
pub const __GLIBC_USE_DEPRECATED_GETS: u32 = 0;
pub const _STDC_PREDEF_H: u32 = 1;
pub const __STDC_IEC_559__: u32 = 1;
pub const __STDC_IEC_559_COMPLEX__: u32 = 1;
pub const __STDC_ISO_10646__: u32 = 201706;
pub const __GNU_LIBRARY__: u32 = 6;
pub const __GLIBC__: u32 = 2;
pub const __GLIBC_MINOR__: u32 = 28;
pub const _SYS_CDEFS_H: u32 = 1;
pub const __glibc_c99_flexarr_available: u32 = 1;
pub const __WORDSIZE: u32 = 64;
pub const __WORDSIZE_TIME64_COMPAT32: u32 = 1;
pub const __SYSCALL_WORDSIZE: u32 = 64;
pub const __HAVE_GENERIC_SELECTION: u32 = 1;
pub const __GLIBC_USE_LIB_EXT2: u32 = 0;
pub const __GLIBC_USE_IEC_60559_BFP_EXT: u32 = 0;
pub const __GLIBC_USE_IEC_60559_FUNCS_EXT: u32 = 0;
pub const __GLIBC_USE_IEC_60559_TYPES_EXT: u32 = 0;
pub const _STDLIB_H: u32 = 1;
pub const WNOHANG: u32 = 1;
pub const WUNTRACED: u32 = 2;
pub const WSTOPPED: u32 = 2;
pub const WEXITED: u32 = 4;
pub const WCONTINUED: u32 = 8;
pub const WNOWAIT: u32 = 16777216;
pub const __WNOTHREAD: u32 = 536870912;
pub const __WALL: u32 = 1073741824;
pub const __WCLONE: u32 = 2147483648;
pub const __W_CONTINUED: u32 = 65535;
pub const __WCOREFLAG: u32 = 128;
pub const __HAVE_FLOAT128: u32 = 0;
pub const __HAVE_DISTINCT_FLOAT128: u32 = 0;
pub const __HAVE_FLOAT64X: u32 = 1;
pub const __HAVE_FLOAT64X_LONG_DOUBLE: u32 = 1;
pub const __HAVE_FLOAT16: u32 = 0;
pub const __HAVE_FLOAT32: u32 = 1;
pub const __HAVE_FLOAT64: u32 = 1;
pub const __HAVE_FLOAT32X: u32 = 1;
pub const __HAVE_FLOAT128X: u32 = 0;
pub const __HAVE_DISTINCT_FLOAT16: u32 = 0;
pub const __HAVE_DISTINCT_FLOAT32: u32 = 0;
pub const __HAVE_DISTINCT_FLOAT64: u32 = 0;
pub const __HAVE_DISTINCT_FLOAT32X: u32 = 0;
pub const __HAVE_DISTINCT_FLOAT64X: u32 = 0;
pub const __HAVE_DISTINCT_FLOAT128X: u32 = 0;
pub const __HAVE_FLOATN_NOT_TYPEDEF: u32 = 0;
pub const __ldiv_t_defined: u32 = 1;
pub const __lldiv_t_defined: u32 = 1;
pub const RAND_MAX: u32 = 2147483647;
pub const EXIT_FAILURE: u32 = 1;
pub const EXIT_SUCCESS: u32 = 0;
pub const _SYS_TYPES_H: u32 = 1;
pub const _BITS_TYPES_H: u32 = 1;
pub const _BITS_TYPESIZES_H: u32 = 1;
pub const __OFF_T_MATCHES_OFF64_T: u32 = 1;
pub const __INO_T_MATCHES_INO64_T: u32 = 1;
pub const __RLIM_T_MATCHES_RLIM64_T: u32 = 1;
pub const __FD_SETSIZE: u32 = 1024;
pub const __clock_t_defined: u32 = 1;
pub const __clockid_t_defined: u32 = 1;
pub const __time_t_defined: u32 = 1;
pub const __timer_t_defined: u32 = 1;
pub const _BITS_STDINT_INTN_H: u32 = 1;
pub const __BIT_TYPES_DEFINED__: u32 = 1;
pub const _ENDIAN_H: u32 = 1;
pub const __LITTLE_ENDIAN: u32 = 1234;
pub const __BIG_ENDIAN: u32 = 4321;
pub const __PDP_ENDIAN: u32 = 3412;
pub const __BYTE_ORDER: u32 = 1234;
pub const __FLOAT_WORD_ORDER: u32 = 1234;
pub const LITTLE_ENDIAN: u32 = 1234;
pub const BIG_ENDIAN: u32 = 4321;
pub const PDP_ENDIAN: u32 = 3412;
pub const BYTE_ORDER: u32 = 1234;
pub const _BITS_BYTESWAP_H: u32 = 1;
pub const _BITS_UINTN_IDENTITY_H: u32 = 1;
pub const _SYS_SELECT_H: u32 = 1;
pub const __FD_ZERO_STOS: &'static [u8; 6usize] = b"stosq\0";
pub const __sigset_t_defined: u32 = 1;
pub const __timeval_defined: u32 = 1;
pub const _STRUCT_TIMESPEC: u32 = 1;
pub const FD_SETSIZE: u32 = 1024;
pub const _BITS_PTHREADTYPES_COMMON_H: u32 = 1;
pub const _THREAD_SHARED_TYPES_H: u32 = 1;
pub const _BITS_PTHREADTYPES_ARCH_H: u32 = 1;
pub const __SIZEOF_PTHREAD_MUTEX_T: u32 = 40;
pub const __SIZEOF_PTHREAD_ATTR_T: u32 = 56;
pub const __SIZEOF_PTHREAD_RWLOCK_T: u32 = 56;
pub const __SIZEOF_PTHREAD_BARRIER_T: u32 = 32;
pub const __SIZEOF_PTHREAD_MUTEXATTR_T: u32 = 4;
pub const __SIZEOF_PTHREAD_COND_T: u32 = 48;
pub const __SIZEOF_PTHREAD_CONDATTR_T: u32 = 4;
pub const __SIZEOF_PTHREAD_RWLOCKATTR_T: u32 = 8;
pub const __SIZEOF_PTHREAD_BARRIERATTR_T: u32 = 4;
pub const __PTHREAD_MUTEX_LOCK_ELISION: u32 = 1;
pub const __PTHREAD_MUTEX_NUSERS_AFTER_KIND: u32 = 0;
pub const __PTHREAD_MUTEX_USE_UNION: u32 = 0;
pub const __PTHREAD_RWLOCK_INT_FLAGS_SHARED: u32 = 1;
pub const __PTHREAD_MUTEX_HAVE_PREV: u32 = 1;
pub const __have_pthread_attr_t: u32 = 1;
pub const _ALLOCA_H: u32 = 1;
pub const _STDINT_H: u32 = 1;
pub const _BITS_WCHAR_H: u32 = 1;
pub const _BITS_STDINT_UINTN_H: u32 = 1;
pub const INT8_MIN: i32 = -128;
pub const INT16_MIN: i32 = -32768;
pub const INT32_MIN: i32 = -2147483648;
pub const INT8_MAX: u32 = 127;
pub const INT16_MAX: u32 = 32767;
pub const INT32_MAX: u32 = 2147483647;
pub const UINT8_MAX: u32 = 255;
pub const UINT16_MAX: u32 = 65535;
pub const UINT32_MAX: u32 = 4294967295;
pub const INT_LEAST8_MIN: i32 = -128;
pub const INT_LEAST16_MIN: i32 = -32768;
pub const INT_LEAST32_MIN: i32 = -2147483648;
pub const INT_LEAST8_MAX: u32 = 127;
pub const INT_LEAST16_MAX: u32 = 32767;
pub const INT_LEAST32_MAX: u32 = 2147483647;
pub const UINT_LEAST8_MAX: u32 = 255;
pub const UINT_LEAST16_MAX: u32 = 65535;
pub const UINT_LEAST32_MAX: u32 = 4294967295;
pub const INT_FAST8_MIN: i32 = -128;
pub const INT_FAST16_MIN: i64 = -9223372036854775808;
pub const INT_FAST32_MIN: i64 = -9223372036854775808;
pub const INT_FAST8_MAX: u32 = 127;
pub const INT_FAST16_MAX: u64 = 9223372036854775807;
pub const INT_FAST32_MAX: u64 = 9223372036854775807;
pub const UINT_FAST8_MAX: u32 = 255;
pub const UINT_FAST16_MAX: i32 = -1;
pub const UINT_FAST32_MAX: i32 = -1;
pub const INTPTR_MIN: i64 = -9223372036854775808;
pub const INTPTR_MAX: u64 = 9223372036854775807;
pub const UINTPTR_MAX: i32 = -1;
pub const PTRDIFF_MIN: i64 = -9223372036854775808;
pub const PTRDIFF_MAX: u64 = 9223372036854775807;
pub const SIG_ATOMIC_MIN: i32 = -2147483648;
pub const SIG_ATOMIC_MAX: u32 = 2147483647;
pub const SIZE_MAX: i32 = -1;
pub const WINT_MIN: u32 = 0;
pub const WINT_MAX: u32 = 4294967295;
pub const __CUDA_API_VERSION: u32 = 10000;
pub const CUDA_VERSION: u32 = 10000;
pub const CU_IPC_HANDLE_SIZE: u32 = 64;
pub const CU_MEMHOSTALLOC_PORTABLE: u32 = 1;
pub const CU_MEMHOSTALLOC_DEVICEMAP: u32 = 2;
pub const CU_MEMHOSTALLOC_WRITECOMBINED: u32 = 4;
pub const CU_MEMHOSTREGISTER_PORTABLE: u32 = 1;
pub const CU_MEMHOSTREGISTER_DEVICEMAP: u32 = 2;
pub const CU_MEMHOSTREGISTER_IOMEMORY: u32 = 4;
pub const CUDA_EXTERNAL_MEMORY_DEDICATED: u32 = 1;
pub const CUDA_COOPERATIVE_LAUNCH_MULTI_DEVICE_NO_PRE_LAUNCH_SYNC: u32 = 1;
pub const CUDA_COOPERATIVE_LAUNCH_MULTI_DEVICE_NO_POST_LAUNCH_SYNC: u32 = 2;
pub const CUDA_ARRAY3D_LAYERED: u32 = 1;
pub const CUDA_ARRAY3D_2DARRAY: u32 = 1;
pub const CUDA_ARRAY3D_SURFACE_LDST: u32 = 2;
pub const CUDA_ARRAY3D_CUBEMAP: u32 = 4;
pub const CUDA_ARRAY3D_TEXTURE_GATHER: u32 = 8;
pub const CUDA_ARRAY3D_DEPTH_TEXTURE: u32 = 16;
pub const CUDA_ARRAY3D_COLOR_ATTACHMENT: u32 = 32;
pub const CU_TRSA_OVERRIDE_FORMAT: u32 = 1;
pub const CU_TRSF_READ_AS_INTEGER: u32 = 1;
pub const CU_TRSF_NORMALIZED_COORDINATES: u32 = 2;
pub const CU_TRSF_SRGB: u32 = 16;
pub const CU_PARAM_TR_DEFAULT: i32 = -1;
pub type wchar_t = ::std::os::raw::c_int;
pub type _Float32 = f32;
pub type _Float64 = f64;
pub type _Float32x = f64;
pub type _Float64x = f64;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct div_t {
    pub quot: ::std::os::raw::c_int,
    pub rem: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout_div_t() {
    assert_eq!(
        ::std::mem::size_of::<div_t>(),
        8usize,
        concat!("Size of: ", stringify!(div_t))
    );
    assert_eq!(
        ::std::mem::align_of::<div_t>(),
        4usize,
        concat!("Alignment of ", stringify!(div_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<div_t>())).quot as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(div_t),
            "::",
            stringify!(quot)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<div_t>())).rem as *const _ as usize },
        4usize,
        concat!(
            "Offset of field: ",
            stringify!(div_t),
            "::",
            stringify!(rem)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct ldiv_t {
    pub quot: ::std::os::raw::c_long,
    pub rem: ::std::os::raw::c_long,
}
#[test]
fn bindgen_test_layout_ldiv_t() {
    assert_eq!(
        ::std::mem::size_of::<ldiv_t>(),
        16usize,
        concat!("Size of: ", stringify!(ldiv_t))
    );
    assert_eq!(
        ::std::mem::align_of::<ldiv_t>(),
        8usize,
        concat!("Alignment of ", stringify!(ldiv_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<ldiv_t>())).quot as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(ldiv_t),
            "::",
            stringify!(quot)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<ldiv_t>())).rem as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(ldiv_t),
            "::",
            stringify!(rem)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct lldiv_t {
    pub quot: ::std::os::raw::c_longlong,
    pub rem: ::std::os::raw::c_longlong,
}
#[test]
fn bindgen_test_layout_lldiv_t() {
    assert_eq!(
        ::std::mem::size_of::<lldiv_t>(),
        16usize,
        concat!("Size of: ", stringify!(lldiv_t))
    );
    assert_eq!(
        ::std::mem::align_of::<lldiv_t>(),
        8usize,
        concat!("Alignment of ", stringify!(lldiv_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<lldiv_t>())).quot as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(lldiv_t),
            "::",
            stringify!(quot)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<lldiv_t>())).rem as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(lldiv_t),
            "::",
            stringify!(rem)
        )
    );
}
extern "C" {
    pub fn __ctype_get_mb_cur_max() -> usize;
}
extern "C" {
    pub fn atof(__nptr: *const ::std::os::raw::c_char) -> f64;
}
extern "C" {
    pub fn atoi(__nptr: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn atol(__nptr: *const ::std::os::raw::c_char) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn atoll(__nptr: *const ::std::os::raw::c_char) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn strtod(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
    ) -> f64;
}
extern "C" {
    pub fn strtof(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
    ) -> f32;
}
extern "C" {
    pub fn strtold(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
    ) -> f64;
}
extern "C" {
    pub fn strtol(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
        __base: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn strtoul(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
        __base: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strtoq(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
        __base: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn strtouq(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
        __base: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_ulonglong;
}
extern "C" {
    pub fn strtoll(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
        __base: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn strtoull(
        __nptr: *const ::std::os::raw::c_char,
        __endptr: *mut *mut ::std::os::raw::c_char,
        __base: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_ulonglong;
}
extern "C" {
    pub fn l64a(__n: ::std::os::raw::c_long) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn a64l(__s: *const ::std::os::raw::c_char) -> ::std::os::raw::c_long;
}
pub type __u_char = ::std::os::raw::c_uchar;
pub type __u_short = ::std::os::raw::c_ushort;
pub type __u_int = ::std::os::raw::c_uint;
pub type __u_long = ::std::os::raw::c_ulong;
pub type __int8_t = ::std::os::raw::c_schar;
pub type __uint8_t = ::std::os::raw::c_uchar;
pub type __int16_t = ::std::os::raw::c_short;
pub type __uint16_t = ::std::os::raw::c_ushort;
pub type __int32_t = ::std::os::raw::c_int;
pub type __uint32_t = ::std::os::raw::c_uint;
pub type __int64_t = ::std::os::raw::c_long;
pub type __uint64_t = ::std::os::raw::c_ulong;
pub type __int_least8_t = __int8_t;
pub type __uint_least8_t = __uint8_t;
pub type __int_least16_t = __int16_t;
pub type __uint_least16_t = __uint16_t;
pub type __int_least32_t = __int32_t;
pub type __uint_least32_t = __uint32_t;
pub type __int_least64_t = __int64_t;
pub type __uint_least64_t = __uint64_t;
pub type __quad_t = ::std::os::raw::c_long;
pub type __u_quad_t = ::std::os::raw::c_ulong;
pub type __intmax_t = ::std::os::raw::c_long;
pub type __uintmax_t = ::std::os::raw::c_ulong;
pub type __dev_t = ::std::os::raw::c_ulong;
pub type __uid_t = ::std::os::raw::c_uint;
pub type __gid_t = ::std::os::raw::c_uint;
pub type __ino_t = ::std::os::raw::c_ulong;
pub type __ino64_t = ::std::os::raw::c_ulong;
pub type __mode_t = ::std::os::raw::c_uint;
pub type __nlink_t = ::std::os::raw::c_ulong;
pub type __off_t = ::std::os::raw::c_long;
pub type __off64_t = ::std::os::raw::c_long;
pub type __pid_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __fsid_t {
    pub __val: [::std::os::raw::c_int; 2usize],
}
#[test]
fn bindgen_test_layout___fsid_t() {
    assert_eq!(
        ::std::mem::size_of::<__fsid_t>(),
        8usize,
        concat!("Size of: ", stringify!(__fsid_t))
    );
    assert_eq!(
        ::std::mem::align_of::<__fsid_t>(),
        4usize,
        concat!("Alignment of ", stringify!(__fsid_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__fsid_t>())).__val as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__fsid_t),
            "::",
            stringify!(__val)
        )
    );
}
pub type __clock_t = ::std::os::raw::c_long;
pub type __rlim_t = ::std::os::raw::c_ulong;
pub type __rlim64_t = ::std::os::raw::c_ulong;
pub type __id_t = ::std::os::raw::c_uint;
pub type __time_t = ::std::os::raw::c_long;
pub type __useconds_t = ::std::os::raw::c_uint;
pub type __suseconds_t = ::std::os::raw::c_long;
pub type __daddr_t = ::std::os::raw::c_int;
pub type __key_t = ::std::os::raw::c_int;
pub type __clockid_t = ::std::os::raw::c_int;
pub type __timer_t = *mut ::std::os::raw::c_void;
pub type __blksize_t = ::std::os::raw::c_long;
pub type __blkcnt_t = ::std::os::raw::c_long;
pub type __blkcnt64_t = ::std::os::raw::c_long;
pub type __fsblkcnt_t = ::std::os::raw::c_ulong;
pub type __fsblkcnt64_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt64_t = ::std::os::raw::c_ulong;
pub type __fsword_t = ::std::os::raw::c_long;
pub type __ssize_t = ::std::os::raw::c_long;
pub type __syscall_slong_t = ::std::os::raw::c_long;
pub type __syscall_ulong_t = ::std::os::raw::c_ulong;
pub type __loff_t = __off64_t;
pub type __caddr_t = *mut ::std::os::raw::c_char;
pub type __intptr_t = ::std::os::raw::c_long;
pub type __socklen_t = ::std::os::raw::c_uint;
pub type __sig_atomic_t = ::std::os::raw::c_int;
pub type u_char = __u_char;
pub type u_short = __u_short;
pub type u_int = __u_int;
pub type u_long = __u_long;
pub type quad_t = __quad_t;
pub type u_quad_t = __u_quad_t;
pub type fsid_t = __fsid_t;
pub type loff_t = __loff_t;
pub type ino_t = __ino_t;
pub type dev_t = __dev_t;
pub type gid_t = __gid_t;
pub type mode_t = __mode_t;
pub type nlink_t = __nlink_t;
pub type uid_t = __uid_t;
pub type off_t = __off_t;
pub type pid_t = __pid_t;
pub type id_t = __id_t;
pub type daddr_t = __daddr_t;
pub type caddr_t = __caddr_t;
pub type key_t = __key_t;
pub type clock_t = __clock_t;
pub type clockid_t = __clockid_t;
pub type time_t = __time_t;
pub type timer_t = __timer_t;
pub type ulong = ::std::os::raw::c_ulong;
pub type ushort = ::std::os::raw::c_ushort;
pub type uint = ::std::os::raw::c_uint;
pub type u_int8_t = ::std::os::raw::c_uchar;
pub type u_int16_t = ::std::os::raw::c_ushort;
pub type u_int32_t = ::std::os::raw::c_uint;
pub type u_int64_t = ::std::os::raw::c_ulong;
pub type register_t = ::std::os::raw::c_long;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __sigset_t {
    pub __val: [::std::os::raw::c_ulong; 16usize],
}
#[test]
fn bindgen_test_layout___sigset_t() {
    assert_eq!(
        ::std::mem::size_of::<__sigset_t>(),
        128usize,
        concat!("Size of: ", stringify!(__sigset_t))
    );
    assert_eq!(
        ::std::mem::align_of::<__sigset_t>(),
        8usize,
        concat!("Alignment of ", stringify!(__sigset_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__sigset_t>())).__val as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__sigset_t),
            "::",
            stringify!(__val)
        )
    );
}
pub type sigset_t = __sigset_t;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct timeval {
    pub tv_sec: __time_t,
    pub tv_usec: __suseconds_t,
}
#[test]
fn bindgen_test_layout_timeval() {
    assert_eq!(
        ::std::mem::size_of::<timeval>(),
        16usize,
        concat!("Size of: ", stringify!(timeval))
    );
    assert_eq!(
        ::std::mem::align_of::<timeval>(),
        8usize,
        concat!("Alignment of ", stringify!(timeval))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<timeval>())).tv_sec as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(timeval),
            "::",
            stringify!(tv_sec)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<timeval>())).tv_usec as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(timeval),
            "::",
            stringify!(tv_usec)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct timespec {
    pub tv_sec: __time_t,
    pub tv_nsec: __syscall_slong_t,
}
#[test]
fn bindgen_test_layout_timespec() {
    assert_eq!(
        ::std::mem::size_of::<timespec>(),
        16usize,
        concat!("Size of: ", stringify!(timespec))
    );
    assert_eq!(
        ::std::mem::align_of::<timespec>(),
        8usize,
        concat!("Alignment of ", stringify!(timespec))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<timespec>())).tv_sec as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(timespec),
            "::",
            stringify!(tv_sec)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<timespec>())).tv_nsec as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(timespec),
            "::",
            stringify!(tv_nsec)
        )
    );
}
pub type suseconds_t = __suseconds_t;
pub type __fd_mask = ::std::os::raw::c_long;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct fd_set {
    pub __fds_bits: [__fd_mask; 16usize],
}
#[test]
fn bindgen_test_layout_fd_set() {
    assert_eq!(
        ::std::mem::size_of::<fd_set>(),
        128usize,
        concat!("Size of: ", stringify!(fd_set))
    );
    assert_eq!(
        ::std::mem::align_of::<fd_set>(),
        8usize,
        concat!("Alignment of ", stringify!(fd_set))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<fd_set>())).__fds_bits as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(fd_set),
            "::",
            stringify!(__fds_bits)
        )
    );
}
pub type fd_mask = __fd_mask;
extern "C" {
    pub fn select(
        __nfds: ::std::os::raw::c_int,
        __readfds: *mut fd_set,
        __writefds: *mut fd_set,
        __exceptfds: *mut fd_set,
        __timeout: *mut timeval,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn pselect(
        __nfds: ::std::os::raw::c_int,
        __readfds: *mut fd_set,
        __writefds: *mut fd_set,
        __exceptfds: *mut fd_set,
        __timeout: *const timespec,
        __sigmask: *const __sigset_t,
    ) -> ::std::os::raw::c_int;
}
pub type blksize_t = __blksize_t;
pub type blkcnt_t = __blkcnt_t;
pub type fsblkcnt_t = __fsblkcnt_t;
pub type fsfilcnt_t = __fsfilcnt_t;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __pthread_rwlock_arch_t {
    pub __readers: ::std::os::raw::c_uint,
    pub __writers: ::std::os::raw::c_uint,
    pub __wrphase_futex: ::std::os::raw::c_uint,
    pub __writers_futex: ::std::os::raw::c_uint,
    pub __pad3: ::std::os::raw::c_uint,
    pub __pad4: ::std::os::raw::c_uint,
    pub __cur_writer: ::std::os::raw::c_int,
    pub __shared: ::std::os::raw::c_int,
    pub __rwelision: ::std::os::raw::c_schar,
    pub __pad1: [::std::os::raw::c_uchar; 7usize],
    pub __pad2: ::std::os::raw::c_ulong,
    pub __flags: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout___pthread_rwlock_arch_t() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_rwlock_arch_t>(),
        56usize,
        concat!("Size of: ", stringify!(__pthread_rwlock_arch_t))
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_rwlock_arch_t>(),
        8usize,
        concat!("Alignment of ", stringify!(__pthread_rwlock_arch_t))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__readers as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__readers)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__writers as *const _ as usize
        },
        4usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__writers)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__wrphase_futex as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__wrphase_futex)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__writers_futex as *const _ as usize
        },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__writers_futex)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__pad3 as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__pad3)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__pad4 as *const _ as usize },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__pad4)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__cur_writer as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__cur_writer)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__shared as *const _ as usize
        },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__shared)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__rwelision as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__rwelision)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__pad1 as *const _ as usize },
        33usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__pad1)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__pad2 as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__pad2)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_rwlock_arch_t>())).__flags as *const _ as usize },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_rwlock_arch_t),
            "::",
            stringify!(__flags)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __pthread_internal_list {
    pub __prev: *mut __pthread_internal_list,
    pub __next: *mut __pthread_internal_list,
}
#[test]
fn bindgen_test_layout___pthread_internal_list() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_internal_list>(),
        16usize,
        concat!("Size of: ", stringify!(__pthread_internal_list))
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_internal_list>(),
        8usize,
        concat!("Alignment of ", stringify!(__pthread_internal_list))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_internal_list>())).__prev as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_internal_list),
            "::",
            stringify!(__prev)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_internal_list>())).__next as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_internal_list),
            "::",
            stringify!(__next)
        )
    );
}
pub type __pthread_list_t = __pthread_internal_list;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __pthread_mutex_s {
    pub __lock: ::std::os::raw::c_int,
    pub __count: ::std::os::raw::c_uint,
    pub __owner: ::std::os::raw::c_int,
    pub __nusers: ::std::os::raw::c_uint,
    pub __kind: ::std::os::raw::c_int,
    pub __spins: ::std::os::raw::c_short,
    pub __elision: ::std::os::raw::c_short,
    pub __list: __pthread_list_t,
}
#[test]
fn bindgen_test_layout___pthread_mutex_s() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_mutex_s>(),
        40usize,
        concat!("Size of: ", stringify!(__pthread_mutex_s))
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_mutex_s>(),
        8usize,
        concat!("Alignment of ", stringify!(__pthread_mutex_s))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__lock as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__lock)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__count as *const _ as usize },
        4usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__count)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__owner as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__owner)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__nusers as *const _ as usize },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__nusers)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__kind as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__kind)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__spins as *const _ as usize },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__spins)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__elision as *const _ as usize },
        22usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__elision)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_mutex_s>())).__list as *const _ as usize },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_mutex_s),
            "::",
            stringify!(__list)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct __pthread_cond_s {
    pub __bindgen_anon_1: __pthread_cond_s__bindgen_ty_1,
    pub __bindgen_anon_2: __pthread_cond_s__bindgen_ty_2,
    pub __g_refs: [::std::os::raw::c_uint; 2usize],
    pub __g_size: [::std::os::raw::c_uint; 2usize],
    pub __g1_orig_size: ::std::os::raw::c_uint,
    pub __wrefs: ::std::os::raw::c_uint,
    pub __g_signals: [::std::os::raw::c_uint; 2usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union __pthread_cond_s__bindgen_ty_1 {
    pub __wseq: ::std::os::raw::c_ulonglong,
    pub __wseq32: __pthread_cond_s__bindgen_ty_1__bindgen_ty_1,
    _bindgen_union_align: u64,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __pthread_cond_s__bindgen_ty_1__bindgen_ty_1 {
    pub __low: ::std::os::raw::c_uint,
    pub __high: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout___pthread_cond_s__bindgen_ty_1__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_cond_s__bindgen_ty_1__bindgen_ty_1>(),
        8usize,
        concat!(
            "Size of: ",
            stringify!(__pthread_cond_s__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_cond_s__bindgen_ty_1__bindgen_ty_1>(),
        4usize,
        concat!(
            "Alignment of ",
            stringify!(__pthread_cond_s__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_1__bindgen_ty_1>())).__low
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(__low)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_1__bindgen_ty_1>())).__high
                as *const _ as usize
        },
        4usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(__high)
        )
    );
}
#[test]
fn bindgen_test_layout___pthread_cond_s__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_cond_s__bindgen_ty_1>(),
        8usize,
        concat!("Size of: ", stringify!(__pthread_cond_s__bindgen_ty_1))
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_cond_s__bindgen_ty_1>(),
        8usize,
        concat!("Alignment of ", stringify!(__pthread_cond_s__bindgen_ty_1))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_1>())).__wseq as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_1),
            "::",
            stringify!(__wseq)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_1>())).__wseq32 as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_1),
            "::",
            stringify!(__wseq32)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union __pthread_cond_s__bindgen_ty_2 {
    pub __g1_start: ::std::os::raw::c_ulonglong,
    pub __g1_start32: __pthread_cond_s__bindgen_ty_2__bindgen_ty_1,
    _bindgen_union_align: u64,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __pthread_cond_s__bindgen_ty_2__bindgen_ty_1 {
    pub __low: ::std::os::raw::c_uint,
    pub __high: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout___pthread_cond_s__bindgen_ty_2__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_cond_s__bindgen_ty_2__bindgen_ty_1>(),
        8usize,
        concat!(
            "Size of: ",
            stringify!(__pthread_cond_s__bindgen_ty_2__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_cond_s__bindgen_ty_2__bindgen_ty_1>(),
        4usize,
        concat!(
            "Alignment of ",
            stringify!(__pthread_cond_s__bindgen_ty_2__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_2__bindgen_ty_1>())).__low
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_2__bindgen_ty_1),
            "::",
            stringify!(__low)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_2__bindgen_ty_1>())).__high
                as *const _ as usize
        },
        4usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_2__bindgen_ty_1),
            "::",
            stringify!(__high)
        )
    );
}
#[test]
fn bindgen_test_layout___pthread_cond_s__bindgen_ty_2() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_cond_s__bindgen_ty_2>(),
        8usize,
        concat!("Size of: ", stringify!(__pthread_cond_s__bindgen_ty_2))
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_cond_s__bindgen_ty_2>(),
        8usize,
        concat!("Alignment of ", stringify!(__pthread_cond_s__bindgen_ty_2))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_2>())).__g1_start as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_2),
            "::",
            stringify!(__g1_start)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<__pthread_cond_s__bindgen_ty_2>())).__g1_start32 as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s__bindgen_ty_2),
            "::",
            stringify!(__g1_start32)
        )
    );
}
#[test]
fn bindgen_test_layout___pthread_cond_s() {
    assert_eq!(
        ::std::mem::size_of::<__pthread_cond_s>(),
        48usize,
        concat!("Size of: ", stringify!(__pthread_cond_s))
    );
    assert_eq!(
        ::std::mem::align_of::<__pthread_cond_s>(),
        8usize,
        concat!("Alignment of ", stringify!(__pthread_cond_s))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_cond_s>())).__g_refs as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s),
            "::",
            stringify!(__g_refs)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_cond_s>())).__g_size as *const _ as usize },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s),
            "::",
            stringify!(__g_size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_cond_s>())).__g1_orig_size as *const _ as usize },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s),
            "::",
            stringify!(__g1_orig_size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_cond_s>())).__wrefs as *const _ as usize },
        36usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s),
            "::",
            stringify!(__wrefs)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<__pthread_cond_s>())).__g_signals as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(__pthread_cond_s),
            "::",
            stringify!(__g_signals)
        )
    );
}
pub type pthread_t = ::std::os::raw::c_ulong;
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_mutexattr_t {
    pub __size: [::std::os::raw::c_char; 4usize],
    pub __align: ::std::os::raw::c_int,
    _bindgen_union_align: u32,
}
#[test]
fn bindgen_test_layout_pthread_mutexattr_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_mutexattr_t>(),
        4usize,
        concat!("Size of: ", stringify!(pthread_mutexattr_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_mutexattr_t>(),
        4usize,
        concat!("Alignment of ", stringify!(pthread_mutexattr_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_mutexattr_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_mutexattr_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_mutexattr_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_mutexattr_t),
            "::",
            stringify!(__align)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_condattr_t {
    pub __size: [::std::os::raw::c_char; 4usize],
    pub __align: ::std::os::raw::c_int,
    _bindgen_union_align: u32,
}
#[test]
fn bindgen_test_layout_pthread_condattr_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_condattr_t>(),
        4usize,
        concat!("Size of: ", stringify!(pthread_condattr_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_condattr_t>(),
        4usize,
        concat!("Alignment of ", stringify!(pthread_condattr_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_condattr_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_condattr_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_condattr_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_condattr_t),
            "::",
            stringify!(__align)
        )
    );
}
pub type pthread_key_t = ::std::os::raw::c_uint;
pub type pthread_once_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_attr_t {
    pub __size: [::std::os::raw::c_char; 56usize],
    pub __align: ::std::os::raw::c_long,
    _bindgen_union_align: [u64; 7usize],
}
#[test]
fn bindgen_test_layout_pthread_attr_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_attr_t>(),
        56usize,
        concat!("Size of: ", stringify!(pthread_attr_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_attr_t>(),
        8usize,
        concat!("Alignment of ", stringify!(pthread_attr_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_attr_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_attr_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_attr_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_attr_t),
            "::",
            stringify!(__align)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_mutex_t {
    pub __data: __pthread_mutex_s,
    pub __size: [::std::os::raw::c_char; 40usize],
    pub __align: ::std::os::raw::c_long,
    _bindgen_union_align: [u64; 5usize],
}
#[test]
fn bindgen_test_layout_pthread_mutex_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_mutex_t>(),
        40usize,
        concat!("Size of: ", stringify!(pthread_mutex_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_mutex_t>(),
        8usize,
        concat!("Alignment of ", stringify!(pthread_mutex_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_mutex_t>())).__data as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_mutex_t),
            "::",
            stringify!(__data)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_mutex_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_mutex_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_mutex_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_mutex_t),
            "::",
            stringify!(__align)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_cond_t {
    pub __data: __pthread_cond_s,
    pub __size: [::std::os::raw::c_char; 48usize],
    pub __align: ::std::os::raw::c_longlong,
    _bindgen_union_align: [u64; 6usize],
}
#[test]
fn bindgen_test_layout_pthread_cond_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_cond_t>(),
        48usize,
        concat!("Size of: ", stringify!(pthread_cond_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_cond_t>(),
        8usize,
        concat!("Alignment of ", stringify!(pthread_cond_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_cond_t>())).__data as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_cond_t),
            "::",
            stringify!(__data)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_cond_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_cond_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_cond_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_cond_t),
            "::",
            stringify!(__align)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_rwlock_t {
    pub __data: __pthread_rwlock_arch_t,
    pub __size: [::std::os::raw::c_char; 56usize],
    pub __align: ::std::os::raw::c_long,
    _bindgen_union_align: [u64; 7usize],
}
#[test]
fn bindgen_test_layout_pthread_rwlock_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_rwlock_t>(),
        56usize,
        concat!("Size of: ", stringify!(pthread_rwlock_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_rwlock_t>(),
        8usize,
        concat!("Alignment of ", stringify!(pthread_rwlock_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_rwlock_t>())).__data as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_rwlock_t),
            "::",
            stringify!(__data)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_rwlock_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_rwlock_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_rwlock_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_rwlock_t),
            "::",
            stringify!(__align)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_rwlockattr_t {
    pub __size: [::std::os::raw::c_char; 8usize],
    pub __align: ::std::os::raw::c_long,
    _bindgen_union_align: u64,
}
#[test]
fn bindgen_test_layout_pthread_rwlockattr_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_rwlockattr_t>(),
        8usize,
        concat!("Size of: ", stringify!(pthread_rwlockattr_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_rwlockattr_t>(),
        8usize,
        concat!("Alignment of ", stringify!(pthread_rwlockattr_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_rwlockattr_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_rwlockattr_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_rwlockattr_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_rwlockattr_t),
            "::",
            stringify!(__align)
        )
    );
}
pub type pthread_spinlock_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_barrier_t {
    pub __size: [::std::os::raw::c_char; 32usize],
    pub __align: ::std::os::raw::c_long,
    _bindgen_union_align: [u64; 4usize],
}
#[test]
fn bindgen_test_layout_pthread_barrier_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_barrier_t>(),
        32usize,
        concat!("Size of: ", stringify!(pthread_barrier_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_barrier_t>(),
        8usize,
        concat!("Alignment of ", stringify!(pthread_barrier_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_barrier_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_barrier_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_barrier_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_barrier_t),
            "::",
            stringify!(__align)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union pthread_barrierattr_t {
    pub __size: [::std::os::raw::c_char; 4usize],
    pub __align: ::std::os::raw::c_int,
    _bindgen_union_align: u32,
}
#[test]
fn bindgen_test_layout_pthread_barrierattr_t() {
    assert_eq!(
        ::std::mem::size_of::<pthread_barrierattr_t>(),
        4usize,
        concat!("Size of: ", stringify!(pthread_barrierattr_t))
    );
    assert_eq!(
        ::std::mem::align_of::<pthread_barrierattr_t>(),
        4usize,
        concat!("Alignment of ", stringify!(pthread_barrierattr_t))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_barrierattr_t>())).__size as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_barrierattr_t),
            "::",
            stringify!(__size)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<pthread_barrierattr_t>())).__align as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(pthread_barrierattr_t),
            "::",
            stringify!(__align)
        )
    );
}
extern "C" {
    pub fn random() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn srandom(__seed: ::std::os::raw::c_uint);
}
extern "C" {
    pub fn initstate(
        __seed: ::std::os::raw::c_uint,
        __statebuf: *mut ::std::os::raw::c_char,
        __statelen: usize,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn setstate(__statebuf: *mut ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct random_data {
    pub fptr: *mut i32,
    pub rptr: *mut i32,
    pub state: *mut i32,
    pub rand_type: ::std::os::raw::c_int,
    pub rand_deg: ::std::os::raw::c_int,
    pub rand_sep: ::std::os::raw::c_int,
    pub end_ptr: *mut i32,
}
#[test]
fn bindgen_test_layout_random_data() {
    assert_eq!(
        ::std::mem::size_of::<random_data>(),
        48usize,
        concat!("Size of: ", stringify!(random_data))
    );
    assert_eq!(
        ::std::mem::align_of::<random_data>(),
        8usize,
        concat!("Alignment of ", stringify!(random_data))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<random_data>())).fptr as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(random_data),
            "::",
            stringify!(fptr)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<random_data>())).rptr as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(random_data),
            "::",
            stringify!(rptr)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<random_data>())).state as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(random_data),
            "::",
            stringify!(state)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<random_data>())).rand_type as *const _ as usize },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(random_data),
            "::",
            stringify!(rand_type)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<random_data>())).rand_deg as *const _ as usize },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(random_data),
            "::",
            stringify!(rand_deg)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<random_data>())).rand_sep as *const _ as usize },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(random_data),
            "::",
            stringify!(rand_sep)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<random_data>())).end_ptr as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(random_data),
            "::",
            stringify!(end_ptr)
        )
    );
}
extern "C" {
    pub fn random_r(__buf: *mut random_data, __result: *mut i32) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn srandom_r(
        __seed: ::std::os::raw::c_uint,
        __buf: *mut random_data,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn initstate_r(
        __seed: ::std::os::raw::c_uint,
        __statebuf: *mut ::std::os::raw::c_char,
        __statelen: usize,
        __buf: *mut random_data,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn setstate_r(
        __statebuf: *mut ::std::os::raw::c_char,
        __buf: *mut random_data,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn rand() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn srand(__seed: ::std::os::raw::c_uint);
}
extern "C" {
    pub fn rand_r(__seed: *mut ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn drand48() -> f64;
}
extern "C" {
    pub fn erand48(__xsubi: *mut ::std::os::raw::c_ushort) -> f64;
}
extern "C" {
    pub fn lrand48() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn nrand48(__xsubi: *mut ::std::os::raw::c_ushort) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn mrand48() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn jrand48(__xsubi: *mut ::std::os::raw::c_ushort) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn srand48(__seedval: ::std::os::raw::c_long);
}
extern "C" {
    pub fn seed48(__seed16v: *mut ::std::os::raw::c_ushort) -> *mut ::std::os::raw::c_ushort;
}
extern "C" {
    pub fn lcong48(__param: *mut ::std::os::raw::c_ushort);
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct drand48_data {
    pub __x: [::std::os::raw::c_ushort; 3usize],
    pub __old_x: [::std::os::raw::c_ushort; 3usize],
    pub __c: ::std::os::raw::c_ushort,
    pub __init: ::std::os::raw::c_ushort,
    pub __a: ::std::os::raw::c_ulonglong,
}
#[test]
fn bindgen_test_layout_drand48_data() {
    assert_eq!(
        ::std::mem::size_of::<drand48_data>(),
        24usize,
        concat!("Size of: ", stringify!(drand48_data))
    );
    assert_eq!(
        ::std::mem::align_of::<drand48_data>(),
        8usize,
        concat!("Alignment of ", stringify!(drand48_data))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<drand48_data>())).__x as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(drand48_data),
            "::",
            stringify!(__x)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<drand48_data>())).__old_x as *const _ as usize },
        6usize,
        concat!(
            "Offset of field: ",
            stringify!(drand48_data),
            "::",
            stringify!(__old_x)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<drand48_data>())).__c as *const _ as usize },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(drand48_data),
            "::",
            stringify!(__c)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<drand48_data>())).__init as *const _ as usize },
        14usize,
        concat!(
            "Offset of field: ",
            stringify!(drand48_data),
            "::",
            stringify!(__init)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<drand48_data>())).__a as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(drand48_data),
            "::",
            stringify!(__a)
        )
    );
}
extern "C" {
    pub fn drand48_r(__buffer: *mut drand48_data, __result: *mut f64) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn erand48_r(
        __xsubi: *mut ::std::os::raw::c_ushort,
        __buffer: *mut drand48_data,
        __result: *mut f64,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn lrand48_r(
        __buffer: *mut drand48_data,
        __result: *mut ::std::os::raw::c_long,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn nrand48_r(
        __xsubi: *mut ::std::os::raw::c_ushort,
        __buffer: *mut drand48_data,
        __result: *mut ::std::os::raw::c_long,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mrand48_r(
        __buffer: *mut drand48_data,
        __result: *mut ::std::os::raw::c_long,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn jrand48_r(
        __xsubi: *mut ::std::os::raw::c_ushort,
        __buffer: *mut drand48_data,
        __result: *mut ::std::os::raw::c_long,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn srand48_r(
        __seedval: ::std::os::raw::c_long,
        __buffer: *mut drand48_data,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn seed48_r(
        __seed16v: *mut ::std::os::raw::c_ushort,
        __buffer: *mut drand48_data,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn lcong48_r(
        __param: *mut ::std::os::raw::c_ushort,
        __buffer: *mut drand48_data,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn malloc(__size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn calloc(__nmemb: usize, __size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn realloc(
        __ptr: *mut ::std::os::raw::c_void,
        __size: usize,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn free(__ptr: *mut ::std::os::raw::c_void);
}
extern "C" {
    pub fn alloca(__size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn valloc(__size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn posix_memalign(
        __memptr: *mut *mut ::std::os::raw::c_void,
        __alignment: usize,
        __size: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn aligned_alloc(__alignment: usize, __size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn abort();
}
extern "C" {
    pub fn atexit(__func: ::std::option::Option<unsafe extern "C" fn()>) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn at_quick_exit(
        __func: ::std::option::Option<unsafe extern "C" fn()>,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn on_exit(
        __func: ::std::option::Option<
            unsafe extern "C" fn(
                __status: ::std::os::raw::c_int,
                __arg: *mut ::std::os::raw::c_void,
            ),
        >,
        __arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn exit(__status: ::std::os::raw::c_int);
}
extern "C" {
    pub fn quick_exit(__status: ::std::os::raw::c_int);
}
extern "C" {
    pub fn _Exit(__status: ::std::os::raw::c_int);
}
extern "C" {
    pub fn getenv(__name: *const ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn putenv(__string: *mut ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn setenv(
        __name: *const ::std::os::raw::c_char,
        __value: *const ::std::os::raw::c_char,
        __replace: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn unsetenv(__name: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn clearenv() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mktemp(__template: *mut ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn mkstemp(__template: *mut ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mkstemps(
        __template: *mut ::std::os::raw::c_char,
        __suffixlen: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mkdtemp(__template: *mut ::std::os::raw::c_char) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn system(__command: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn realpath(
        __name: *const ::std::os::raw::c_char,
        __resolved: *mut ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
pub type __compar_fn_t = ::std::option::Option<
    unsafe extern "C" fn(arg1: *const ::std::os::raw::c_void, arg2: *const ::std::os::raw::c_void)
        -> ::std::os::raw::c_int,
>;
extern "C" {
    pub fn bsearch(
        __key: *const ::std::os::raw::c_void,
        __base: *const ::std::os::raw::c_void,
        __nmemb: usize,
        __size: usize,
        __compar: __compar_fn_t,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn qsort(
        __base: *mut ::std::os::raw::c_void,
        __nmemb: usize,
        __size: usize,
        __compar: __compar_fn_t,
    );
}
extern "C" {
    pub fn abs(__x: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn labs(__x: ::std::os::raw::c_long) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn llabs(__x: ::std::os::raw::c_longlong) -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn div(__numer: ::std::os::raw::c_int, __denom: ::std::os::raw::c_int) -> div_t;
}
extern "C" {
    pub fn ldiv(__numer: ::std::os::raw::c_long, __denom: ::std::os::raw::c_long) -> ldiv_t;
}
extern "C" {
    pub fn lldiv(
        __numer: ::std::os::raw::c_longlong,
        __denom: ::std::os::raw::c_longlong,
    ) -> lldiv_t;
}
extern "C" {
    pub fn ecvt(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn fcvt(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn gcvt(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __buf: *mut ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn qecvt(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn qfcvt(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn qgcvt(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __buf: *mut ::std::os::raw::c_char,
    ) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn ecvt_r(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
        __buf: *mut ::std::os::raw::c_char,
        __len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fcvt_r(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
        __buf: *mut ::std::os::raw::c_char,
        __len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn qecvt_r(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
        __buf: *mut ::std::os::raw::c_char,
        __len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn qfcvt_r(
        __value: f64,
        __ndigit: ::std::os::raw::c_int,
        __decpt: *mut ::std::os::raw::c_int,
        __sign: *mut ::std::os::raw::c_int,
        __buf: *mut ::std::os::raw::c_char,
        __len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mblen(__s: *const ::std::os::raw::c_char, __n: usize) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mbtowc(
        __pwc: *mut wchar_t,
        __s: *const ::std::os::raw::c_char,
        __n: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn wctomb(__s: *mut ::std::os::raw::c_char, __wchar: wchar_t) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mbstowcs(__pwcs: *mut wchar_t, __s: *const ::std::os::raw::c_char, __n: usize) -> usize;
}
extern "C" {
    pub fn wcstombs(__s: *mut ::std::os::raw::c_char, __pwcs: *const wchar_t, __n: usize) -> usize;
}
extern "C" {
    pub fn rpmatch(__response: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getsubopt(
        __optionp: *mut *mut ::std::os::raw::c_char,
        __tokens: *const *mut ::std::os::raw::c_char,
        __valuep: *mut *mut ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getloadavg(__loadavg: *mut f64, __nelem: ::std::os::raw::c_int)
        -> ::std::os::raw::c_int;
}
pub type int_least8_t = __int_least8_t;
pub type int_least16_t = __int_least16_t;
pub type int_least32_t = __int_least32_t;
pub type int_least64_t = __int_least64_t;
pub type uint_least8_t = __uint_least8_t;
pub type uint_least16_t = __uint_least16_t;
pub type uint_least32_t = __uint_least32_t;
pub type uint_least64_t = __uint_least64_t;
pub type int_fast8_t = ::std::os::raw::c_schar;
pub type int_fast16_t = ::std::os::raw::c_long;
pub type int_fast32_t = ::std::os::raw::c_long;
pub type int_fast64_t = ::std::os::raw::c_long;
pub type uint_fast8_t = ::std::os::raw::c_uchar;
pub type uint_fast16_t = ::std::os::raw::c_ulong;
pub type uint_fast32_t = ::std::os::raw::c_ulong;
pub type uint_fast64_t = ::std::os::raw::c_ulong;
pub type intmax_t = __intmax_t;
pub type uintmax_t = __uintmax_t;
pub type cuuint32_t = u32;
pub type cuuint64_t = u64;
pub type CUdeviceptr = ::std::os::raw::c_ulonglong;
pub type CUdevice = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUctx_st {
    _unused: [u8; 0],
}
pub type CUcontext = *mut CUctx_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUmod_st {
    _unused: [u8; 0],
}
pub type CUmodule = *mut CUmod_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUfunc_st {
    _unused: [u8; 0],
}
pub type CUfunction = *mut CUfunc_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUarray_st {
    _unused: [u8; 0],
}
pub type CUarray = *mut CUarray_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUmipmappedArray_st {
    _unused: [u8; 0],
}
pub type CUmipmappedArray = *mut CUmipmappedArray_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUtexref_st {
    _unused: [u8; 0],
}
pub type CUtexref = *mut CUtexref_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUsurfref_st {
    _unused: [u8; 0],
}
pub type CUsurfref = *mut CUsurfref_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUevent_st {
    _unused: [u8; 0],
}
pub type CUevent = *mut CUevent_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUstream_st {
    _unused: [u8; 0],
}
pub type CUstream = *mut CUstream_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUgraphicsResource_st {
    _unused: [u8; 0],
}
pub type CUgraphicsResource = *mut CUgraphicsResource_st;
pub type CUtexObject = ::std::os::raw::c_ulonglong;
pub type CUsurfObject = ::std::os::raw::c_ulonglong;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUextMemory_st {
    _unused: [u8; 0],
}
pub type CUexternalMemory = *mut CUextMemory_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUextSemaphore_st {
    _unused: [u8; 0],
}
pub type CUexternalSemaphore = *mut CUextSemaphore_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUgraph_st {
    _unused: [u8; 0],
}
pub type CUgraph = *mut CUgraph_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUgraphNode_st {
    _unused: [u8; 0],
}
pub type CUgraphNode = *mut CUgraphNode_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUgraphExec_st {
    _unused: [u8; 0],
}
pub type CUgraphExec = *mut CUgraphExec_st;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUuuid_st {
    pub bytes: [::std::os::raw::c_char; 16usize],
}
#[test]
fn bindgen_test_layout_CUuuid_st() {
    assert_eq!(
        ::std::mem::size_of::<CUuuid_st>(),
        16usize,
        concat!("Size of: ", stringify!(CUuuid_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUuuid_st>(),
        1usize,
        concat!("Alignment of ", stringify!(CUuuid_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUuuid_st>())).bytes as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUuuid_st),
            "::",
            stringify!(bytes)
        )
    );
}
pub type CUuuid = CUuuid_st;
/// CUDA IPC event handle
#[repr(C)]
#[derive(Copy, Clone)]
pub struct CUipcEventHandle_st {
    pub reserved: [::std::os::raw::c_char; 64usize],
}
#[test]
fn bindgen_test_layout_CUipcEventHandle_st() {
    assert_eq!(
        ::std::mem::size_of::<CUipcEventHandle_st>(),
        64usize,
        concat!("Size of: ", stringify!(CUipcEventHandle_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUipcEventHandle_st>(),
        1usize,
        concat!("Alignment of ", stringify!(CUipcEventHandle_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUipcEventHandle_st>())).reserved as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUipcEventHandle_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUipcEventHandle = CUipcEventHandle_st;
/// CUDA IPC mem handle
#[repr(C)]
#[derive(Copy, Clone)]
pub struct CUipcMemHandle_st {
    pub reserved: [::std::os::raw::c_char; 64usize],
}
#[test]
fn bindgen_test_layout_CUipcMemHandle_st() {
    assert_eq!(
        ::std::mem::size_of::<CUipcMemHandle_st>(),
        64usize,
        concat!("Size of: ", stringify!(CUipcMemHandle_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUipcMemHandle_st>(),
        1usize,
        concat!("Alignment of ", stringify!(CUipcMemHandle_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUipcMemHandle_st>())).reserved as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUipcMemHandle_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUipcMemHandle = CUipcMemHandle_st;
///< Automatically enable peer access between remote devices as needed
pub const CUipcMem_flags_enum_CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS: CUipcMem_flags_enum = 1;
/// CUDA Ipc Mem Flags
pub type CUipcMem_flags_enum = u32;
pub use self::CUipcMem_flags_enum as CUipcMem_flags;
///< Memory can be accessed by any stream on any device
pub const CUmemAttach_flags_enum_CU_MEM_ATTACH_GLOBAL: CUmemAttach_flags_enum = 1;
///< Memory cannot be accessed by any stream on any device
pub const CUmemAttach_flags_enum_CU_MEM_ATTACH_HOST: CUmemAttach_flags_enum = 2;
///< Memory can only be accessed by a single stream on the associated device
pub const CUmemAttach_flags_enum_CU_MEM_ATTACH_SINGLE: CUmemAttach_flags_enum = 4;
/// CUDA Mem Attach Flags
pub type CUmemAttach_flags_enum = u32;
pub use self::CUmemAttach_flags_enum as CUmemAttach_flags;
///< Automatic scheduling
pub const CUctx_flags_enum_CU_CTX_SCHED_AUTO: CUctx_flags_enum = 0;
///< Set spin as default scheduling
pub const CUctx_flags_enum_CU_CTX_SCHED_SPIN: CUctx_flags_enum = 1;
///< Set yield as default scheduling
pub const CUctx_flags_enum_CU_CTX_SCHED_YIELD: CUctx_flags_enum = 2;
///< Set blocking synchronization as default scheduling
pub const CUctx_flags_enum_CU_CTX_SCHED_BLOCKING_SYNC: CUctx_flags_enum = 4;
///< Set blocking synchronization as default scheduling
///  \deprecated This flag was deprecated as of CUDA 4.0
///  and was replaced with ::CU_CTX_SCHED_BLOCKING_SYNC.
pub const CUctx_flags_enum_CU_CTX_BLOCKING_SYNC: CUctx_flags_enum = 4;
pub const CUctx_flags_enum_CU_CTX_SCHED_MASK: CUctx_flags_enum = 7;
///< Support mapped pinned allocations
pub const CUctx_flags_enum_CU_CTX_MAP_HOST: CUctx_flags_enum = 8;
///< Keep local memory allocation after launch
pub const CUctx_flags_enum_CU_CTX_LMEM_RESIZE_TO_MAX: CUctx_flags_enum = 16;
pub const CUctx_flags_enum_CU_CTX_FLAGS_MASK: CUctx_flags_enum = 31;
/// Context creation flags
pub type CUctx_flags_enum = u32;
pub use self::CUctx_flags_enum as CUctx_flags;
///< Default stream flag
pub const CUstream_flags_enum_CU_STREAM_DEFAULT: CUstream_flags_enum = 0;
///< Stream does not synchronize with stream 0 (the NULL stream)
pub const CUstream_flags_enum_CU_STREAM_NON_BLOCKING: CUstream_flags_enum = 1;
/// Stream creation flags
pub type CUstream_flags_enum = u32;
pub use self::CUstream_flags_enum as CUstream_flags;
///< Default event flag
pub const CUevent_flags_enum_CU_EVENT_DEFAULT: CUevent_flags_enum = 0;
///< Event uses blocking synchronization
pub const CUevent_flags_enum_CU_EVENT_BLOCKING_SYNC: CUevent_flags_enum = 1;
///< Event will not record timing data
pub const CUevent_flags_enum_CU_EVENT_DISABLE_TIMING: CUevent_flags_enum = 2;
///< Event is suitable for interprocess use. CU_EVENT_DISABLE_TIMING must be set
pub const CUevent_flags_enum_CU_EVENT_INTERPROCESS: CUevent_flags_enum = 4;
/// Event creation flags
pub type CUevent_flags_enum = u32;
pub use self::CUevent_flags_enum as CUevent_flags;
///< Wait until (int32_t)(*addr - value) >= 0 (or int64_t for 64 bit
///values). Note this is a cyclic comparison which ignores wraparound.
///(Default behavior.)
pub const CUstreamWaitValue_flags_enum_CU_STREAM_WAIT_VALUE_GEQ: CUstreamWaitValue_flags_enum = 0;
///< Wait until *addr == value.
pub const CUstreamWaitValue_flags_enum_CU_STREAM_WAIT_VALUE_EQ: CUstreamWaitValue_flags_enum = 1;
///< Wait until (*addr & value) != 0.
pub const CUstreamWaitValue_flags_enum_CU_STREAM_WAIT_VALUE_AND: CUstreamWaitValue_flags_enum = 2;
///< Wait until ~(*addr | value) != 0. Support for this operation can be
///queried with ::cuDeviceGetAttribute() and
///::CU_DEVICE_ATTRIBUTE_CAN_USE_STREAM_WAIT_VALUE_NOR.
pub const CUstreamWaitValue_flags_enum_CU_STREAM_WAIT_VALUE_NOR: CUstreamWaitValue_flags_enum = 3;
///< Follow the wait operation with a flush of outstanding remote writes. This
///means that, if a remote write operation is guaranteed to have reached the
///device before the wait can be satisfied, that write is guaranteed to be
///visible to downstream device work. The device is permitted to reorder
///remote writes internally. For example, this flag would be required if
///two remote writes arrive in a defined order, the wait is satisfied by the
///second write, and downstream work needs to observe the first write.
///Support for this operation is restricted to selected platforms and can be
///queried with ::CU_DEVICE_ATTRIBUTE_CAN_USE_WAIT_VALUE_FLUSH.
pub const CUstreamWaitValue_flags_enum_CU_STREAM_WAIT_VALUE_FLUSH: CUstreamWaitValue_flags_enum =
    1073741824;
/// Flags for ::cuStreamWaitValue32 and ::cuStreamWaitValue64
pub type CUstreamWaitValue_flags_enum = u32;
pub use self::CUstreamWaitValue_flags_enum as CUstreamWaitValue_flags;
///< Default behavior
pub const CUstreamWriteValue_flags_enum_CU_STREAM_WRITE_VALUE_DEFAULT:
    CUstreamWriteValue_flags_enum = 0;
///< Permits the write to be reordered with writes which were issued
///before it, as a performance optimization. Normally,
///::cuStreamWriteValue32 will provide a memory fence before the
///write, which has similar semantics to
///__threadfence_system() but is scoped to the stream
///rather than a CUDA thread.
pub const CUstreamWriteValue_flags_enum_CU_STREAM_WRITE_VALUE_NO_MEMORY_BARRIER:
    CUstreamWriteValue_flags_enum = 1;
/// Flags for ::cuStreamWriteValue32
pub type CUstreamWriteValue_flags_enum = u32;
pub use self::CUstreamWriteValue_flags_enum as CUstreamWriteValue_flags;
///< Represents a ::cuStreamWaitValue32 operation
pub const CUstreamBatchMemOpType_enum_CU_STREAM_MEM_OP_WAIT_VALUE_32: CUstreamBatchMemOpType_enum =
    1;
///< Represents a ::cuStreamWriteValue32 operation
pub const CUstreamBatchMemOpType_enum_CU_STREAM_MEM_OP_WRITE_VALUE_32: CUstreamBatchMemOpType_enum =
    2;
///< Represents a ::cuStreamWaitValue64 operation
pub const CUstreamBatchMemOpType_enum_CU_STREAM_MEM_OP_WAIT_VALUE_64: CUstreamBatchMemOpType_enum =
    4;
///< Represents a ::cuStreamWriteValue64 operation
pub const CUstreamBatchMemOpType_enum_CU_STREAM_MEM_OP_WRITE_VALUE_64: CUstreamBatchMemOpType_enum =
    5;
///< This has the same effect as ::CU_STREAM_WAIT_VALUE_FLUSH, but as a
///standalone operation.
pub const CUstreamBatchMemOpType_enum_CU_STREAM_MEM_OP_FLUSH_REMOTE_WRITES:
    CUstreamBatchMemOpType_enum = 3;
/// Operations for ::cuStreamBatchMemOp
pub type CUstreamBatchMemOpType_enum = u32;
pub use self::CUstreamBatchMemOpType_enum as CUstreamBatchMemOpType;
/// Per-operation parameters for ::cuStreamBatchMemOp
#[repr(C)]
#[derive(Copy, Clone)]
pub union CUstreamBatchMemOpParams_union {
    pub operation: CUstreamBatchMemOpType,
    pub waitValue: CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st,
    pub writeValue: CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st,
    pub flushRemoteWrites: CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st,
    pub pad: [cuuint64_t; 6usize],
    _bindgen_union_align: [u64; 6usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st {
    pub operation: CUstreamBatchMemOpType,
    pub address: CUdeviceptr,
    pub __bindgen_anon_1:
        CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1,
    pub flags: ::std::os::raw::c_uint,
    ///< For driver internal use. Initial value is unimportant.
    pub alias: CUdeviceptr,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1 {
    pub value: cuuint32_t,
    pub value64: cuuint64_t,
    _bindgen_union_align: u64,
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1(
) {
    assert_eq!(
        ::std::mem::size_of::<
            CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1,
        >(),
        8usize,
        concat!(
            "Size of: ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1
            )
        )
    );
    assert_eq!(
        ::std::mem::align_of::<
            CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1,
        >(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1
            )
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1,
            >())).value as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1
            ),
            "::",
            stringify!(value)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1,
            >())).value64 as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1
            ),
            "::",
            stringify!(value64)
        )
    );
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st() {
    assert_eq!(
        ::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>(),
        40usize,
        concat!(
            "Size of: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>(
            ))).operation as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st),
            "::",
            stringify!(operation)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>(
            ))).address as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st),
            "::",
            stringify!(address)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>(
            ))).flags as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>(
            ))).alias as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st),
            "::",
            stringify!(alias)
        )
    );
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st {
    pub operation: CUstreamBatchMemOpType,
    pub address: CUdeviceptr,
    pub __bindgen_anon_1:
        CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1,
    pub flags: ::std::os::raw::c_uint,
    ///< For driver internal use. Initial value is unimportant.
    pub alias: CUdeviceptr,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1 {
    pub value: cuuint32_t,
    pub value64: cuuint64_t,
    _bindgen_union_align: u64,
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1(
) {
    assert_eq!(
        ::std::mem::size_of::<
            CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1,
        >(),
        8usize,
        concat!(
            "Size of: ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1
            )
        )
    );
    assert_eq!(
        ::std::mem::align_of::<
            CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1,
        >(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1
            )
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1,
            >())).value as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1
            ),
            "::",
            stringify!(value)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1,
            >())).value64 as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(
                CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1
            ),
            "::",
            stringify!(value64)
        )
    );
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st() {
    assert_eq!(
        ::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>(),
        40usize,
        concat!(
            "Size of: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>(
            ))).operation as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st),
            "::",
            stringify!(operation)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>(
            ))).address as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st),
            "::",
            stringify!(address)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>(
            ))).flags as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>(
            ))).alias as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st),
            "::",
            stringify!(alias)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st {
    pub operation: CUstreamBatchMemOpType,
    pub flags: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st() {
    assert_eq!(
        ::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st>(
        ),
        8usize,
        concat!(
            "Size of: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<
            CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st,
        >(),
        4usize,
        concat!(
            "Alignment of ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st,
            >())).operation as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st),
            "::",
            stringify!(operation)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st,
            >())).flags as *const _ as usize
        },
        4usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st),
            "::",
            stringify!(flags)
        )
    );
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union() {
    assert_eq!(
        ::std::mem::size_of::<CUstreamBatchMemOpParams_union>(),
        48usize,
        concat!("Size of: ", stringify!(CUstreamBatchMemOpParams_union))
    );
    assert_eq!(
        ::std::mem::align_of::<CUstreamBatchMemOpParams_union>(),
        8usize,
        concat!("Alignment of ", stringify!(CUstreamBatchMemOpParams_union))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union>())).operation as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union),
            "::",
            stringify!(operation)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union>())).waitValue as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union),
            "::",
            stringify!(waitValue)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union>())).writeValue as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union),
            "::",
            stringify!(writeValue)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union>())).flushRemoteWrites as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union),
            "::",
            stringify!(flushRemoteWrites)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUstreamBatchMemOpParams_union>())).pad as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUstreamBatchMemOpParams_union),
            "::",
            stringify!(pad)
        )
    );
}
pub type CUstreamBatchMemOpParams = CUstreamBatchMemOpParams_union;
///< Default behavior
pub const CUoccupancy_flags_enum_CU_OCCUPANCY_DEFAULT: CUoccupancy_flags_enum = 0;
///< Assume global caching is enabled and cannot be automatically turned off
pub const CUoccupancy_flags_enum_CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE: CUoccupancy_flags_enum = 1;
/// Occupancy calculator flag
pub type CUoccupancy_flags_enum = u32;
pub use self::CUoccupancy_flags_enum as CUoccupancy_flags;
///< Unsigned 8-bit integers
pub const CUarray_format_enum_CU_AD_FORMAT_UNSIGNED_INT8: CUarray_format_enum = 1;
///< Unsigned 16-bit integers
pub const CUarray_format_enum_CU_AD_FORMAT_UNSIGNED_INT16: CUarray_format_enum = 2;
///< Unsigned 32-bit integers
pub const CUarray_format_enum_CU_AD_FORMAT_UNSIGNED_INT32: CUarray_format_enum = 3;
///< Signed 8-bit integers
pub const CUarray_format_enum_CU_AD_FORMAT_SIGNED_INT8: CUarray_format_enum = 8;
///< Signed 16-bit integers
pub const CUarray_format_enum_CU_AD_FORMAT_SIGNED_INT16: CUarray_format_enum = 9;
///< Signed 32-bit integers
pub const CUarray_format_enum_CU_AD_FORMAT_SIGNED_INT32: CUarray_format_enum = 10;
///< 16-bit floating point
pub const CUarray_format_enum_CU_AD_FORMAT_HALF: CUarray_format_enum = 16;
///< 32-bit floating point
pub const CUarray_format_enum_CU_AD_FORMAT_FLOAT: CUarray_format_enum = 32;
/// Array formats
pub type CUarray_format_enum = u32;
pub use self::CUarray_format_enum as CUarray_format;
///< Wrapping address mode
pub const CUaddress_mode_enum_CU_TR_ADDRESS_MODE_WRAP: CUaddress_mode_enum = 0;
///< Clamp to edge address mode
pub const CUaddress_mode_enum_CU_TR_ADDRESS_MODE_CLAMP: CUaddress_mode_enum = 1;
///< Mirror address mode
pub const CUaddress_mode_enum_CU_TR_ADDRESS_MODE_MIRROR: CUaddress_mode_enum = 2;
///< Border address mode
pub const CUaddress_mode_enum_CU_TR_ADDRESS_MODE_BORDER: CUaddress_mode_enum = 3;
/// Texture reference addressing modes
pub type CUaddress_mode_enum = u32;
pub use self::CUaddress_mode_enum as CUaddress_mode;
///< Point filter mode
pub const CUfilter_mode_enum_CU_TR_FILTER_MODE_POINT: CUfilter_mode_enum = 0;
///< Linear filter mode
pub const CUfilter_mode_enum_CU_TR_FILTER_MODE_LINEAR: CUfilter_mode_enum = 1;
/// Texture reference filtering modes
pub type CUfilter_mode_enum = u32;
pub use self::CUfilter_mode_enum as CUfilter_mode;
///< Maximum number of threads per block
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK:
    CUdevice_attribute_enum = 1;
///< Maximum block dimension X
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X: CUdevice_attribute_enum = 2;
///< Maximum block dimension Y
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y: CUdevice_attribute_enum = 3;
///< Maximum block dimension Z
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z: CUdevice_attribute_enum = 4;
///< Maximum grid dimension X
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X: CUdevice_attribute_enum = 5;
///< Maximum grid dimension Y
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y: CUdevice_attribute_enum = 6;
///< Maximum grid dimension Z
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z: CUdevice_attribute_enum = 7;
///< Maximum shared memory available per block in bytes
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK:
    CUdevice_attribute_enum = 8;
///< Deprecated, use CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_SHARED_MEMORY_PER_BLOCK:
    CUdevice_attribute_enum = 8;
///< Memory available on device for __constant__ variables in a CUDA C kernel in bytes
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY:
    CUdevice_attribute_enum = 9;
///< Warp size in threads
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_WARP_SIZE: CUdevice_attribute_enum = 10;
///< Maximum pitch in bytes allowed by memory copies
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_PITCH: CUdevice_attribute_enum = 11;
///< Maximum number of 32-bit registers available per block
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK:
    CUdevice_attribute_enum = 12;
///< Deprecated, use CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK: CUdevice_attribute_enum =
    12;
///< Typical clock frequency in kilohertz
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CLOCK_RATE: CUdevice_attribute_enum = 13;
///< Alignment requirement for textures
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT: CUdevice_attribute_enum =
    14;
///< Device can possibly copy memory and execute a kernel concurrently. Deprecated. Use instead CU_DEVICE_ATTRIBUTE_ASYNC_ENGINE_COUNT.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_GPU_OVERLAP: CUdevice_attribute_enum = 15;
///< Number of multiprocessors on device
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT:
    CUdevice_attribute_enum = 16;
///< Specifies whether there is a run time limit on kernels
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT: CUdevice_attribute_enum =
    17;
///< Device is integrated with host memory
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_INTEGRATED: CUdevice_attribute_enum = 18;
///< Device can map host memory into CUDA address space
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CAN_MAP_HOST_MEMORY: CUdevice_attribute_enum =
    19;
///< Compute mode (See ::CUcomputemode for details)
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_COMPUTE_MODE: CUdevice_attribute_enum = 20;
///< Maximum 1D texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_WIDTH:
    CUdevice_attribute_enum = 21;
///< Maximum 2D texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_WIDTH:
    CUdevice_attribute_enum = 22;
///< Maximum 2D texture height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_HEIGHT:
    CUdevice_attribute_enum = 23;
///< Maximum 3D texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH:
    CUdevice_attribute_enum = 24;
///< Maximum 3D texture height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT:
    CUdevice_attribute_enum = 25;
///< Maximum 3D texture depth
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH:
    CUdevice_attribute_enum = 26;
///< Maximum 2D layered texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH:
    CUdevice_attribute_enum = 27;
///< Maximum 2D layered texture height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT:
    CUdevice_attribute_enum = 28;
///< Maximum layers in a 2D layered texture
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS:
    CUdevice_attribute_enum = 29;
///< Deprecated, use CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_WIDTH:
    CUdevice_attribute_enum = 27;
///< Deprecated, use CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_HEIGHT:
    CUdevice_attribute_enum = 28;
///< Deprecated, use CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES:
    CUdevice_attribute_enum = 29;
///< Alignment requirement for surfaces
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_SURFACE_ALIGNMENT: CUdevice_attribute_enum =
    30;
///< Device can possibly execute multiple kernels concurrently
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS: CUdevice_attribute_enum =
    31;
///< Device has ECC support enabled
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_ECC_ENABLED: CUdevice_attribute_enum = 32;
///< PCI bus ID of the device
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_PCI_BUS_ID: CUdevice_attribute_enum = 33;
///< PCI device ID of the device
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_PCI_DEVICE_ID: CUdevice_attribute_enum = 34;
///< Device is using TCC driver model
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_TCC_DRIVER: CUdevice_attribute_enum = 35;
///< Peak memory clock frequency in kilohertz
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE: CUdevice_attribute_enum =
    36;
///< Global memory bus width in bits
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH:
    CUdevice_attribute_enum = 37;
///< Size of L2 cache in bytes
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE: CUdevice_attribute_enum = 38;
///< Maximum resident threads per multiprocessor
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR:
    CUdevice_attribute_enum = 39;
///< Number of asynchronous engines
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_ASYNC_ENGINE_COUNT: CUdevice_attribute_enum =
    40;
///< Device shares a unified address space with the host
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING: CUdevice_attribute_enum =
    41;
///< Maximum 1D layered texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_WIDTH:
    CUdevice_attribute_enum = 42;
///< Maximum layers in a 1D layered texture
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_LAYERS:
    CUdevice_attribute_enum = 43;
///< Deprecated, do not use.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CAN_TEX2D_GATHER: CUdevice_attribute_enum =
    44;
///< Maximum 2D texture width if CUDA_ARRAY3D_TEXTURE_GATHER is set
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_WIDTH:
    CUdevice_attribute_enum = 45;
///< Maximum 2D texture height if CUDA_ARRAY3D_TEXTURE_GATHER is set
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_HEIGHT:
    CUdevice_attribute_enum = 46;
///< Alternate maximum 3D texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE:
    CUdevice_attribute_enum = 47;
///< Alternate maximum 3D texture height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE:
    CUdevice_attribute_enum = 48;
///< Alternate maximum 3D texture depth
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE:
    CUdevice_attribute_enum = 49;
///< PCI domain ID of the device
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_PCI_DOMAIN_ID: CUdevice_attribute_enum = 50;
///< Pitch alignment requirement for textures
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT:
    CUdevice_attribute_enum = 51;
///< Maximum cubemap texture width/height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_WIDTH:
    CUdevice_attribute_enum = 52;
///< Maximum cubemap layered texture width/height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH:
    CUdevice_attribute_enum = 53;
///< Maximum layers in a cubemap layered texture
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS:
    CUdevice_attribute_enum = 54;
///< Maximum 1D surface width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_WIDTH:
    CUdevice_attribute_enum = 55;
///< Maximum 2D surface width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_WIDTH:
    CUdevice_attribute_enum = 56;
///< Maximum 2D surface height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_HEIGHT:
    CUdevice_attribute_enum = 57;
///< Maximum 3D surface width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_WIDTH:
    CUdevice_attribute_enum = 58;
///< Maximum 3D surface height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_HEIGHT:
    CUdevice_attribute_enum = 59;
///< Maximum 3D surface depth
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_DEPTH:
    CUdevice_attribute_enum = 60;
///< Maximum 1D layered surface width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_WIDTH:
    CUdevice_attribute_enum = 61;
///< Maximum layers in a 1D layered surface
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_LAYERS:
    CUdevice_attribute_enum = 62;
///< Maximum 2D layered surface width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_WIDTH:
    CUdevice_attribute_enum = 63;
///< Maximum 2D layered surface height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_HEIGHT:
    CUdevice_attribute_enum = 64;
///< Maximum layers in a 2D layered surface
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_LAYERS:
    CUdevice_attribute_enum = 65;
///< Maximum cubemap surface width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_WIDTH:
    CUdevice_attribute_enum = 66;
///< Maximum cubemap layered surface width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH:
    CUdevice_attribute_enum = 67;
///< Maximum layers in a cubemap layered surface
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS:
    CUdevice_attribute_enum = 68;
///< Maximum 1D linear texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH:
    CUdevice_attribute_enum = 69;
///< Maximum 2D linear texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH:
    CUdevice_attribute_enum = 70;
///< Maximum 2D linear texture height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT:
    CUdevice_attribute_enum = 71;
///< Maximum 2D linear texture pitch in bytes
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH:
    CUdevice_attribute_enum = 72;
///< Maximum mipmapped 2D texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH:
    CUdevice_attribute_enum = 73;
///< Maximum mipmapped 2D texture height
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT:
    CUdevice_attribute_enum = 74;
///< Major compute capability version number
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR:
    CUdevice_attribute_enum = 75;
///< Minor compute capability version number
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR:
    CUdevice_attribute_enum = 76;
///< Maximum mipmapped 1D texture width
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH:
    CUdevice_attribute_enum = 77;
///< Device supports stream priorities
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_STREAM_PRIORITIES_SUPPORTED:
    CUdevice_attribute_enum = 78;
///< Device supports caching globals in L1
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_GLOBAL_L1_CACHE_SUPPORTED:
    CUdevice_attribute_enum = 79;
///< Device supports caching locals in L1
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_LOCAL_L1_CACHE_SUPPORTED:
    CUdevice_attribute_enum = 80;
///< Maximum shared memory available per multiprocessor in bytes
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR:
    CUdevice_attribute_enum = 81;
///< Maximum number of 32-bit registers available per multiprocessor
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_MULTIPROCESSOR:
    CUdevice_attribute_enum = 82;
///< Device can allocate managed memory on this system
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY: CUdevice_attribute_enum = 83;
///< Device is on a multi-GPU board
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD: CUdevice_attribute_enum = 84;
///< Unique id for a group of devices on the same multi-GPU board
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD_GROUP_ID:
    CUdevice_attribute_enum = 85;
///< Link between the device and the host supports native atomic operations (this is a placeholder attribute, and is not supported on any current hardware)
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_HOST_NATIVE_ATOMIC_SUPPORTED:
    CUdevice_attribute_enum = 86;
///< Ratio of single precision performance (in floating-point operations per second) to double precision performance
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO:
    CUdevice_attribute_enum = 87;
///< Device supports coherently accessing pageable memory without calling cudaHostRegister on it
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS:
    CUdevice_attribute_enum = 88;
///< Device can coherently access managed memory concurrently with the CPU
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS:
    CUdevice_attribute_enum = 89;
///< Device supports compute preemption.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_COMPUTE_PREEMPTION_SUPPORTED:
    CUdevice_attribute_enum = 90;
///< Device can access host registered memory at the same virtual address as the CPU
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM:
    CUdevice_attribute_enum = 91;
///< ::cuStreamBatchMemOp and related APIs are supported.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CAN_USE_STREAM_MEM_OPS:
    CUdevice_attribute_enum = 92;
///< 64-bit operations are supported in ::cuStreamBatchMemOp and related APIs.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CAN_USE_64_BIT_STREAM_MEM_OPS:
    CUdevice_attribute_enum = 93;
///< ::CU_STREAM_WAIT_VALUE_NOR is supported.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CAN_USE_STREAM_WAIT_VALUE_NOR:
    CUdevice_attribute_enum = 94;
///< Device supports launching cooperative kernels via ::cuLaunchCooperativeKernel
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_COOPERATIVE_LAUNCH: CUdevice_attribute_enum =
    95;
///< Device can participate in cooperative kernels launched via ::cuLaunchCooperativeKernelMultiDevice
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_COOPERATIVE_MULTI_DEVICE_LAUNCH:
    CUdevice_attribute_enum = 96;
///< Maximum optin shared memory per block
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN:
    CUdevice_attribute_enum = 97;
///< Both the ::CU_STREAM_WAIT_VALUE_FLUSH flag and the ::CU_STREAM_MEM_OP_FLUSH_REMOTE_WRITES MemOp are supported on the device. See \ref CUDA_MEMOP for additional details.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_CAN_FLUSH_REMOTE_WRITES:
    CUdevice_attribute_enum = 98;
///< Device supports host memory registration via ::cudaHostRegister.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_HOST_REGISTER_SUPPORTED:
    CUdevice_attribute_enum = 99;
///< Device accesses pageable memory via the host's page tables.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES : CUdevice_attribute_enum = 100 ;
///< The host can directly access managed memory on the device without migration.
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_DIRECT_MANAGED_MEM_ACCESS_FROM_HOST:
    CUdevice_attribute_enum = 101;
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAX: CUdevice_attribute_enum = 102;
/// Device properties
pub type CUdevice_attribute_enum = u32;
pub use self::CUdevice_attribute_enum as CUdevice_attribute;
/// Legacy device properties
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUdevprop_st {
    ///< Maximum number of threads per block
    pub maxThreadsPerBlock: ::std::os::raw::c_int,
    ///< Maximum size of each dimension of a block
    pub maxThreadsDim: [::std::os::raw::c_int; 3usize],
    ///< Maximum size of each dimension of a grid
    pub maxGridSize: [::std::os::raw::c_int; 3usize],
    ///< Shared memory available per block in bytes
    pub sharedMemPerBlock: ::std::os::raw::c_int,
    ///< Constant memory available on device in bytes
    pub totalConstantMemory: ::std::os::raw::c_int,
    ///< Warp size in threads
    pub SIMDWidth: ::std::os::raw::c_int,
    ///< Maximum pitch in bytes allowed by memory copies
    pub memPitch: ::std::os::raw::c_int,
    ///< 32-bit registers available per block
    pub regsPerBlock: ::std::os::raw::c_int,
    ///< Clock frequency in kilohertz
    pub clockRate: ::std::os::raw::c_int,
    ///< Alignment requirement for textures
    pub textureAlign: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout_CUdevprop_st() {
    assert_eq!(
        ::std::mem::size_of::<CUdevprop_st>(),
        56usize,
        concat!("Size of: ", stringify!(CUdevprop_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUdevprop_st>(),
        4usize,
        concat!("Alignment of ", stringify!(CUdevprop_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).maxThreadsPerBlock as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(maxThreadsPerBlock)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).maxThreadsDim as *const _ as usize },
        4usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(maxThreadsDim)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).maxGridSize as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(maxGridSize)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).sharedMemPerBlock as *const _ as usize },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(sharedMemPerBlock)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUdevprop_st>())).totalConstantMemory as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(totalConstantMemory)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).SIMDWidth as *const _ as usize },
        36usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(SIMDWidth)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).memPitch as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(memPitch)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).regsPerBlock as *const _ as usize },
        44usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(regsPerBlock)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).clockRate as *const _ as usize },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(clockRate)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUdevprop_st>())).textureAlign as *const _ as usize },
        52usize,
        concat!(
            "Offset of field: ",
            stringify!(CUdevprop_st),
            "::",
            stringify!(textureAlign)
        )
    );
}
pub type CUdevprop = CUdevprop_st;
///< The ::CUcontext on which a pointer was allocated or registered
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_CONTEXT: CUpointer_attribute_enum = 1;
///< The ::CUmemorytype describing the physical location of a pointer
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_MEMORY_TYPE: CUpointer_attribute_enum = 2;
///< The address at which a pointer's memory may be accessed on the device
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_DEVICE_POINTER: CUpointer_attribute_enum =
    3;
///< The address at which a pointer's memory may be accessed on the host
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_HOST_POINTER: CUpointer_attribute_enum = 4;
///< A pair of tokens for use with the nv-p2p.h Linux kernel interface
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_P2P_TOKENS: CUpointer_attribute_enum = 5;
///< Synchronize every synchronous memory operation initiated on this region
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_SYNC_MEMOPS: CUpointer_attribute_enum = 6;
///< A process-wide unique ID for an allocated memory region
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_BUFFER_ID: CUpointer_attribute_enum = 7;
///< Indicates if the pointer points to managed memory
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_IS_MANAGED: CUpointer_attribute_enum = 8;
///< A device ordinal of a device on which a pointer was allocated or registered
pub const CUpointer_attribute_enum_CU_POINTER_ATTRIBUTE_DEVICE_ORDINAL: CUpointer_attribute_enum =
    9;
/// Pointer information
pub type CUpointer_attribute_enum = u32;
pub use self::CUpointer_attribute_enum as CUpointer_attribute;
/// The maximum number of threads per block, beyond which a launch of the
/// function would fail. This number depends on both the function and the
/// device on which the function is currently loaded.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_MAX_THREADS_PER_BLOCK:
    CUfunction_attribute_enum = 0;
/// The size in bytes of statically-allocated shared memory required by
/// this function. This does not include dynamically-allocated shared
/// memory requested by the user at runtime.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES: CUfunction_attribute_enum =
    1;
/// The size in bytes of user-allocated constant memory required by this
/// function.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_CONST_SIZE_BYTES: CUfunction_attribute_enum =
    2;
/// The size in bytes of local memory used by each thread of this function.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_LOCAL_SIZE_BYTES: CUfunction_attribute_enum =
    3;
/// The number of registers used by each thread of this function.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_NUM_REGS: CUfunction_attribute_enum = 4;
/// The PTX virtual architecture version for which the function was
/// compiled. This value is the major PTX version * 10 + the minor PTX
/// version, so a PTX version 1.3 function would return the value 13.
/// Note that this may return the undefined value of 0 for cubins
/// compiled prior to CUDA 3.0.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_PTX_VERSION: CUfunction_attribute_enum = 5;
/// The binary architecture version for which the function was compiled.
/// This value is the major binary version * 10 + the minor binary version,
/// so a binary version 1.3 function would return the value 13. Note that
/// this will return a value of 10 for legacy cubins that do not have a
/// properly-encoded binary architecture version.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_BINARY_VERSION: CUfunction_attribute_enum = 6;
/// The attribute to indicate whether the function has been compiled with
/// user specified option "-Xptxas --dlcm=ca" set .
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_CACHE_MODE_CA: CUfunction_attribute_enum = 7;
/// The maximum size in bytes of dynamically-allocated shared memory that can be used by
/// this function. If the user-specified dynamic shared memory size is larger than this
/// value, the launch will fail.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES:
    CUfunction_attribute_enum = 8;
/// On devices where the L1 cache and shared memory use the same hardware resources,
/// this sets the shared memory carveout preference, in percent of the total resources.
/// This is only a hint, and the driver can choose a different ratio if required to execute the function.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_PREFERRED_SHARED_MEMORY_CARVEOUT:
    CUfunction_attribute_enum = 9;
/// On devices where the L1 cache and shared memory use the same hardware resources,
/// this sets the shared memory carveout preference, in percent of the total resources.
/// This is only a hint, and the driver can choose a different ratio if required to execute the function.
pub const CUfunction_attribute_enum_CU_FUNC_ATTRIBUTE_MAX: CUfunction_attribute_enum = 10;
/// Function properties
pub type CUfunction_attribute_enum = u32;
pub use self::CUfunction_attribute_enum as CUfunction_attribute;
///< no preference for shared memory or L1 (default)
pub const CUfunc_cache_enum_CU_FUNC_CACHE_PREFER_NONE: CUfunc_cache_enum = 0;
///< prefer larger shared memory and smaller L1 cache
pub const CUfunc_cache_enum_CU_FUNC_CACHE_PREFER_SHARED: CUfunc_cache_enum = 1;
///< prefer larger L1 cache and smaller shared memory
pub const CUfunc_cache_enum_CU_FUNC_CACHE_PREFER_L1: CUfunc_cache_enum = 2;
///< prefer equal sized L1 cache and shared memory
pub const CUfunc_cache_enum_CU_FUNC_CACHE_PREFER_EQUAL: CUfunc_cache_enum = 3;
/// Function cache configurations
pub type CUfunc_cache_enum = u32;
pub use self::CUfunc_cache_enum as CUfunc_cache;
///< set default shared memory bank size
pub const CUsharedconfig_enum_CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE: CUsharedconfig_enum = 0;
///< set shared memory bank width to four bytes
pub const CUsharedconfig_enum_CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE: CUsharedconfig_enum = 1;
///< set shared memory bank width to eight bytes
pub const CUsharedconfig_enum_CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE: CUsharedconfig_enum = 2;
/// Shared memory configurations
pub type CUsharedconfig_enum = u32;
pub use self::CUsharedconfig_enum as CUsharedconfig;
pub const CUshared_carveout_enum_CU_SHAREDMEM_CARVEOUT_DEFAULT: CUshared_carveout_enum = -1;
/// < no preference for shared memory or L1 (default)
pub const CUshared_carveout_enum_CU_SHAREDMEM_CARVEOUT_MAX_SHARED: CUshared_carveout_enum = 100;
/// < prefer maximum available shared memory, minimum L1 cache
pub const CUshared_carveout_enum_CU_SHAREDMEM_CARVEOUT_MAX_L1: CUshared_carveout_enum = 0;
/// Shared memory carveout configurations
pub type CUshared_carveout_enum = i32;
pub use self::CUshared_carveout_enum as CUshared_carveout;
///< Host memory
pub const CUmemorytype_enum_CU_MEMORYTYPE_HOST: CUmemorytype_enum = 1;
///< Device memory
pub const CUmemorytype_enum_CU_MEMORYTYPE_DEVICE: CUmemorytype_enum = 2;
///< Array memory
pub const CUmemorytype_enum_CU_MEMORYTYPE_ARRAY: CUmemorytype_enum = 3;
///< Unified device or host memory
pub const CUmemorytype_enum_CU_MEMORYTYPE_UNIFIED: CUmemorytype_enum = 4;
/// Memory types
pub type CUmemorytype_enum = u32;
pub use self::CUmemorytype_enum as CUmemorytype;
///< Default compute mode (Multiple contexts allowed per device)
pub const CUcomputemode_enum_CU_COMPUTEMODE_DEFAULT: CUcomputemode_enum = 0;
///< Compute-prohibited mode (No contexts can be created on this device at this time)
pub const CUcomputemode_enum_CU_COMPUTEMODE_PROHIBITED: CUcomputemode_enum = 2;
///< Compute-exclusive-process mode (Only one context used by a single process can be present on this device at a time)
pub const CUcomputemode_enum_CU_COMPUTEMODE_EXCLUSIVE_PROCESS: CUcomputemode_enum = 3;
/// Compute Modes
pub type CUcomputemode_enum = u32;
pub use self::CUcomputemode_enum as CUcomputemode;
///< Data will mostly be read and only occassionally be written to
pub const CUmem_advise_enum_CU_MEM_ADVISE_SET_READ_MOSTLY: CUmem_advise_enum = 1;
///< Undo the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY
pub const CUmem_advise_enum_CU_MEM_ADVISE_UNSET_READ_MOSTLY: CUmem_advise_enum = 2;
///< Set the preferred location for the data as the specified device
pub const CUmem_advise_enum_CU_MEM_ADVISE_SET_PREFERRED_LOCATION: CUmem_advise_enum = 3;
///< Clear the preferred location for the data
pub const CUmem_advise_enum_CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION: CUmem_advise_enum = 4;
///< Data will be accessed by the specified device, so prevent page faults as much as possible
pub const CUmem_advise_enum_CU_MEM_ADVISE_SET_ACCESSED_BY: CUmem_advise_enum = 5;
///< Let the Unified Memory subsystem decide on the page faulting policy for the specified device
pub const CUmem_advise_enum_CU_MEM_ADVISE_UNSET_ACCESSED_BY: CUmem_advise_enum = 6;
/// Memory advise values
pub type CUmem_advise_enum = u32;
pub use self::CUmem_advise_enum as CUmem_advise;
///< Whether the range will mostly be read and only occassionally be written to
pub const CUmem_range_attribute_enum_CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY:
    CUmem_range_attribute_enum = 1;
///< The preferred location of the range
pub const CUmem_range_attribute_enum_CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION:
    CUmem_range_attribute_enum = 2;
///< Memory range has ::CU_MEM_ADVISE_SET_ACCESSED_BY set for specified device
pub const CUmem_range_attribute_enum_CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY:
    CUmem_range_attribute_enum = 3;
///< The last location to which the range was prefetched
pub const CUmem_range_attribute_enum_CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION:
    CUmem_range_attribute_enum = 4;
pub type CUmem_range_attribute_enum = u32;
pub use self::CUmem_range_attribute_enum as CUmem_range_attribute;
/// Max number of registers that a thread may use.\n
/// Option type: unsigned int\n
/// Applies to: compiler only
pub const CUjit_option_enum_CU_JIT_MAX_REGISTERS: CUjit_option_enum = 0;
/// IN: Specifies minimum number of threads per block to target compilation
/// for\n
/// OUT: Returns the number of threads the compiler actually targeted.
/// This restricts the resource utilization fo the compiler (e.g. max
/// registers) such that a block with the given number of threads should be
/// able to launch based on register limitations. Note, this option does not
/// currently take into account any other resource limitations, such as
/// shared memory utilization.\n
/// Cannot be combined with ::CU_JIT_TARGET.\n
/// Option type: unsigned int\n
/// Applies to: compiler only
pub const CUjit_option_enum_CU_JIT_THREADS_PER_BLOCK: CUjit_option_enum = 1;
/// Overwrites the option value with the total wall clock time, in
/// milliseconds, spent in the compiler and linker\n
/// Option type: float\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_WALL_TIME: CUjit_option_enum = 2;
/// Pointer to a buffer in which to print any log messages
/// that are informational in nature (the buffer size is specified via
/// option ::CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES)\n
/// Option type: char *\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_INFO_LOG_BUFFER: CUjit_option_enum = 3;
/// IN: Log buffer size in bytes.  Log messages will be capped at this size
/// (including null terminator)\n
/// OUT: Amount of log buffer filled with messages\n
/// Option type: unsigned int\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES: CUjit_option_enum = 4;
/// Pointer to a buffer in which to print any log messages that
/// reflect errors (the buffer size is specified via option
/// ::CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES)\n
/// Option type: char *\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_ERROR_LOG_BUFFER: CUjit_option_enum = 5;
/// IN: Log buffer size in bytes.  Log messages will be capped at this size
/// (including null terminator)\n
/// OUT: Amount of log buffer filled with messages\n
/// Option type: unsigned int\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES: CUjit_option_enum = 6;
/// Level of optimizations to apply to generated code (0 - 4), with 4
/// being the default and highest level of optimizations.\n
/// Option type: unsigned int\n
/// Applies to: compiler only
pub const CUjit_option_enum_CU_JIT_OPTIMIZATION_LEVEL: CUjit_option_enum = 7;
/// No option value required. Determines the target based on the current
/// attached context (default)\n
/// Option type: No option value needed\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_TARGET_FROM_CUCONTEXT: CUjit_option_enum = 8;
/// Target is chosen based on supplied ::CUjit_target.  Cannot be
/// combined with ::CU_JIT_THREADS_PER_BLOCK.\n
/// Option type: unsigned int for enumerated type ::CUjit_target\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_TARGET: CUjit_option_enum = 9;
/// Specifies choice of fallback strategy if matching cubin is not found.
/// Choice is based on supplied ::CUjit_fallback.  This option cannot be
/// used with cuLink* APIs as the linker requires exact matches.\n
/// Option type: unsigned int for enumerated type ::CUjit_fallback\n
/// Applies to: compiler only
pub const CUjit_option_enum_CU_JIT_FALLBACK_STRATEGY: CUjit_option_enum = 10;
/// Specifies whether to create debug information in output (-g)
/// (0: false, default)\n
/// Option type: int\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_GENERATE_DEBUG_INFO: CUjit_option_enum = 11;
/// Generate verbose log messages (0: false, default)\n
/// Option type: int\n
/// Applies to: compiler and linker
pub const CUjit_option_enum_CU_JIT_LOG_VERBOSE: CUjit_option_enum = 12;
/// Generate line number information (-lineinfo) (0: false, default)\n
/// Option type: int\n
/// Applies to: compiler only
pub const CUjit_option_enum_CU_JIT_GENERATE_LINE_INFO: CUjit_option_enum = 13;
/// Specifies whether to enable caching explicitly (-dlcm) \n
/// Choice is based on supplied ::CUjit_cacheMode_enum.\n
/// Option type: unsigned int for enumerated type ::CUjit_cacheMode_enum\n
/// Applies to: compiler only
pub const CUjit_option_enum_CU_JIT_CACHE_MODE: CUjit_option_enum = 14;
/// The below jit options are used for internal purposes only, in this version of CUDA
pub const CUjit_option_enum_CU_JIT_NEW_SM3X_OPT: CUjit_option_enum = 15;
/// The below jit options are used for internal purposes only, in this version of CUDA
pub const CUjit_option_enum_CU_JIT_FAST_COMPILE: CUjit_option_enum = 16;
/// Array of device symbol names that will be relocated to the corresponing
/// host addresses stored in ::CU_JIT_GLOBAL_SYMBOL_ADDRESSES.\n
/// Must contain ::CU_JIT_GLOBAL_SYMBOL_COUNT entries.\n
/// When loding a device module, driver will relocate all encountered
/// unresolved symbols to the host addresses.\n
/// It is only allowed to register symbols that correspond to unresolved
/// global variables.\n
/// It is illegal to register the same device symbol at multiple addresses.\n
/// Option type: const char **\n
/// Applies to: dynamic linker only
pub const CUjit_option_enum_CU_JIT_GLOBAL_SYMBOL_NAMES: CUjit_option_enum = 17;
/// Array of host addresses that will be used to relocate corresponding
/// device symbols stored in ::CU_JIT_GLOBAL_SYMBOL_NAMES.\n
/// Must contain ::CU_JIT_GLOBAL_SYMBOL_COUNT entries.\n
/// Option type: void **\n
/// Applies to: dynamic linker only
pub const CUjit_option_enum_CU_JIT_GLOBAL_SYMBOL_ADDRESSES: CUjit_option_enum = 18;
/// Number of entries in ::CU_JIT_GLOBAL_SYMBOL_NAMES and
/// ::CU_JIT_GLOBAL_SYMBOL_ADDRESSES arrays.\n
/// Option type: unsigned int\n
/// Applies to: dynamic linker only
pub const CUjit_option_enum_CU_JIT_GLOBAL_SYMBOL_COUNT: CUjit_option_enum = 19;
/// Number of entries in ::CU_JIT_GLOBAL_SYMBOL_NAMES and
/// ::CU_JIT_GLOBAL_SYMBOL_ADDRESSES arrays.\n
/// Option type: unsigned int\n
/// Applies to: dynamic linker only
pub const CUjit_option_enum_CU_JIT_NUM_OPTIONS: CUjit_option_enum = 20;
/// Online compiler and linker options
pub type CUjit_option_enum = u32;
pub use self::CUjit_option_enum as CUjit_option;
///< Compute device class 2.0
pub const CUjit_target_enum_CU_TARGET_COMPUTE_20: CUjit_target_enum = 20;
///< Compute device class 2.1
pub const CUjit_target_enum_CU_TARGET_COMPUTE_21: CUjit_target_enum = 21;
///< Compute device class 3.0
pub const CUjit_target_enum_CU_TARGET_COMPUTE_30: CUjit_target_enum = 30;
///< Compute device class 3.2
pub const CUjit_target_enum_CU_TARGET_COMPUTE_32: CUjit_target_enum = 32;
///< Compute device class 3.5
pub const CUjit_target_enum_CU_TARGET_COMPUTE_35: CUjit_target_enum = 35;
///< Compute device class 3.7
pub const CUjit_target_enum_CU_TARGET_COMPUTE_37: CUjit_target_enum = 37;
///< Compute device class 5.0
pub const CUjit_target_enum_CU_TARGET_COMPUTE_50: CUjit_target_enum = 50;
///< Compute device class 5.2
pub const CUjit_target_enum_CU_TARGET_COMPUTE_52: CUjit_target_enum = 52;
///< Compute device class 5.3
pub const CUjit_target_enum_CU_TARGET_COMPUTE_53: CUjit_target_enum = 53;
///< Compute device class 6.0.
pub const CUjit_target_enum_CU_TARGET_COMPUTE_60: CUjit_target_enum = 60;
///< Compute device class 6.1.
pub const CUjit_target_enum_CU_TARGET_COMPUTE_61: CUjit_target_enum = 61;
///< Compute device class 6.2.
pub const CUjit_target_enum_CU_TARGET_COMPUTE_62: CUjit_target_enum = 62;
///< Compute device class 7.0.
pub const CUjit_target_enum_CU_TARGET_COMPUTE_70: CUjit_target_enum = 70;
///< Compute device class 7.5.
pub const CUjit_target_enum_CU_TARGET_COMPUTE_75: CUjit_target_enum = 75;
/// Online compilation targets
pub type CUjit_target_enum = u32;
pub use self::CUjit_target_enum as CUjit_target;
///< Prefer to compile ptx if exact binary match not found
pub const CUjit_fallback_enum_CU_PREFER_PTX: CUjit_fallback_enum = 0;
///< Prefer to fall back to compatible binary code if exact match not found
pub const CUjit_fallback_enum_CU_PREFER_BINARY: CUjit_fallback_enum = 1;
/// Cubin matching fallback strategies
pub type CUjit_fallback_enum = u32;
pub use self::CUjit_fallback_enum as CUjit_fallback;
///< Compile with no -dlcm flag specified
pub const CUjit_cacheMode_enum_CU_JIT_CACHE_OPTION_NONE: CUjit_cacheMode_enum = 0;
///< Compile with L1 cache disabled
pub const CUjit_cacheMode_enum_CU_JIT_CACHE_OPTION_CG: CUjit_cacheMode_enum = 1;
///< Compile with L1 cache enabled
pub const CUjit_cacheMode_enum_CU_JIT_CACHE_OPTION_CA: CUjit_cacheMode_enum = 2;
/// Caching modes for dlcm
pub type CUjit_cacheMode_enum = u32;
pub use self::CUjit_cacheMode_enum as CUjit_cacheMode;
/// Compiled device-class-specific device code\n
/// Applicable options: none
pub const CUjitInputType_enum_CU_JIT_INPUT_CUBIN: CUjitInputType_enum = 0;
/// PTX source code\n
/// Applicable options: PTX compiler options
pub const CUjitInputType_enum_CU_JIT_INPUT_PTX: CUjitInputType_enum = 1;
/// Bundle of multiple cubins and/or PTX of some device code\n
/// Applicable options: PTX compiler options, ::CU_JIT_FALLBACK_STRATEGY
pub const CUjitInputType_enum_CU_JIT_INPUT_FATBINARY: CUjitInputType_enum = 2;
/// Host object with embedded device code\n
/// Applicable options: PTX compiler options, ::CU_JIT_FALLBACK_STRATEGY
pub const CUjitInputType_enum_CU_JIT_INPUT_OBJECT: CUjitInputType_enum = 3;
/// Archive of host objects with embedded device code\n
/// Applicable options: PTX compiler options, ::CU_JIT_FALLBACK_STRATEGY
pub const CUjitInputType_enum_CU_JIT_INPUT_LIBRARY: CUjitInputType_enum = 4;
/// Archive of host objects with embedded device code\n
/// Applicable options: PTX compiler options, ::CU_JIT_FALLBACK_STRATEGY
pub const CUjitInputType_enum_CU_JIT_NUM_INPUT_TYPES: CUjitInputType_enum = 5;
/// Device code formats
pub type CUjitInputType_enum = u32;
pub use self::CUjitInputType_enum as CUjitInputType;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUlinkState_st {
    _unused: [u8; 0],
}
pub type CUlinkState = *mut CUlinkState_st;
pub const CUgraphicsRegisterFlags_enum_CU_GRAPHICS_REGISTER_FLAGS_NONE:
    CUgraphicsRegisterFlags_enum = 0;
pub const CUgraphicsRegisterFlags_enum_CU_GRAPHICS_REGISTER_FLAGS_READ_ONLY:
    CUgraphicsRegisterFlags_enum = 1;
pub const CUgraphicsRegisterFlags_enum_CU_GRAPHICS_REGISTER_FLAGS_WRITE_DISCARD:
    CUgraphicsRegisterFlags_enum = 2;
pub const CUgraphicsRegisterFlags_enum_CU_GRAPHICS_REGISTER_FLAGS_SURFACE_LDST:
    CUgraphicsRegisterFlags_enum = 4;
pub const CUgraphicsRegisterFlags_enum_CU_GRAPHICS_REGISTER_FLAGS_TEXTURE_GATHER:
    CUgraphicsRegisterFlags_enum = 8;
/// Flags to register a graphics resource
pub type CUgraphicsRegisterFlags_enum = u32;
pub use self::CUgraphicsRegisterFlags_enum as CUgraphicsRegisterFlags;
pub const CUgraphicsMapResourceFlags_enum_CU_GRAPHICS_MAP_RESOURCE_FLAGS_NONE:
    CUgraphicsMapResourceFlags_enum = 0;
pub const CUgraphicsMapResourceFlags_enum_CU_GRAPHICS_MAP_RESOURCE_FLAGS_READ_ONLY:
    CUgraphicsMapResourceFlags_enum = 1;
pub const CUgraphicsMapResourceFlags_enum_CU_GRAPHICS_MAP_RESOURCE_FLAGS_WRITE_DISCARD:
    CUgraphicsMapResourceFlags_enum = 2;
/// Flags for mapping and unmapping interop resources
pub type CUgraphicsMapResourceFlags_enum = u32;
pub use self::CUgraphicsMapResourceFlags_enum as CUgraphicsMapResourceFlags;
///< Positive X face of cubemap
pub const CUarray_cubemap_face_enum_CU_CUBEMAP_FACE_POSITIVE_X: CUarray_cubemap_face_enum = 0;
///< Negative X face of cubemap
pub const CUarray_cubemap_face_enum_CU_CUBEMAP_FACE_NEGATIVE_X: CUarray_cubemap_face_enum = 1;
///< Positive Y face of cubemap
pub const CUarray_cubemap_face_enum_CU_CUBEMAP_FACE_POSITIVE_Y: CUarray_cubemap_face_enum = 2;
///< Negative Y face of cubemap
pub const CUarray_cubemap_face_enum_CU_CUBEMAP_FACE_NEGATIVE_Y: CUarray_cubemap_face_enum = 3;
///< Positive Z face of cubemap
pub const CUarray_cubemap_face_enum_CU_CUBEMAP_FACE_POSITIVE_Z: CUarray_cubemap_face_enum = 4;
///< Negative Z face of cubemap
pub const CUarray_cubemap_face_enum_CU_CUBEMAP_FACE_NEGATIVE_Z: CUarray_cubemap_face_enum = 5;
/// Array indices for cube faces
pub type CUarray_cubemap_face_enum = u32;
pub use self::CUarray_cubemap_face_enum as CUarray_cubemap_face;
///< GPU thread stack size
pub const CUlimit_enum_CU_LIMIT_STACK_SIZE: CUlimit_enum = 0;
///< GPU printf FIFO size
pub const CUlimit_enum_CU_LIMIT_PRINTF_FIFO_SIZE: CUlimit_enum = 1;
///< GPU malloc heap size
pub const CUlimit_enum_CU_LIMIT_MALLOC_HEAP_SIZE: CUlimit_enum = 2;
///< GPU device runtime launch synchronize depth
pub const CUlimit_enum_CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH: CUlimit_enum = 3;
///< GPU device runtime pending launch count
pub const CUlimit_enum_CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT: CUlimit_enum = 4;
///< A value between 0 and 128 that indicates the maximum fetch granularity of L2 (in Bytes). This is a hint
pub const CUlimit_enum_CU_LIMIT_MAX_L2_FETCH_GRANULARITY: CUlimit_enum = 5;
pub const CUlimit_enum_CU_LIMIT_MAX: CUlimit_enum = 6;
/// Limits
pub type CUlimit_enum = u32;
pub use self::CUlimit_enum as CUlimit;
///< Array resoure
pub const CUresourcetype_enum_CU_RESOURCE_TYPE_ARRAY: CUresourcetype_enum = 0;
///< Mipmapped array resource
pub const CUresourcetype_enum_CU_RESOURCE_TYPE_MIPMAPPED_ARRAY: CUresourcetype_enum = 1;
///< Linear resource
pub const CUresourcetype_enum_CU_RESOURCE_TYPE_LINEAR: CUresourcetype_enum = 2;
///< Pitch 2D resource
pub const CUresourcetype_enum_CU_RESOURCE_TYPE_PITCH2D: CUresourcetype_enum = 3;
/// Resource types
pub type CUresourcetype_enum = u32;
pub use self::CUresourcetype_enum as CUresourcetype;
/// CUDA host function
/// \param userData Argument value passed to the function
pub type CUhostFn =
    ::std::option::Option<unsafe extern "C" fn(userData: *mut ::std::os::raw::c_void)>;
/// GPU kernel node parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_KERNEL_NODE_PARAMS_st {
    ///< Kernel to launch
    pub func: CUfunction,
    ///< Width of grid in blocks
    pub gridDimX: ::std::os::raw::c_uint,
    ///< Height of grid in blocks
    pub gridDimY: ::std::os::raw::c_uint,
    ///< Depth of grid in blocks
    pub gridDimZ: ::std::os::raw::c_uint,
    ///< X dimension of each thread block
    pub blockDimX: ::std::os::raw::c_uint,
    ///< Y dimension of each thread block
    pub blockDimY: ::std::os::raw::c_uint,
    ///< Z dimension of each thread block
    pub blockDimZ: ::std::os::raw::c_uint,
    ///< Dynamic shared-memory size per thread block in bytes
    pub sharedMemBytes: ::std::os::raw::c_uint,
    ///< Array of pointers to kernel parameters
    pub kernelParams: *mut *mut ::std::os::raw::c_void,
    ///< Extra options
    pub extra: *mut *mut ::std::os::raw::c_void,
}
#[test]
fn bindgen_test_layout_CUDA_KERNEL_NODE_PARAMS_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_KERNEL_NODE_PARAMS_st>(),
        56usize,
        concat!("Size of: ", stringify!(CUDA_KERNEL_NODE_PARAMS_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_KERNEL_NODE_PARAMS_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_KERNEL_NODE_PARAMS_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).func as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(func)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).gridDimX as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(gridDimX)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).gridDimY as *const _ as usize
        },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(gridDimY)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).gridDimZ as *const _ as usize
        },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(gridDimZ)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).blockDimX as *const _ as usize
        },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(blockDimX)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).blockDimY as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(blockDimY)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).blockDimZ as *const _ as usize
        },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(blockDimZ)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).sharedMemBytes as *const _
                as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(sharedMemBytes)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).kernelParams as *const _ as usize
        },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(kernelParams)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_KERNEL_NODE_PARAMS_st>())).extra as *const _ as usize
        },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_KERNEL_NODE_PARAMS_st),
            "::",
            stringify!(extra)
        )
    );
}
pub type CUDA_KERNEL_NODE_PARAMS = CUDA_KERNEL_NODE_PARAMS_st;
/// Memset node parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_MEMSET_NODE_PARAMS_st {
    ///< Destination device pointer
    pub dst: CUdeviceptr,
    ///< Pitch of destination device pointer. Unused if height is 1
    pub pitch: usize,
    ///< Value to be set
    pub value: ::std::os::raw::c_uint,
    ///< Size of each element in bytes. Must be 1, 2, or 4.
    pub elementSize: ::std::os::raw::c_uint,
    ///< Width in bytes, of the row
    pub width: usize,
    ///< Number of rows
    pub height: usize,
}
#[test]
fn bindgen_test_layout_CUDA_MEMSET_NODE_PARAMS_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_MEMSET_NODE_PARAMS_st>(),
        40usize,
        concat!("Size of: ", stringify!(CUDA_MEMSET_NODE_PARAMS_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_MEMSET_NODE_PARAMS_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_MEMSET_NODE_PARAMS_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMSET_NODE_PARAMS_st>())).dst as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMSET_NODE_PARAMS_st),
            "::",
            stringify!(dst)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMSET_NODE_PARAMS_st>())).pitch as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMSET_NODE_PARAMS_st),
            "::",
            stringify!(pitch)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMSET_NODE_PARAMS_st>())).value as *const _ as usize
        },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMSET_NODE_PARAMS_st),
            "::",
            stringify!(value)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMSET_NODE_PARAMS_st>())).elementSize as *const _ as usize
        },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMSET_NODE_PARAMS_st),
            "::",
            stringify!(elementSize)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMSET_NODE_PARAMS_st>())).width as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMSET_NODE_PARAMS_st),
            "::",
            stringify!(width)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMSET_NODE_PARAMS_st>())).height as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMSET_NODE_PARAMS_st),
            "::",
            stringify!(height)
        )
    );
}
pub type CUDA_MEMSET_NODE_PARAMS = CUDA_MEMSET_NODE_PARAMS_st;
/// Host node parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_HOST_NODE_PARAMS_st {
    ///< The function to call when the node executes
    pub fn_: CUhostFn,
    ///< Argument to pass to the function
    pub userData: *mut ::std::os::raw::c_void,
}
#[test]
fn bindgen_test_layout_CUDA_HOST_NODE_PARAMS_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_HOST_NODE_PARAMS_st>(),
        16usize,
        concat!("Size of: ", stringify!(CUDA_HOST_NODE_PARAMS_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_HOST_NODE_PARAMS_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_HOST_NODE_PARAMS_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_HOST_NODE_PARAMS_st>())).fn_ as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_HOST_NODE_PARAMS_st),
            "::",
            stringify!(fn_)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_HOST_NODE_PARAMS_st>())).userData as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_HOST_NODE_PARAMS_st),
            "::",
            stringify!(userData)
        )
    );
}
pub type CUDA_HOST_NODE_PARAMS = CUDA_HOST_NODE_PARAMS_st;
///< GPU kernel node
pub const CUgraphNodeType_enum_CU_GRAPH_NODE_TYPE_KERNEL: CUgraphNodeType_enum = 0;
///< Memcpy node
pub const CUgraphNodeType_enum_CU_GRAPH_NODE_TYPE_MEMCPY: CUgraphNodeType_enum = 1;
///< Memset node
pub const CUgraphNodeType_enum_CU_GRAPH_NODE_TYPE_MEMSET: CUgraphNodeType_enum = 2;
///< Host (executable) node
pub const CUgraphNodeType_enum_CU_GRAPH_NODE_TYPE_HOST: CUgraphNodeType_enum = 3;
///< Node which executes an embedded graph
pub const CUgraphNodeType_enum_CU_GRAPH_NODE_TYPE_GRAPH: CUgraphNodeType_enum = 4;
///< Empty (no-op) node
pub const CUgraphNodeType_enum_CU_GRAPH_NODE_TYPE_EMPTY: CUgraphNodeType_enum = 5;
pub const CUgraphNodeType_enum_CU_GRAPH_NODE_TYPE_COUNT: CUgraphNodeType_enum = 6;
/// Graph node types
pub type CUgraphNodeType_enum = u32;
pub use self::CUgraphNodeType_enum as CUgraphNodeType;
///< Stream is not capturing
pub const CUstreamCaptureStatus_enum_CU_STREAM_CAPTURE_STATUS_NONE: CUstreamCaptureStatus_enum = 0;
///< Stream is actively capturing
pub const CUstreamCaptureStatus_enum_CU_STREAM_CAPTURE_STATUS_ACTIVE: CUstreamCaptureStatus_enum =
    1;
///< Stream is part of a capture sequence that
///has been invalidated, but not terminated
pub const CUstreamCaptureStatus_enum_CU_STREAM_CAPTURE_STATUS_INVALIDATED:
    CUstreamCaptureStatus_enum = 2;
/// Possible stream capture statuses returned by ::cuStreamIsCapturing
pub type CUstreamCaptureStatus_enum = u32;
pub use self::CUstreamCaptureStatus_enum as CUstreamCaptureStatus;
/// The API call returned with no errors. In the case of query calls, this
/// also means that the operation being queried is complete (see
/// ::cuEventQuery() and ::cuStreamQuery()).
pub const cudaError_enum_CUDA_SUCCESS: cudaError_enum = 0;
/// This indicates that one or more of the parameters passed to the API call
/// is not within an acceptable range of values.
pub const cudaError_enum_CUDA_ERROR_INVALID_VALUE: cudaError_enum = 1;
/// The API call failed because it was unable to allocate enough memory to
/// perform the requested operation.
pub const cudaError_enum_CUDA_ERROR_OUT_OF_MEMORY: cudaError_enum = 2;
/// This indicates that the CUDA driver has not been initialized with
/// ::cuInit() or that initialization has failed.
pub const cudaError_enum_CUDA_ERROR_NOT_INITIALIZED: cudaError_enum = 3;
/// This indicates that the CUDA driver is in the process of shutting down.
pub const cudaError_enum_CUDA_ERROR_DEINITIALIZED: cudaError_enum = 4;
/// This indicates profiler is not initialized for this run. This can
/// happen when the application is running with external profiling tools
/// like visual profiler.
pub const cudaError_enum_CUDA_ERROR_PROFILER_DISABLED: cudaError_enum = 5;
/// \deprecated
/// This error return is deprecated as of CUDA 5.0. It is no longer an error
/// to attempt to enable/disable the profiling via ::cuProfilerStart or
/// ::cuProfilerStop without initialization.
pub const cudaError_enum_CUDA_ERROR_PROFILER_NOT_INITIALIZED: cudaError_enum = 6;
/// \deprecated
/// This error return is deprecated as of CUDA 5.0. It is no longer an error
/// to call cuProfilerStart() when profiling is already enabled.
pub const cudaError_enum_CUDA_ERROR_PROFILER_ALREADY_STARTED: cudaError_enum = 7;
/// \deprecated
/// This error return is deprecated as of CUDA 5.0. It is no longer an error
/// to call cuProfilerStop() when profiling is already disabled.
pub const cudaError_enum_CUDA_ERROR_PROFILER_ALREADY_STOPPED: cudaError_enum = 8;
/// This indicates that no CUDA-capable devices were detected by the installed
/// CUDA driver.
pub const cudaError_enum_CUDA_ERROR_NO_DEVICE: cudaError_enum = 100;
/// This indicates that the device ordinal supplied by the user does not
/// correspond to a valid CUDA device.
pub const cudaError_enum_CUDA_ERROR_INVALID_DEVICE: cudaError_enum = 101;
/// This indicates that the device kernel image is invalid. This can also
/// indicate an invalid CUDA module.
pub const cudaError_enum_CUDA_ERROR_INVALID_IMAGE: cudaError_enum = 200;
/// This most frequently indicates that there is no context bound to the
/// current thread. This can also be returned if the context passed to an
/// API call is not a valid handle (such as a context that has had
/// ::cuCtxDestroy() invoked on it). This can also be returned if a user
/// mixes different API versions (i.e. 3010 context with 3020 API calls).
/// See ::cuCtxGetApiVersion() for more details.
pub const cudaError_enum_CUDA_ERROR_INVALID_CONTEXT: cudaError_enum = 201;
/// This indicated that the context being supplied as a parameter to the
/// API call was already the active context.
/// \deprecated
/// This error return is deprecated as of CUDA 3.2. It is no longer an
/// error to attempt to push the active context via ::cuCtxPushCurrent().
pub const cudaError_enum_CUDA_ERROR_CONTEXT_ALREADY_CURRENT: cudaError_enum = 202;
/// This indicates that a map or register operation has failed.
pub const cudaError_enum_CUDA_ERROR_MAP_FAILED: cudaError_enum = 205;
/// This indicates that an unmap or unregister operation has failed.
pub const cudaError_enum_CUDA_ERROR_UNMAP_FAILED: cudaError_enum = 206;
/// This indicates that the specified array is currently mapped and thus
/// cannot be destroyed.
pub const cudaError_enum_CUDA_ERROR_ARRAY_IS_MAPPED: cudaError_enum = 207;
/// This indicates that the resource is already mapped.
pub const cudaError_enum_CUDA_ERROR_ALREADY_MAPPED: cudaError_enum = 208;
/// This indicates that there is no kernel image available that is suitable
/// for the device. This can occur when a user specifies code generation
/// options for a particular CUDA source file that do not include the
/// corresponding device configuration.
pub const cudaError_enum_CUDA_ERROR_NO_BINARY_FOR_GPU: cudaError_enum = 209;
/// This indicates that a resource has already been acquired.
pub const cudaError_enum_CUDA_ERROR_ALREADY_ACQUIRED: cudaError_enum = 210;
/// This indicates that a resource is not mapped.
pub const cudaError_enum_CUDA_ERROR_NOT_MAPPED: cudaError_enum = 211;
/// This indicates that a mapped resource is not available for access as an
/// array.
pub const cudaError_enum_CUDA_ERROR_NOT_MAPPED_AS_ARRAY: cudaError_enum = 212;
/// This indicates that a mapped resource is not available for access as a
/// pointer.
pub const cudaError_enum_CUDA_ERROR_NOT_MAPPED_AS_POINTER: cudaError_enum = 213;
/// This indicates that an uncorrectable ECC error was detected during
/// execution.
pub const cudaError_enum_CUDA_ERROR_ECC_UNCORRECTABLE: cudaError_enum = 214;
/// This indicates that the ::CUlimit passed to the API call is not
/// supported by the active device.
pub const cudaError_enum_CUDA_ERROR_UNSUPPORTED_LIMIT: cudaError_enum = 215;
/// This indicates that the ::CUcontext passed to the API call can
/// only be bound to a single CPU thread at a time but is already
/// bound to a CPU thread.
pub const cudaError_enum_CUDA_ERROR_CONTEXT_ALREADY_IN_USE: cudaError_enum = 216;
/// This indicates that peer access is not supported across the given
/// devices.
pub const cudaError_enum_CUDA_ERROR_PEER_ACCESS_UNSUPPORTED: cudaError_enum = 217;
/// This indicates that a PTX JIT compilation failed.
pub const cudaError_enum_CUDA_ERROR_INVALID_PTX: cudaError_enum = 218;
/// This indicates an error with OpenGL or DirectX context.
pub const cudaError_enum_CUDA_ERROR_INVALID_GRAPHICS_CONTEXT: cudaError_enum = 219;
/// This indicates that an uncorrectable NVLink error was detected during the
/// execution.
pub const cudaError_enum_CUDA_ERROR_NVLINK_UNCORRECTABLE: cudaError_enum = 220;
/// This indicates that the PTX JIT compiler library was not found.
pub const cudaError_enum_CUDA_ERROR_JIT_COMPILER_NOT_FOUND: cudaError_enum = 221;
/// This indicates that the device kernel source is invalid.
pub const cudaError_enum_CUDA_ERROR_INVALID_SOURCE: cudaError_enum = 300;
/// This indicates that the file specified was not found.
pub const cudaError_enum_CUDA_ERROR_FILE_NOT_FOUND: cudaError_enum = 301;
/// This indicates that a link to a shared object failed to resolve.
pub const cudaError_enum_CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND: cudaError_enum = 302;
/// This indicates that initialization of a shared object failed.
pub const cudaError_enum_CUDA_ERROR_SHARED_OBJECT_INIT_FAILED: cudaError_enum = 303;
/// This indicates that an OS call failed.
pub const cudaError_enum_CUDA_ERROR_OPERATING_SYSTEM: cudaError_enum = 304;
/// This indicates that a resource handle passed to the API call was not
/// valid. Resource handles are opaque types like ::CUstream and ::CUevent.
pub const cudaError_enum_CUDA_ERROR_INVALID_HANDLE: cudaError_enum = 400;
/// This indicates that a resource required by the API call is not in a
/// valid state to perform the requested operation.
pub const cudaError_enum_CUDA_ERROR_ILLEGAL_STATE: cudaError_enum = 401;
/// This indicates that a named symbol was not found. Examples of symbols
/// are global/constant variable names, texture names, and surface names.
pub const cudaError_enum_CUDA_ERROR_NOT_FOUND: cudaError_enum = 500;
/// This indicates that asynchronous operations issued previously have not
/// completed yet. This result is not actually an error, but must be indicated
/// differently than ::CUDA_SUCCESS (which indicates completion). Calls that
/// may return this value include ::cuEventQuery() and ::cuStreamQuery().
pub const cudaError_enum_CUDA_ERROR_NOT_READY: cudaError_enum = 600;
/// While executing a kernel, the device encountered a
/// load or store instruction on an invalid memory address.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_ILLEGAL_ADDRESS: cudaError_enum = 700;
/// This indicates that a launch did not occur because it did not have
/// appropriate resources. This error usually indicates that the user has
/// attempted to pass too many arguments to the device kernel, or the
/// kernel launch specifies too many threads for the kernel's register
/// count. Passing arguments of the wrong size (i.e. a 64-bit pointer
/// when a 32-bit int is expected) is equivalent to passing too many
/// arguments and can also result in this error.
pub const cudaError_enum_CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES: cudaError_enum = 701;
/// This indicates that the device kernel took too long to execute. This can
/// only occur if timeouts are enabled - see the device attribute
/// ::CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT for more information.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_LAUNCH_TIMEOUT: cudaError_enum = 702;
/// This error indicates a kernel launch that uses an incompatible texturing
/// mode.
pub const cudaError_enum_CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING: cudaError_enum = 703;
/// This error indicates that a call to ::cuCtxEnablePeerAccess() is
/// trying to re-enable peer access to a context which has already
/// had peer access to it enabled.
pub const cudaError_enum_CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED: cudaError_enum = 704;
/// This error indicates that ::cuCtxDisablePeerAccess() is
/// trying to disable peer access which has not been enabled yet
/// via ::cuCtxEnablePeerAccess().
pub const cudaError_enum_CUDA_ERROR_PEER_ACCESS_NOT_ENABLED: cudaError_enum = 705;
/// This error indicates that the primary context for the specified device
/// has already been initialized.
pub const cudaError_enum_CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE: cudaError_enum = 708;
/// This error indicates that the context current to the calling thread
/// has been destroyed using ::cuCtxDestroy, or is a primary context which
/// has not yet been initialized.
pub const cudaError_enum_CUDA_ERROR_CONTEXT_IS_DESTROYED: cudaError_enum = 709;
/// A device-side assert triggered during kernel execution. The context
/// cannot be used anymore, and must be destroyed. All existing device
/// memory allocations from this context are invalid and must be
/// reconstructed if the program is to continue using CUDA.
pub const cudaError_enum_CUDA_ERROR_ASSERT: cudaError_enum = 710;
/// This error indicates that the hardware resources required to enable
/// peer access have been exhausted for one or more of the devices
/// passed to ::cuCtxEnablePeerAccess().
pub const cudaError_enum_CUDA_ERROR_TOO_MANY_PEERS: cudaError_enum = 711;
/// This error indicates that the memory range passed to ::cuMemHostRegister()
/// has already been registered.
pub const cudaError_enum_CUDA_ERROR_HOST_MEMORY_ALREADY_REGISTERED: cudaError_enum = 712;
/// This error indicates that the pointer passed to ::cuMemHostUnregister()
/// does not correspond to any currently registered memory region.
pub const cudaError_enum_CUDA_ERROR_HOST_MEMORY_NOT_REGISTERED: cudaError_enum = 713;
/// While executing a kernel, the device encountered a stack error.
/// This can be due to stack corruption or exceeding the stack size limit.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_HARDWARE_STACK_ERROR: cudaError_enum = 714;
/// While executing a kernel, the device encountered an illegal instruction.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_ILLEGAL_INSTRUCTION: cudaError_enum = 715;
/// While executing a kernel, the device encountered a load or store instruction
/// on a memory address which is not aligned.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_MISALIGNED_ADDRESS: cudaError_enum = 716;
/// While executing a kernel, the device encountered an instruction
/// which can only operate on memory locations in certain address spaces
/// (global, shared, or local), but was supplied a memory address not
/// belonging to an allowed address space.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_INVALID_ADDRESS_SPACE: cudaError_enum = 717;
/// While executing a kernel, the device program counter wrapped its address space.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_INVALID_PC: cudaError_enum = 718;
/// An exception occurred on the device while executing a kernel. Common
/// causes include dereferencing an invalid device pointer and accessing
/// out of bounds shared memory.
/// This leaves the process in an inconsistent state and any further CUDA work
/// will return the same error. To continue using CUDA, the process must be terminated
/// and relaunched.
pub const cudaError_enum_CUDA_ERROR_LAUNCH_FAILED: cudaError_enum = 719;
/// This error indicates that the number of blocks launched per grid for a kernel that was
/// launched via either ::cuLaunchCooperativeKernel or ::cuLaunchCooperativeKernelMultiDevice
/// exceeds the maximum number of blocks as allowed by ::cuOccupancyMaxActiveBlocksPerMultiprocessor
/// or ::cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags times the number of multiprocessors
/// as specified by the device attribute ::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT.
pub const cudaError_enum_CUDA_ERROR_COOPERATIVE_LAUNCH_TOO_LARGE: cudaError_enum = 720;
/// This error indicates that the attempted operation is not permitted.
pub const cudaError_enum_CUDA_ERROR_NOT_PERMITTED: cudaError_enum = 800;
/// This error indicates that the attempted operation is not supported
/// on the current system or device.
pub const cudaError_enum_CUDA_ERROR_NOT_SUPPORTED: cudaError_enum = 801;
/// This error indicates that the system is not yet ready to start any CUDA
/// work.  To continue using CUDA, verify the system configuration is in a
/// valid state and all required driver daemons are actively running.
pub const cudaError_enum_CUDA_ERROR_SYSTEM_NOT_READY: cudaError_enum = 802;
/// This error indicates that the operation is not permitted when
/// the stream is capturing.
pub const cudaError_enum_CUDA_ERROR_STREAM_CAPTURE_UNSUPPORTED: cudaError_enum = 900;
/// This error indicates that the current capture sequence on the stream
/// has been invalidated due to a previous error.
pub const cudaError_enum_CUDA_ERROR_STREAM_CAPTURE_INVALIDATED: cudaError_enum = 901;
/// This error indicates that the operation would have resulted in a merge
/// of two independent capture sequences.
pub const cudaError_enum_CUDA_ERROR_STREAM_CAPTURE_MERGE: cudaError_enum = 902;
/// This error indicates that the capture was not initiated in this stream.
pub const cudaError_enum_CUDA_ERROR_STREAM_CAPTURE_UNMATCHED: cudaError_enum = 903;
/// This error indicates that the capture sequence contains a fork that was
/// not joined to the primary stream.
pub const cudaError_enum_CUDA_ERROR_STREAM_CAPTURE_UNJOINED: cudaError_enum = 904;
/// This error indicates that a dependency would have been created which
/// crosses the capture sequence boundary. Only implicit in-stream ordering
/// dependencies are allowed to cross the boundary.
pub const cudaError_enum_CUDA_ERROR_STREAM_CAPTURE_ISOLATION: cudaError_enum = 905;
/// This error indicates a disallowed implicit dependency on a current capture
/// sequence from cudaStreamLegacy.
pub const cudaError_enum_CUDA_ERROR_STREAM_CAPTURE_IMPLICIT: cudaError_enum = 906;
/// This error indicates that the operation is not permitted on an event which
/// was last recorded in a capturing stream.
pub const cudaError_enum_CUDA_ERROR_CAPTURED_EVENT: cudaError_enum = 907;
/// This indicates that an unknown internal error has occurred.
pub const cudaError_enum_CUDA_ERROR_UNKNOWN: cudaError_enum = 999;
/// Error codes
pub type cudaError_enum = u32;
pub use self::cudaError_enum as CUresult;
///< A relative value indicating the performance of the link between two devices
pub const CUdevice_P2PAttribute_enum_CU_DEVICE_P2P_ATTRIBUTE_PERFORMANCE_RANK:
    CUdevice_P2PAttribute_enum = 1;
///< P2P Access is enable
pub const CUdevice_P2PAttribute_enum_CU_DEVICE_P2P_ATTRIBUTE_ACCESS_SUPPORTED:
    CUdevice_P2PAttribute_enum = 2;
///< Atomic operation over the link supported
pub const CUdevice_P2PAttribute_enum_CU_DEVICE_P2P_ATTRIBUTE_NATIVE_ATOMIC_SUPPORTED:
    CUdevice_P2PAttribute_enum = 3;
///< \deprecated use CU_DEVICE_P2P_ATTRIBUTE_CUDA_ARRAY_ACCESS_SUPPORTED instead
pub const CUdevice_P2PAttribute_enum_CU_DEVICE_P2P_ATTRIBUTE_ARRAY_ACCESS_ACCESS_SUPPORTED:
    CUdevice_P2PAttribute_enum = 4;
///< Accessing CUDA arrays over the link supported
pub const CUdevice_P2PAttribute_enum_CU_DEVICE_P2P_ATTRIBUTE_CUDA_ARRAY_ACCESS_SUPPORTED:
    CUdevice_P2PAttribute_enum = 4;
/// P2P Attributes
pub type CUdevice_P2PAttribute_enum = u32;
pub use self::CUdevice_P2PAttribute_enum as CUdevice_P2PAttribute;
/// CUDA stream callback
/// \param hStream The stream the callback was added to, as passed to ::cuStreamAddCallback.  May be NULL.
/// \param status ::CUDA_SUCCESS or any persistent error on the stream.
/// \param userData User parameter provided at registration.
pub type CUstreamCallback = ::std::option::Option<
    unsafe extern "C" fn(
        hStream: CUstream,
        status: CUresult,
        userData: *mut ::std::os::raw::c_void,
    ),
>;
/// Block size to per-block dynamic shared memory mapping for a certain
/// kernel \param blockSize Block size of the kernel.
///
/// \return The dynamic shared memory needed by a block.
pub type CUoccupancyB2DSize =
    ::std::option::Option<unsafe extern "C" fn(blockSize: ::std::os::raw::c_int) -> usize>;
/// 2D memory copy parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_MEMCPY2D_st {
    ///< Source X in bytes
    pub srcXInBytes: usize,
    ///< Source Y
    pub srcY: usize,
    ///< Source memory type (host, device, array)
    pub srcMemoryType: CUmemorytype,
    ///< Source host pointer
    pub srcHost: *const ::std::os::raw::c_void,
    ///< Source device pointer
    pub srcDevice: CUdeviceptr,
    ///< Source array reference
    pub srcArray: CUarray,
    ///< Source pitch (ignored when src is array)
    pub srcPitch: usize,
    ///< Destination X in bytes
    pub dstXInBytes: usize,
    ///< Destination Y
    pub dstY: usize,
    ///< Destination memory type (host, device, array)
    pub dstMemoryType: CUmemorytype,
    ///< Destination host pointer
    pub dstHost: *mut ::std::os::raw::c_void,
    ///< Destination device pointer
    pub dstDevice: CUdeviceptr,
    ///< Destination array reference
    pub dstArray: CUarray,
    ///< Destination pitch (ignored when dst is array)
    pub dstPitch: usize,
    ///< Width of 2D memory copy in bytes
    pub WidthInBytes: usize,
    ///< Height of 2D memory copy
    pub Height: usize,
}
#[test]
fn bindgen_test_layout_CUDA_MEMCPY2D_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_MEMCPY2D_st>(),
        128usize,
        concat!("Size of: ", stringify!(CUDA_MEMCPY2D_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_MEMCPY2D_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_MEMCPY2D_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).srcXInBytes as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(srcXInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).srcY as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(srcY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).srcMemoryType as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(srcMemoryType)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).srcHost as *const _ as usize },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(srcHost)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).srcDevice as *const _ as usize },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(srcDevice)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).srcArray as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(srcArray)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).srcPitch as *const _ as usize },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(srcPitch)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).dstXInBytes as *const _ as usize },
        56usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(dstXInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).dstY as *const _ as usize },
        64usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(dstY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).dstMemoryType as *const _ as usize },
        72usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(dstMemoryType)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).dstHost as *const _ as usize },
        80usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(dstHost)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).dstDevice as *const _ as usize },
        88usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(dstDevice)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).dstArray as *const _ as usize },
        96usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(dstArray)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).dstPitch as *const _ as usize },
        104usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(dstPitch)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).WidthInBytes as *const _ as usize },
        112usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(WidthInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY2D_st>())).Height as *const _ as usize },
        120usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY2D_st),
            "::",
            stringify!(Height)
        )
    );
}
pub type CUDA_MEMCPY2D = CUDA_MEMCPY2D_st;
/// 3D memory copy parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_MEMCPY3D_st {
    ///< Source X in bytes
    pub srcXInBytes: usize,
    ///< Source Y
    pub srcY: usize,
    ///< Source Z
    pub srcZ: usize,
    ///< Source LOD
    pub srcLOD: usize,
    ///< Source memory type (host, device, array)
    pub srcMemoryType: CUmemorytype,
    ///< Source host pointer
    pub srcHost: *const ::std::os::raw::c_void,
    ///< Source device pointer
    pub srcDevice: CUdeviceptr,
    ///< Source array reference
    pub srcArray: CUarray,
    ///< Must be NULL
    pub reserved0: *mut ::std::os::raw::c_void,
    ///< Source pitch (ignored when src is array)
    pub srcPitch: usize,
    ///< Source height (ignored when src is array; may be 0 if Depth==1)
    pub srcHeight: usize,
    ///< Destination X in bytes
    pub dstXInBytes: usize,
    ///< Destination Y
    pub dstY: usize,
    ///< Destination Z
    pub dstZ: usize,
    ///< Destination LOD
    pub dstLOD: usize,
    ///< Destination memory type (host, device, array)
    pub dstMemoryType: CUmemorytype,
    ///< Destination host pointer
    pub dstHost: *mut ::std::os::raw::c_void,
    ///< Destination device pointer
    pub dstDevice: CUdeviceptr,
    ///< Destination array reference
    pub dstArray: CUarray,
    ///< Must be NULL
    pub reserved1: *mut ::std::os::raw::c_void,
    ///< Destination pitch (ignored when dst is array)
    pub dstPitch: usize,
    ///< Destination height (ignored when dst is array; may be 0 if Depth==1)
    pub dstHeight: usize,
    ///< Width of 3D memory copy in bytes
    pub WidthInBytes: usize,
    ///< Height of 3D memory copy
    pub Height: usize,
    ///< Depth of 3D memory copy
    pub Depth: usize,
}
#[test]
fn bindgen_test_layout_CUDA_MEMCPY3D_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_MEMCPY3D_st>(),
        200usize,
        concat!("Size of: ", stringify!(CUDA_MEMCPY3D_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_MEMCPY3D_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_MEMCPY3D_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcXInBytes as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcXInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcY as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcZ as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcZ)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcLOD as *const _ as usize },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcLOD)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcMemoryType as *const _ as usize },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcMemoryType)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcHost as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcHost)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcDevice as *const _ as usize },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcDevice)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcArray as *const _ as usize },
        56usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcArray)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).reserved0 as *const _ as usize },
        64usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(reserved0)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcPitch as *const _ as usize },
        72usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcPitch)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).srcHeight as *const _ as usize },
        80usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(srcHeight)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstXInBytes as *const _ as usize },
        88usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstXInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstY as *const _ as usize },
        96usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstZ as *const _ as usize },
        104usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstZ)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstLOD as *const _ as usize },
        112usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstLOD)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstMemoryType as *const _ as usize },
        120usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstMemoryType)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstHost as *const _ as usize },
        128usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstHost)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstDevice as *const _ as usize },
        136usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstDevice)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstArray as *const _ as usize },
        144usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstArray)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).reserved1 as *const _ as usize },
        152usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(reserved1)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstPitch as *const _ as usize },
        160usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstPitch)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).dstHeight as *const _ as usize },
        168usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(dstHeight)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).WidthInBytes as *const _ as usize },
        176usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(WidthInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).Height as *const _ as usize },
        184usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(Height)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_st>())).Depth as *const _ as usize },
        192usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_st),
            "::",
            stringify!(Depth)
        )
    );
}
pub type CUDA_MEMCPY3D = CUDA_MEMCPY3D_st;
/// 3D memory cross-context copy parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_MEMCPY3D_PEER_st {
    ///< Source X in bytes
    pub srcXInBytes: usize,
    ///< Source Y
    pub srcY: usize,
    ///< Source Z
    pub srcZ: usize,
    ///< Source LOD
    pub srcLOD: usize,
    ///< Source memory type (host, device, array)
    pub srcMemoryType: CUmemorytype,
    ///< Source host pointer
    pub srcHost: *const ::std::os::raw::c_void,
    ///< Source device pointer
    pub srcDevice: CUdeviceptr,
    ///< Source array reference
    pub srcArray: CUarray,
    ///< Source context (ignored with srcMemoryType is ::CU_MEMORYTYPE_ARRAY)
    pub srcContext: CUcontext,
    ///< Source pitch (ignored when src is array)
    pub srcPitch: usize,
    ///< Source height (ignored when src is array; may be 0 if Depth==1)
    pub srcHeight: usize,
    ///< Destination X in bytes
    pub dstXInBytes: usize,
    ///< Destination Y
    pub dstY: usize,
    ///< Destination Z
    pub dstZ: usize,
    ///< Destination LOD
    pub dstLOD: usize,
    ///< Destination memory type (host, device, array)
    pub dstMemoryType: CUmemorytype,
    ///< Destination host pointer
    pub dstHost: *mut ::std::os::raw::c_void,
    ///< Destination device pointer
    pub dstDevice: CUdeviceptr,
    ///< Destination array reference
    pub dstArray: CUarray,
    ///< Destination context (ignored with dstMemoryType is ::CU_MEMORYTYPE_ARRAY)
    pub dstContext: CUcontext,
    ///< Destination pitch (ignored when dst is array)
    pub dstPitch: usize,
    ///< Destination height (ignored when dst is array; may be 0 if Depth==1)
    pub dstHeight: usize,
    ///< Width of 3D memory copy in bytes
    pub WidthInBytes: usize,
    ///< Height of 3D memory copy
    pub Height: usize,
    ///< Depth of 3D memory copy
    pub Depth: usize,
}
#[test]
fn bindgen_test_layout_CUDA_MEMCPY3D_PEER_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_MEMCPY3D_PEER_st>(),
        200usize,
        concat!("Size of: ", stringify!(CUDA_MEMCPY3D_PEER_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_MEMCPY3D_PEER_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_MEMCPY3D_PEER_st))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcXInBytes as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcXInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcY as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcZ as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcZ)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcLOD as *const _ as usize },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcLOD)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcMemoryType as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcMemoryType)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcHost as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcHost)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcDevice as *const _ as usize },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcDevice)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcArray as *const _ as usize },
        56usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcArray)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcContext as *const _ as usize
        },
        64usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcContext)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcPitch as *const _ as usize },
        72usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcPitch)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).srcHeight as *const _ as usize },
        80usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(srcHeight)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstXInBytes as *const _ as usize
        },
        88usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstXInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstY as *const _ as usize },
        96usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstZ as *const _ as usize },
        104usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstZ)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstLOD as *const _ as usize },
        112usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstLOD)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstMemoryType as *const _ as usize
        },
        120usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstMemoryType)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstHost as *const _ as usize },
        128usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstHost)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstDevice as *const _ as usize },
        136usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstDevice)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstArray as *const _ as usize },
        144usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstArray)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstContext as *const _ as usize
        },
        152usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstContext)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstPitch as *const _ as usize },
        160usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstPitch)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).dstHeight as *const _ as usize },
        168usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(dstHeight)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).WidthInBytes as *const _ as usize
        },
        176usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(WidthInBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).Height as *const _ as usize },
        184usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(Height)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_MEMCPY3D_PEER_st>())).Depth as *const _ as usize },
        192usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_MEMCPY3D_PEER_st),
            "::",
            stringify!(Depth)
        )
    );
}
pub type CUDA_MEMCPY3D_PEER = CUDA_MEMCPY3D_PEER_st;
/// Array descriptor
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_ARRAY_DESCRIPTOR_st {
    ///< Width of array
    pub Width: usize,
    ///< Height of array
    pub Height: usize,
    ///< Array format
    pub Format: CUarray_format,
    ///< Channels per array element
    pub NumChannels: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUDA_ARRAY_DESCRIPTOR_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_ARRAY_DESCRIPTOR_st>(),
        24usize,
        concat!("Size of: ", stringify!(CUDA_ARRAY_DESCRIPTOR_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_ARRAY_DESCRIPTOR_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_ARRAY_DESCRIPTOR_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_ARRAY_DESCRIPTOR_st>())).Width as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY_DESCRIPTOR_st),
            "::",
            stringify!(Width)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_ARRAY_DESCRIPTOR_st>())).Height as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY_DESCRIPTOR_st),
            "::",
            stringify!(Height)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_ARRAY_DESCRIPTOR_st>())).Format as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY_DESCRIPTOR_st),
            "::",
            stringify!(Format)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_ARRAY_DESCRIPTOR_st>())).NumChannels as *const _ as usize
        },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY_DESCRIPTOR_st),
            "::",
            stringify!(NumChannels)
        )
    );
}
pub type CUDA_ARRAY_DESCRIPTOR = CUDA_ARRAY_DESCRIPTOR_st;
/// 3D array descriptor
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_ARRAY3D_DESCRIPTOR_st {
    ///< Width of 3D array
    pub Width: usize,
    ///< Height of 3D array
    pub Height: usize,
    ///< Depth of 3D array
    pub Depth: usize,
    ///< Array format
    pub Format: CUarray_format,
    ///< Channels per array element
    pub NumChannels: ::std::os::raw::c_uint,
    ///< Flags
    pub Flags: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUDA_ARRAY3D_DESCRIPTOR_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_ARRAY3D_DESCRIPTOR_st>(),
        40usize,
        concat!("Size of: ", stringify!(CUDA_ARRAY3D_DESCRIPTOR_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_ARRAY3D_DESCRIPTOR_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_ARRAY3D_DESCRIPTOR_st))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_ARRAY3D_DESCRIPTOR_st>())).Width as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY3D_DESCRIPTOR_st),
            "::",
            stringify!(Width)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_ARRAY3D_DESCRIPTOR_st>())).Height as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY3D_DESCRIPTOR_st),
            "::",
            stringify!(Height)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_ARRAY3D_DESCRIPTOR_st>())).Depth as *const _ as usize
        },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY3D_DESCRIPTOR_st),
            "::",
            stringify!(Depth)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_ARRAY3D_DESCRIPTOR_st>())).Format as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY3D_DESCRIPTOR_st),
            "::",
            stringify!(Format)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_ARRAY3D_DESCRIPTOR_st>())).NumChannels as *const _ as usize
        },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY3D_DESCRIPTOR_st),
            "::",
            stringify!(NumChannels)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_ARRAY3D_DESCRIPTOR_st>())).Flags as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_ARRAY3D_DESCRIPTOR_st),
            "::",
            stringify!(Flags)
        )
    );
}
pub type CUDA_ARRAY3D_DESCRIPTOR = CUDA_ARRAY3D_DESCRIPTOR_st;
/// CUDA Resource descriptor
#[repr(C)]
#[derive(Copy, Clone)]
pub struct CUDA_RESOURCE_DESC_st {
    ///< Resource type
    pub resType: CUresourcetype,
    pub res: CUDA_RESOURCE_DESC_st__bindgen_ty_1,
    ///< Flags (must be zero)
    pub flags: ::std::os::raw::c_uint,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union CUDA_RESOURCE_DESC_st__bindgen_ty_1 {
    pub array: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1,
    pub mipmap: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2,
    pub linear: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3,
    pub pitch2D: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4,
    pub reserved: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5,
    _bindgen_union_align: [u64; 16usize],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1 {
    ///< CUDA array
    pub hArray: CUarray,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1>(),
        8usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1>())).hArray
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(hArray)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2 {
    ///< CUDA mipmapped array
    pub hMipmappedArray: CUmipmappedArray,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2>(),
        8usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2>()))
                .hMipmappedArray as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2),
            "::",
            stringify!(hMipmappedArray)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3 {
    ///< Device pointer
    pub devPtr: CUdeviceptr,
    ///< Array format
    pub format: CUarray_format,
    ///< Channels per array element
    pub numChannels: ::std::os::raw::c_uint,
    ///< Size in bytes
    pub sizeInBytes: usize,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>(),
        24usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>())).devPtr
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3),
            "::",
            stringify!(devPtr)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>())).format
                as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3),
            "::",
            stringify!(format)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>()))
                .numChannels as *const _ as usize
        },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3),
            "::",
            stringify!(numChannels)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>()))
                .sizeInBytes as *const _ as usize
        },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3),
            "::",
            stringify!(sizeInBytes)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4 {
    ///< Device pointer
    pub devPtr: CUdeviceptr,
    ///< Array format
    pub format: CUarray_format,
    ///< Channels per array element
    pub numChannels: ::std::os::raw::c_uint,
    ///< Width of the array in elements
    pub width: usize,
    ///< Height of the array in elements
    pub height: usize,
    ///< Pitch between two rows in bytes
    pub pitchInBytes: usize,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>(),
        40usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>())).devPtr
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4),
            "::",
            stringify!(devPtr)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>())).format
                as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4),
            "::",
            stringify!(format)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>()))
                .numChannels as *const _ as usize
        },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4),
            "::",
            stringify!(numChannels)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>())).width
                as *const _ as usize
        },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4),
            "::",
            stringify!(width)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>())).height
                as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4),
            "::",
            stringify!(height)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>()))
                .pitchInBytes as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4),
            "::",
            stringify!(pitchInBytes)
        )
    );
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5 {
    pub reserved: [::std::os::raw::c_int; 32usize],
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5>(),
        128usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5>(),
        4usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5>())).reserved
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5),
            "::",
            stringify!(reserved)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>(),
        128usize,
        concat!("Size of: ", stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>())).array as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(array)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>())).mipmap as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(mipmap)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>())).linear as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(linear)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>())).pitch2D as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(pitch2D)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>())).reserved as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(reserved)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_DESC_st>(),
        144usize,
        concat!("Size of: ", stringify!(CUDA_RESOURCE_DESC_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_DESC_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_RESOURCE_DESC_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st>())).resType as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st),
            "::",
            stringify!(resType)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st>())).res as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st),
            "::",
            stringify!(res)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_RESOURCE_DESC_st>())).flags as *const _ as usize },
        136usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_DESC_st),
            "::",
            stringify!(flags)
        )
    );
}
pub type CUDA_RESOURCE_DESC = CUDA_RESOURCE_DESC_st;
/// Texture descriptor
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_TEXTURE_DESC_st {
    ///< Address modes
    pub addressMode: [CUaddress_mode; 3usize],
    ///< Filter mode
    pub filterMode: CUfilter_mode,
    ///< Flags
    pub flags: ::std::os::raw::c_uint,
    ///< Maximum anisotropy ratio
    pub maxAnisotropy: ::std::os::raw::c_uint,
    ///< Mipmap filter mode
    pub mipmapFilterMode: CUfilter_mode,
    ///< Mipmap level bias
    pub mipmapLevelBias: f32,
    ///< Mipmap minimum level clamp
    pub minMipmapLevelClamp: f32,
    ///< Mipmap maximum level clamp
    pub maxMipmapLevelClamp: f32,
    ///< Border Color
    pub borderColor: [f32; 4usize],
    pub reserved: [::std::os::raw::c_int; 12usize],
}
#[test]
fn bindgen_test_layout_CUDA_TEXTURE_DESC_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_TEXTURE_DESC_st>(),
        104usize,
        concat!("Size of: ", stringify!(CUDA_TEXTURE_DESC_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_TEXTURE_DESC_st>(),
        4usize,
        concat!("Alignment of ", stringify!(CUDA_TEXTURE_DESC_st))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).addressMode as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(addressMode)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).filterMode as *const _ as usize },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(filterMode)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).flags as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).maxAnisotropy as *const _ as usize
        },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(maxAnisotropy)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).mipmapFilterMode as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(mipmapFilterMode)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).mipmapLevelBias as *const _ as usize
        },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(mipmapLevelBias)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).minMipmapLevelClamp as *const _
                as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(minMipmapLevelClamp)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).maxMipmapLevelClamp as *const _
                as usize
        },
        36usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(maxMipmapLevelClamp)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).borderColor as *const _ as usize
        },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(borderColor)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_TEXTURE_DESC_st>())).reserved as *const _ as usize },
        56usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_TEXTURE_DESC_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_TEXTURE_DESC = CUDA_TEXTURE_DESC_st;
///< No resource view format (use underlying resource format)
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_NONE: CUresourceViewFormat_enum = 0;
///< 1 channel unsigned 8-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_1X8: CUresourceViewFormat_enum = 1;
///< 2 channel unsigned 8-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_2X8: CUresourceViewFormat_enum = 2;
///< 4 channel unsigned 8-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_4X8: CUresourceViewFormat_enum = 3;
///< 1 channel signed 8-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_1X8: CUresourceViewFormat_enum = 4;
///< 2 channel signed 8-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_2X8: CUresourceViewFormat_enum = 5;
///< 4 channel signed 8-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_4X8: CUresourceViewFormat_enum = 6;
///< 1 channel unsigned 16-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_1X16: CUresourceViewFormat_enum = 7;
///< 2 channel unsigned 16-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_2X16: CUresourceViewFormat_enum = 8;
///< 4 channel unsigned 16-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_4X16: CUresourceViewFormat_enum = 9;
///< 1 channel signed 16-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_1X16: CUresourceViewFormat_enum = 10;
///< 2 channel signed 16-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_2X16: CUresourceViewFormat_enum = 11;
///< 4 channel signed 16-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_4X16: CUresourceViewFormat_enum = 12;
///< 1 channel unsigned 32-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_1X32: CUresourceViewFormat_enum = 13;
///< 2 channel unsigned 32-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_2X32: CUresourceViewFormat_enum = 14;
///< 4 channel unsigned 32-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UINT_4X32: CUresourceViewFormat_enum = 15;
///< 1 channel signed 32-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_1X32: CUresourceViewFormat_enum = 16;
///< 2 channel signed 32-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_2X32: CUresourceViewFormat_enum = 17;
///< 4 channel signed 32-bit integers
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SINT_4X32: CUresourceViewFormat_enum = 18;
///< 1 channel 16-bit floating point
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_FLOAT_1X16: CUresourceViewFormat_enum = 19;
///< 2 channel 16-bit floating point
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_FLOAT_2X16: CUresourceViewFormat_enum = 20;
///< 4 channel 16-bit floating point
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_FLOAT_4X16: CUresourceViewFormat_enum = 21;
///< 1 channel 32-bit floating point
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_FLOAT_1X32: CUresourceViewFormat_enum = 22;
///< 2 channel 32-bit floating point
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_FLOAT_2X32: CUresourceViewFormat_enum = 23;
///< 4 channel 32-bit floating point
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_FLOAT_4X32: CUresourceViewFormat_enum = 24;
///< Block compressed 1
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UNSIGNED_BC1: CUresourceViewFormat_enum = 25;
///< Block compressed 2
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UNSIGNED_BC2: CUresourceViewFormat_enum = 26;
///< Block compressed 3
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UNSIGNED_BC3: CUresourceViewFormat_enum = 27;
///< Block compressed 4 unsigned
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UNSIGNED_BC4: CUresourceViewFormat_enum = 28;
///< Block compressed 4 signed
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SIGNED_BC4: CUresourceViewFormat_enum = 29;
///< Block compressed 5 unsigned
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UNSIGNED_BC5: CUresourceViewFormat_enum = 30;
///< Block compressed 5 signed
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SIGNED_BC5: CUresourceViewFormat_enum = 31;
///< Block compressed 6 unsigned half-float
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UNSIGNED_BC6H: CUresourceViewFormat_enum =
    32;
///< Block compressed 6 signed half-float
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_SIGNED_BC6H: CUresourceViewFormat_enum = 33;
///< Block compressed 7
pub const CUresourceViewFormat_enum_CU_RES_VIEW_FORMAT_UNSIGNED_BC7: CUresourceViewFormat_enum = 34;
/// Resource view format
pub type CUresourceViewFormat_enum = u32;
pub use self::CUresourceViewFormat_enum as CUresourceViewFormat;
/// Resource view descriptor
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_RESOURCE_VIEW_DESC_st {
    ///< Resource view format
    pub format: CUresourceViewFormat,
    ///< Width of the resource view
    pub width: usize,
    ///< Height of the resource view
    pub height: usize,
    ///< Depth of the resource view
    pub depth: usize,
    ///< First defined mipmap level
    pub firstMipmapLevel: ::std::os::raw::c_uint,
    ///< Last defined mipmap level
    pub lastMipmapLevel: ::std::os::raw::c_uint,
    ///< First layer index
    pub firstLayer: ::std::os::raw::c_uint,
    ///< Last layer index
    pub lastLayer: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_VIEW_DESC_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_RESOURCE_VIEW_DESC_st>(),
        112usize,
        concat!("Size of: ", stringify!(CUDA_RESOURCE_VIEW_DESC_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_RESOURCE_VIEW_DESC_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_RESOURCE_VIEW_DESC_st))
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).format as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(format)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).width as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(width)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).height as *const _ as usize
        },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(height)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).depth as *const _ as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(depth)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).firstMipmapLevel as *const _
                as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(firstMipmapLevel)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).lastMipmapLevel as *const _
                as usize
        },
        36usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(lastMipmapLevel)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).firstLayer as *const _ as usize
        },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(firstLayer)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).lastLayer as *const _ as usize
        },
        44usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(lastLayer)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_RESOURCE_VIEW_DESC_st>())).reserved as *const _ as usize
        },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_RESOURCE_VIEW_DESC_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_RESOURCE_VIEW_DESC = CUDA_RESOURCE_VIEW_DESC_st;
/// GPU Direct v3 tokens
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st {
    pub p2pToken: ::std::os::raw::c_ulonglong,
    pub vaSpaceToken: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st>(),
        16usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st>())).p2pToken as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st),
            "::",
            stringify!(p2pToken)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st>())).vaSpaceToken
                as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st),
            "::",
            stringify!(vaSpaceToken)
        )
    );
}
pub type CUDA_POINTER_ATTRIBUTE_P2P_TOKENS = CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st;
/// Kernel launch parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_LAUNCH_PARAMS_st {
    ///< Kernel to launch
    pub function: CUfunction,
    ///< Width of grid in blocks
    pub gridDimX: ::std::os::raw::c_uint,
    ///< Height of grid in blocks
    pub gridDimY: ::std::os::raw::c_uint,
    ///< Depth of grid in blocks
    pub gridDimZ: ::std::os::raw::c_uint,
    ///< X dimension of each thread block
    pub blockDimX: ::std::os::raw::c_uint,
    ///< Y dimension of each thread block
    pub blockDimY: ::std::os::raw::c_uint,
    ///< Z dimension of each thread block
    pub blockDimZ: ::std::os::raw::c_uint,
    ///< Dynamic shared-memory size per thread block in bytes
    pub sharedMemBytes: ::std::os::raw::c_uint,
    ///< Stream identifier
    pub hStream: CUstream,
    ///< Array of pointers to kernel parameters
    pub kernelParams: *mut *mut ::std::os::raw::c_void,
}
#[test]
fn bindgen_test_layout_CUDA_LAUNCH_PARAMS_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_LAUNCH_PARAMS_st>(),
        56usize,
        concat!("Size of: ", stringify!(CUDA_LAUNCH_PARAMS_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_LAUNCH_PARAMS_st>(),
        8usize,
        concat!("Alignment of ", stringify!(CUDA_LAUNCH_PARAMS_st))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).function as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(function)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).gridDimX as *const _ as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(gridDimX)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).gridDimY as *const _ as usize },
        12usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(gridDimY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).gridDimZ as *const _ as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(gridDimZ)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).blockDimX as *const _ as usize },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(blockDimX)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).blockDimY as *const _ as usize },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(blockDimY)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).blockDimZ as *const _ as usize },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(blockDimZ)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).sharedMemBytes as *const _ as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(sharedMemBytes)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).hStream as *const _ as usize },
        40usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(hStream)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_LAUNCH_PARAMS_st>())).kernelParams as *const _ as usize
        },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_LAUNCH_PARAMS_st),
            "::",
            stringify!(kernelParams)
        )
    );
}
pub type CUDA_LAUNCH_PARAMS = CUDA_LAUNCH_PARAMS_st;
/// Handle is an opaque file descriptor
pub const CUexternalMemoryHandleType_enum_CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD:
    CUexternalMemoryHandleType_enum = 1;
/// Handle is an opaque shared NT handle
pub const CUexternalMemoryHandleType_enum_CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32:
    CUexternalMemoryHandleType_enum = 2;
/// Handle is an opaque, globally shared handle
pub const CUexternalMemoryHandleType_enum_CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT:
    CUexternalMemoryHandleType_enum = 3;
/// Handle is a D3D12 heap object
pub const CUexternalMemoryHandleType_enum_CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP:
    CUexternalMemoryHandleType_enum = 4;
/// Handle is a D3D12 committed resource
pub const CUexternalMemoryHandleType_enum_CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE:
    CUexternalMemoryHandleType_enum = 5;
/// External memory handle types
pub type CUexternalMemoryHandleType_enum = u32;
pub use self::CUexternalMemoryHandleType_enum as CUexternalMemoryHandleType;
/// External memory handle descriptor
#[repr(C)]
#[derive(Copy, Clone)]
pub struct CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st {
    /// Type of the handle
    pub type_: CUexternalMemoryHandleType,
    pub handle: CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1,
    /// Size of the memory allocation
    pub size: ::std::os::raw::c_ulonglong,
    /// Flags must either be zero or ::CUDA_EXTERNAL_MEMORY_DEDICATED
    pub flags: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1 {
    /// File descriptor referencing the memory object. Valid
    /// when type is
    /// ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD
    pub fd: ::std::os::raw::c_int,
    pub win32: CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1,
    _bindgen_union_align: [u64; 2usize],
}
/// Win32 handle referencing the semaphore object. Valid when
/// type is one of the following:
/// - ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32
/// - ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT
/// - ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP
/// - ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE
/// Exactly one of 'handle' and 'name' must be non-NULL. If
/// type is
/// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT
/// then 'name' must be NULL.
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1 {
    /// Valid NT handle. Must be NULL if 'name' is non-NULL
    pub handle: *mut ::std::os::raw::c_void,
    /// Name of a valid memory object.
    /// Must be NULL if 'handle' is non-NULL.
    pub name: *const ::std::os::raw::c_void,
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1>(),
        16usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1>(
            ))).handle as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(handle)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1>(
            ))).name as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(name)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1>(),
        16usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1>())).fd
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(fd)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1>())).win32
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(win32)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st>(),
        104usize,
        concat!("Size of: ", stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st>())).type_ as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st),
            "::",
            stringify!(type_)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st>())).handle as *const _
                as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st),
            "::",
            stringify!(handle)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st>())).size as *const _
                as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st),
            "::",
            stringify!(size)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st>())).flags as *const _
                as usize
        },
        32usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st>())).reserved as *const _
                as usize
        },
        36usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_EXTERNAL_MEMORY_HANDLE_DESC = CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st;
/// External memory buffer descriptor
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st {
    /// Offset into the memory object where the buffer's base is
    pub offset: ::std::os::raw::c_ulonglong,
    /// Size of the buffer
    pub size: ::std::os::raw::c_ulonglong,
    /// Flags reserved for future use. Must be zero.
    pub flags: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st>(),
        88usize,
        concat!("Size of: ", stringify!(CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st))
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st>())).offset as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st),
            "::",
            stringify!(offset)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st>())).size as *const _
                as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st),
            "::",
            stringify!(size)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st>())).flags as *const _
                as usize
        },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st>())).reserved as *const _
                as usize
        },
        20usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_EXTERNAL_MEMORY_BUFFER_DESC = CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st;
/// External memory mipmap descriptor
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st {
    /// Offset into the memory object where the base level of the
    /// mipmap chain is.
    pub offset: ::std::os::raw::c_ulonglong,
    /// Format, dimension and type of base level of the mipmap chain
    pub arrayDesc: CUDA_ARRAY3D_DESCRIPTOR,
    /// Total number of levels in the mipmap chain
    pub numLevels: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st>(),
        120usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st>())).offset
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st),
            "::",
            stringify!(offset)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st>())).arrayDesc
                as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st),
            "::",
            stringify!(arrayDesc)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st>())).numLevels
                as *const _ as usize
        },
        48usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st),
            "::",
            stringify!(numLevels)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st>())).reserved
                as *const _ as usize
        },
        52usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC = CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st;
/// Handle is an opaque file descriptor
pub const CUexternalSemaphoreHandleType_enum_CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD:
    CUexternalSemaphoreHandleType_enum = 1;
/// Handle is an opaque shared NT handle
pub const CUexternalSemaphoreHandleType_enum_CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32:
    CUexternalSemaphoreHandleType_enum = 2;
/// Handle is an opaque, globally shared handle
pub const CUexternalSemaphoreHandleType_enum_CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT:
    CUexternalSemaphoreHandleType_enum = 3;
/// Handle is a shared NT handle referencing a D3D12 fence object
pub const CUexternalSemaphoreHandleType_enum_CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE:
    CUexternalSemaphoreHandleType_enum = 4;
/// External semaphore handle types
pub type CUexternalSemaphoreHandleType_enum = u32;
pub use self::CUexternalSemaphoreHandleType_enum as CUexternalSemaphoreHandleType;
/// External semaphore handle descriptor
#[repr(C)]
#[derive(Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st {
    /// Type of the handle
    pub type_: CUexternalSemaphoreHandleType,
    pub handle: CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1,
    /// Flags reserved for the future. Must be zero.
    pub flags: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1 {
    /// File descriptor referencing the semaphore object. Valid
    /// when type is
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD
    pub fd: ::std::os::raw::c_int,
    pub win32: CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1,
    _bindgen_union_align: [u64; 2usize],
}
/// Win32 handle referencing the semaphore object. Valid when
/// type is one of the following:
/// - ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32
/// - ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT
/// - ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE
/// Exactly one of 'handle' and 'name' must be non-NULL. If
/// type is
/// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT
/// then 'name' must be NULL.
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1 {
    /// Valid NT handle. Must be NULL if 'name' is non-NULL
    pub handle: *mut ::std::os::raw::c_void,
    /// Name of a valid synchronization primitive.
    /// Must be NULL if 'handle' is non-NULL.
    pub name: *const ::std::os::raw::c_void,
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1>(),
        16usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1>(
        ),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1,
            >())).handle as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(handle)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1,
            >())).name as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(name)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1>(),
        16usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1>())).fd
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(fd)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1>())).win32
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st__bindgen_ty_1),
            "::",
            stringify!(win32)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st>(),
        96usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st>())).type_ as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st),
            "::",
            stringify!(type_)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st>())).handle as *const _
                as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st),
            "::",
            stringify!(handle)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st>())).flags as *const _
                as usize
        },
        24usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st>())).reserved as *const _
                as usize
        },
        28usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC = CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st;
/// External semaphore signal parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st {
    pub params: CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1,
    /// Flags reserved for the future. Must be zero.
    pub flags: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1 {
    pub fence: CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
/// Parameters for fence objects
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1 {
    /// Value of fence to be signaled
    pub value: ::std::os::raw::c_ulonglong,
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1>(
        ),
        8usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1>(
        ),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1,
            >())).value as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(value)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1>(),
        72usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1>())).fence
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1),
            "::",
            stringify!(fence)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1>()))
                .reserved as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st__bindgen_ty_1),
            "::",
            stringify!(reserved)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st>(),
        144usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st>())).params as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st),
            "::",
            stringify!(params)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st>())).flags as *const _
                as usize
        },
        72usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st>())).reserved
                as *const _ as usize
        },
        76usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS = CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_st;
/// External semaphore wait parameters
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st {
    pub params: CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1,
    /// Flags reserved for the future. Must be zero.
    pub flags: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1 {
    pub fence: CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
/// Parameters for fence objects
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1 {
    /// Value of fence to be waited on
    pub value: ::std::os::raw::c_ulonglong,
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1>(),
        8usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1>(
        ),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<
                CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1,
            >())).value as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1__bindgen_ty_1),
            "::",
            stringify!(value)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1>(),
        72usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1>())).fence
                as *const _ as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1),
            "::",
            stringify!(fence)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1>()))
                .reserved as *const _ as usize
        },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st__bindgen_ty_1),
            "::",
            stringify!(reserved)
        )
    );
}
#[test]
fn bindgen_test_layout_CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st() {
    assert_eq!(
        ::std::mem::size_of::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st>(),
        144usize,
        concat!(
            "Size of: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st)
        )
    );
    assert_eq!(
        ::std::mem::align_of::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st>(),
        8usize,
        concat!(
            "Alignment of ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st>())).params as *const _
                as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st),
            "::",
            stringify!(params)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st>())).flags as *const _
                as usize
        },
        72usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st),
            "::",
            stringify!(flags)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st>())).reserved as *const _
                as usize
        },
        76usize,
        concat!(
            "Offset of field: ",
            stringify!(CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st),
            "::",
            stringify!(reserved)
        )
    );
}
pub type CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS = CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_st;
extern "C" {
    /// \brief Gets the string description of an error code
    ///
    /// Sets \p *pStr to the address of a NULL-terminated string description
    /// of the error code \p error.
    /// If the error code is not recognized, ::CUDA_ERROR_INVALID_VALUE
    /// will be returned and \p *pStr will be set to the NULL address.
    ///
    /// \param error - Error code to convert to string
    /// \param pStr - Address of the string pointer.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::CUresult,
    /// ::cudaGetErrorString
    pub fn cuGetErrorString(error: CUresult, pStr: *mut *const ::std::os::raw::c_char) -> CUresult;
}
extern "C" {
    /// \brief Gets the string representation of an error code enum name
    ///
    /// Sets \p *pStr to the address of a NULL-terminated string representation
    /// of the name of the enum error code \p error.
    /// If the error code is not recognized, ::CUDA_ERROR_INVALID_VALUE
    /// will be returned and \p *pStr will be set to the NULL address.
    ///
    /// \param error - Error code to convert to string
    /// \param pStr - Address of the string pointer.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::CUresult,
    /// ::cudaGetErrorName
    pub fn cuGetErrorName(error: CUresult, pStr: *mut *const ::std::os::raw::c_char) -> CUresult;
}
extern "C" {
    /// \brief Initialize the CUDA driver API
    ///
    /// Initializes the driver API and must be called before any other function from
    /// the driver API. Currently, the \p Flags parameter must be 0. If ::cuInit()
    /// has not been called, any function from the driver API will return
    /// ::CUDA_ERROR_NOT_INITIALIZED.
    ///
    /// \param Flags - Initialization flag for CUDA.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    pub fn cuInit(Flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Returns the latest CUDA version supported by driver
    ///
    /// Returns in \p *driverVersion the version of CUDA supported by
    /// the driver.  The version is returned as
    /// (1000 &times; major + 10 &times; minor). For example, CUDA 9.2
    /// would be represented by 9020.
    ///
    /// This function automatically returns ::CUDA_ERROR_INVALID_VALUE if
    /// \p driverVersion is NULL.
    ///
    /// \param driverVersion - Returns the CUDA driver version
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cudaDriverGetVersion,
    /// ::cudaRuntimeGetVersion
    pub fn cuDriverGetVersion(driverVersion: *mut ::std::os::raw::c_int) -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a compute device
    ///
    /// Returns in \p *device a device handle given an ordinal in the range <b>[0,
    /// ::cuDeviceGetCount()-1]</b>.
    ///
    /// \param device  - Returned device handle
    /// \param ordinal - Device number to get handle for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGetUuid,
    /// ::cuDeviceGetLuid,
    /// ::cuDeviceTotalMem
    pub fn cuDeviceGet(device: *mut CUdevice, ordinal: ::std::os::raw::c_int) -> CUresult;
}
extern "C" {
    /// \brief Returns the number of compute-capable devices
    ///
    /// Returns in \p *count the number of devices with compute capability greater
    /// than or equal to 2.0 that are available for execution. If there is no such
    /// device, ::cuDeviceGetCount() returns 0.
    ///
    /// \param count - Returned number of compute-capable devices
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGetUuid,
    /// ::cuDeviceGetLuid,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem,
    /// ::cudaGetDeviceCount
    pub fn cuDeviceGetCount(count: *mut ::std::os::raw::c_int) -> CUresult;
}
extern "C" {
    /// \brief Returns an identifer string for the device
    ///
    /// Returns an ASCII string identifying the device \p dev in the NULL-terminated
    /// string pointed to by \p name. \p len specifies the maximum length of the
    /// string that may be returned.
    ///
    /// \param name - Returned identifier string for the device
    /// \param len  - Maximum length of string to store in \p name
    /// \param dev  - Device to get identifier string for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetUuid,
    /// ::cuDeviceGetLuid,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem,
    /// ::cudaGetDeviceProperties
    pub fn cuDeviceGetName(
        name: *mut ::std::os::raw::c_char,
        len: ::std::os::raw::c_int,
        dev: CUdevice,
    ) -> CUresult;
}
extern "C" {
    /// \brief Return an UUID for the device
    ///
    /// Returns 16-octets identifing the device \p dev in the structure
    /// pointed by the \p uuid.
    ///
    /// \param uuid - Returned UUID
    /// \param dev  - Device to get identifier string for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGetLuid,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem,
    /// ::cudaGetDeviceProperties
    pub fn cuDeviceGetUuid(uuid: *mut CUuuid, dev: CUdevice) -> CUresult;
}
extern "C" {
    pub fn cuDeviceTotalMem_v2(bytes: *mut usize, dev: CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Returns information about the device
    ///
    /// Returns in \p *pi the integer value of the attribute \p attrib on device
    /// \p dev. The supported attributes are:
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK: Maximum number of threads per
    ///   block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X: Maximum x-dimension of a block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y: Maximum y-dimension of a block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z: Maximum z-dimension of a block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X: Maximum x-dimension of a grid;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y: Maximum y-dimension of a grid;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z: Maximum z-dimension of a grid;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK: Maximum amount of
    ///   shared memory available to a thread block in bytes;
    /// - ::CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY: Memory available on device for
    ///   __constant__ variables in a CUDA C kernel in bytes;
    /// - ::CU_DEVICE_ATTRIBUTE_WARP_SIZE: Warp size in threads;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_PITCH: Maximum pitch in bytes allowed by the
    ///   memory copy functions that involve memory regions allocated through
    ///   ::cuMemAllocPitch();
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_WIDTH: Maximum 1D
    ///  texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH: Maximum width
    ///  for a 1D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: Maximum
    ///  mipmapped 1D texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_WIDTH: Maximum 2D
    ///  texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_HEIGHT: Maximum 2D
    ///  texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH: Maximum width
    ///  for a 2D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: Maximum height
    ///  for a 2D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH: Maximum pitch
    ///  in bytes for a 2D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: Maximum
    ///  mipmapped 2D texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: Maximum
    ///  mipmapped 2D texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH: Maximum 3D
    ///  texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT: Maximum 3D
    ///  texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH: Maximum 3D
    ///  texture depth;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE:
    ///  Alternate maximum 3D texture width, 0 if no alternate
    ///  maximum 3D texture size is supported;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE:
    ///  Alternate maximum 3D texture height, 0 if no alternate
    ///  maximum 3D texture size is supported;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE:
    ///  Alternate maximum 3D texture depth, 0 if no alternate
    ///  maximum 3D texture size is supported;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_WIDTH:
    ///  Maximum cubemap texture width or height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_WIDTH:
    ///  Maximum 1D layered texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_LAYERS:
    ///   Maximum layers in a 1D layered texture;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH:
    ///  Maximum 2D layered texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT:
    ///   Maximum 2D layered texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS:
    ///   Maximum layers in a 2D layered texture;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH:
    ///   Maximum cubemap layered texture width or height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS:
    ///   Maximum layers in a cubemap layered texture;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_WIDTH:
    ///   Maximum 1D surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_WIDTH:
    ///   Maximum 2D surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_HEIGHT:
    ///   Maximum 2D surface height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_WIDTH:
    ///   Maximum 3D surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_HEIGHT:
    ///   Maximum 3D surface height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_DEPTH:
    ///   Maximum 3D surface depth;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_WIDTH:
    ///   Maximum 1D layered surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_LAYERS:
    ///   Maximum layers in a 1D layered surface;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_WIDTH:
    ///   Maximum 2D layered surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_HEIGHT:
    ///   Maximum 2D layered surface height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_LAYERS:
    ///   Maximum layers in a 2D layered surface;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_WIDTH:
    ///   Maximum cubemap surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH:
    ///   Maximum cubemap layered surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS:
    ///   Maximum layers in a cubemap layered surface;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK: Maximum number of 32-bit
    ///   registers available to a thread block;
    /// - ::CU_DEVICE_ATTRIBUTE_CLOCK_RATE: The typical clock frequency in kilohertz;
    /// - ::CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT: Alignment requirement; texture
    ///   base addresses aligned to ::textureAlign bytes do not need an offset
    ///   applied to texture fetches;
    /// - ::CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT: Pitch alignment requirement
    ///   for 2D texture references bound to pitched memory;
    /// - ::CU_DEVICE_ATTRIBUTE_GPU_OVERLAP: 1 if the device can concurrently copy
    ///   memory between host and device while executing a kernel, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT: Number of multiprocessors on
    ///   the device;
    /// - ::CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT: 1 if there is a run time limit
    ///   for kernels executed on the device, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_INTEGRATED: 1 if the device is integrated with the
    ///   memory subsystem, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_CAN_MAP_HOST_MEMORY: 1 if the device can map host
    ///   memory into the CUDA address space, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_MODE: Compute mode that device is currently
    ///   in. Available modes are as follows:
    ///   - ::CU_COMPUTEMODE_DEFAULT: Default mode - Device is not restricted and
    ///     can have multiple CUDA contexts present at a single time.
    ///   - ::CU_COMPUTEMODE_PROHIBITED: Compute-prohibited mode - Device is
    ///     prohibited from creating new CUDA contexts.
    ///   - ::CU_COMPUTEMODE_EXCLUSIVE_PROCESS:  Compute-exclusive-process mode - Device
    ///     can have only one context used by a single process at a time.
    /// - ::CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS: 1 if the device supports
    ///   executing multiple kernels within the same context simultaneously, or 0 if
    ///   not. It is not guaranteed that multiple kernels will be resident
    ///   on the device concurrently so this feature should not be relied upon for
    ///   correctness;
    /// - ::CU_DEVICE_ATTRIBUTE_ECC_ENABLED: 1 if error correction is enabled on the
    ///    device, 0 if error correction is disabled or not supported by the device;
    /// - ::CU_DEVICE_ATTRIBUTE_PCI_BUS_ID: PCI bus identifier of the device;
    /// - ::CU_DEVICE_ATTRIBUTE_PCI_DEVICE_ID: PCI device (also known as slot) identifier
    ///   of the device;
    /// - ::CU_DEVICE_ATTRIBUTE_PCI_DOMAIN_ID: PCI domain identifier of the device
    /// - ::CU_DEVICE_ATTRIBUTE_TCC_DRIVER: 1 if the device is using a TCC driver. TCC
    ///    is only available on Tesla hardware running Windows Vista or later;
    /// - ::CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE: Peak memory clock frequency in kilohertz;
    /// - ::CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH: Global memory bus width in bits;
    /// - ::CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE: Size of L2 cache in bytes. 0 if the device doesn't have L2 cache;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR: Maximum resident threads per multiprocessor;
    /// - ::CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING: 1 if the device shares a unified address space with
    ///   the host, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR: Major compute capability version number;
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR: Minor compute capability version number;
    /// - ::CU_DEVICE_ATTRIBUTE_GLOBAL_L1_CACHE_SUPPORTED: 1 if device supports caching globals
    ///    in L1 cache, 0 if caching globals in L1 cache is not supported by the device;
    /// - ::CU_DEVICE_ATTRIBUTE_LOCAL_L1_CACHE_SUPPORTED: 1 if device supports caching locals
    ///    in L1 cache, 0 if caching locals in L1 cache is not supported by the device;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: Maximum amount of
    ///   shared memory available to a multiprocessor in bytes; this amount is shared
    ///   by all thread blocks simultaneously resident on a multiprocessor;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_MULTIPROCESSOR: Maximum number of 32-bit
    ///   registers available to a multiprocessor; this number is shared by all thread
    ///   blocks simultaneously resident on a multiprocessor;
    /// - ::CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY: 1 if device supports allocating managed memory
    ///   on this system, 0 if allocating managed memory is not supported by the device on this system.
    /// - ::CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD: 1 if device is on a multi-GPU board, 0 if not.
    /// - ::CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD_GROUP_ID: Unique identifier for a group of devices
    ///   associated with the same board. Devices on the same multi-GPU board will share the same identifier.
    /// - ::CU_DEVICE_ATTRIBUTE_HOST_NATIVE_ATOMIC_SUPPORTED: 1 if Link between the device and the host
    ///   supports native atomic operations.
    /// - ::CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO: Ratio of single precision performance
    ///   (in floating-point operations per second) to double precision performance.
    /// - ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS: Device suppports coherently accessing
    ///   pageable memory without calling cudaHostRegister on it.
    /// - ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS: Device can coherently access managed memory
    ///   concurrently with the CPU.
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_PREEMPTION_SUPPORTED: Device supports Compute Preemption.
    /// - ::CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM: Device can access host registered
    ///   memory at the same virtual address as the CPU.
    /// -  ::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN: The maximum per block shared memory size
    ///    suported on this device. This is the maximum value that can be opted into when using the cuFuncSetAttribute() call.
    ///    For more details see ::CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES
    /// - ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES: Device accesses pageable memory via the host's
    ///   page tables.
    /// - ::CU_DEVICE_ATTRIBUTE_DIRECT_MANAGED_MEM_ACCESS_FROM_HOST: The host can directly access managed memory on the device without migration.
    ///
    /// \param pi     - Returned device attribute value
    /// \param attrib - Device attribute to query
    /// \param dev    - Device handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGetUuid,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem,
    /// ::cudaDeviceGetAttribute,
    /// ::cudaGetDeviceProperties
    pub fn cuDeviceGetAttribute(
        pi: *mut ::std::os::raw::c_int,
        attrib: CUdevice_attribute,
        dev: CUdevice,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns properties for a selected device
    ///
    /// \deprecated
    ///
    /// This function was deprecated as of CUDA 5.0 and replaced by ::cuDeviceGetAttribute().
    ///
    /// Returns in \p *prop the properties of device \p dev. The ::CUdevprop
    /// structure is defined as:
    ///
    /// \code
    ///typedef struct CUdevprop_st {
    ///int maxThreadsPerBlock;
    ///int maxThreadsDim[3];
    ///int maxGridSize[3];
    ///int sharedMemPerBlock;
    ///int totalConstantMemory;
    ///int SIMDWidth;
    ///int memPitch;
    ///int regsPerBlock;
    ///int clockRate;
    ///int textureAlign
    ///} CUdevprop;
    /// \endcode
    /// where:
    ///
    /// - ::maxThreadsPerBlock is the maximum number of threads per block;
    /// - ::maxThreadsDim[3] is the maximum sizes of each dimension of a block;
    /// - ::maxGridSize[3] is the maximum sizes of each dimension of a grid;
    /// - ::sharedMemPerBlock is the total amount of shared memory available per
    ///   block in bytes;
    /// - ::totalConstantMemory is the total amount of constant memory available on
    ///   the device in bytes;
    /// - ::SIMDWidth is the warp size;
    /// - ::memPitch is the maximum pitch allowed by the memory copy functions that
    ///   involve memory regions allocated through ::cuMemAllocPitch();
    /// - ::regsPerBlock is the total number of registers available per block;
    /// - ::clockRate is the clock frequency in kilohertz;
    /// - ::textureAlign is the alignment requirement; texture base addresses that
    ///   are aligned to ::textureAlign bytes do not need an offset applied to
    ///   texture fetches.
    ///
    /// \param prop - Returned properties of device
    /// \param dev  - Device to get properties for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGetUuid,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem
    pub fn cuDeviceGetProperties(prop: *mut CUdevprop, dev: CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Returns the compute capability of the device
    ///
    /// \deprecated
    ///
    /// This function was deprecated as of CUDA 5.0 and its functionality superceded
    /// by ::cuDeviceGetAttribute().
    ///
    /// Returns in \p *major and \p *minor the major and minor revision numbers that
    /// define the compute capability of the device \p dev.
    ///
    /// \param major - Major revision number
    /// \param minor - Minor revision number
    /// \param dev   - Device handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGetUuid,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem
    pub fn cuDeviceComputeCapability(
        major: *mut ::std::os::raw::c_int,
        minor: *mut ::std::os::raw::c_int,
        dev: CUdevice,
    ) -> CUresult;
}
extern "C" {
    /// \brief Retain the primary context on the GPU
    ///
    /// Retains the primary context on the device, creating it if necessary,
    /// increasing its usage count. The caller must call
    /// ::cuDevicePrimaryCtxRelease() when done using the context.
    /// Unlike ::cuCtxCreate() the newly created context is not pushed onto the stack.
    ///
    /// Context creation will fail with ::CUDA_ERROR_UNKNOWN if the compute mode of
    /// the device is ::CU_COMPUTEMODE_PROHIBITED.  The function ::cuDeviceGetAttribute()
    /// can be used with ::CU_DEVICE_ATTRIBUTE_COMPUTE_MODE to determine the compute mode
    /// of the device.
    /// The <i>nvidia-smi</i> tool can be used to set the compute mode for
    /// devices. Documentation for <i>nvidia-smi</i> can be obtained by passing a
    /// -h option to it.
    ///
    /// Please note that the primary context always supports pinned allocations. Other
    /// flags can be specified by ::cuDevicePrimaryCtxSetFlags().
    ///
    /// \param pctx  - Returned context handle of the new context
    /// \param dev   - Device for which primary context is requested
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRelease,
    /// ::cuDevicePrimaryCtxSetFlags,
    /// ::cuCtxCreate,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    pub fn cuDevicePrimaryCtxRetain(pctx: *mut CUcontext, dev: CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Release the primary context on the GPU
    ///
    /// Releases the primary context interop on the device by decreasing the usage
    /// count by 1. If the usage drops to 0 the primary context of device \p dev
    /// will be destroyed regardless of how many threads it is current to.
    ///
    /// Please note that unlike ::cuCtxDestroy() this method does not pop the context
    /// from stack in any circumstances.
    ///
    /// \param dev - Device which primary context is released
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRetain,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    pub fn cuDevicePrimaryCtxRelease(dev: CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Set flags for the primary context
    ///
    /// Sets the flags for the primary context on the device overwriting perviously
    /// set ones. If the primary context is already created
    /// ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE is returned.
    ///
    /// The three LSBs of the \p flags parameter can be used to control how the OS
    /// thread, which owns the CUDA context at the time of an API call, interacts
    /// with the OS scheduler when waiting for results from the GPU. Only one of
    /// the scheduling flags can be set when creating a context.
    ///
    /// - ::CU_CTX_SCHED_SPIN: Instruct CUDA to actively spin when waiting for
    /// results from the GPU. This can decrease latency when waiting for the GPU,
    /// but may lower the performance of CPU threads if they are performing work in
    /// parallel with the CUDA thread.
    ///
    /// - ::CU_CTX_SCHED_YIELD: Instruct CUDA to yield its thread when waiting for
    /// results from the GPU. This can increase latency when waiting for the GPU,
    /// but can increase the performance of CPU threads performing work in parallel
    /// with the GPU.
    ///
    /// - ::CU_CTX_SCHED_BLOCKING_SYNC: Instruct CUDA to block the CPU thread on a
    /// synchronization primitive when waiting for the GPU to finish work.
    ///
    /// - ::CU_CTX_BLOCKING_SYNC: Instruct CUDA to block the CPU thread on a
    /// synchronization primitive when waiting for the GPU to finish work. <br>
    /// <b>Deprecated:</b> This flag was deprecated as of CUDA 4.0 and was
    /// replaced with ::CU_CTX_SCHED_BLOCKING_SYNC.
    ///
    /// - ::CU_CTX_SCHED_AUTO: The default value if the \p flags parameter is zero,
    /// uses a heuristic based on the number of active CUDA contexts in the
    /// process \e C and the number of logical processors in the system \e P. If
    /// \e C > \e P, then CUDA will yield to other OS threads when waiting for
    /// the GPU (::CU_CTX_SCHED_YIELD), otherwise CUDA will not yield while
    /// waiting for results and actively spin on the processor (::CU_CTX_SCHED_SPIN).
    /// However, on low power devices like Tegra, it always defaults to
    /// ::CU_CTX_SCHED_BLOCKING_SYNC.
    ///
    /// - ::CU_CTX_LMEM_RESIZE_TO_MAX: Instruct CUDA to not reduce local memory
    /// after resizing local memory for a kernel. This can prevent thrashing by
    /// local memory allocations when launching many kernels with high local
    /// memory usage at the cost of potentially increased memory usage.
    ///
    /// \param dev   - Device for which the primary context flags are set
    /// \param flags - New flags for the device
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRetain,
    /// ::cuDevicePrimaryCtxGetState,
    /// ::cuCtxCreate,
    /// ::cuCtxGetFlags,
    /// ::cudaSetDeviceFlags
    pub fn cuDevicePrimaryCtxSetFlags(dev: CUdevice, flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Get the state of the primary context
    ///
    /// Returns in \p *flags the flags for the primary context of \p dev, and in
    /// \p *active whether it is active.  See ::cuDevicePrimaryCtxSetFlags for flag
    /// values.
    ///
    /// \param dev    - Device to get primary context flags for
    /// \param flags  - Pointer to store flags
    /// \param active - Pointer to store context state; 0 = inactive, 1 = active
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDevicePrimaryCtxSetFlags,
    /// ::cuCtxGetFlags,
    /// ::cudaGetDeviceFlags
    pub fn cuDevicePrimaryCtxGetState(
        dev: CUdevice,
        flags: *mut ::std::os::raw::c_uint,
        active: *mut ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Destroy all allocations and reset all state on the primary context
    ///
    /// Explicitly destroys and cleans up all resources associated with the current
    /// device in the current process.
    ///
    /// Note that it is responsibility of the calling function to ensure that no
    /// other module in the process is using the device any more. For that reason
    /// it is recommended to use ::cuDevicePrimaryCtxRelease() in most cases.
    /// However it is safe for other modules to call ::cuDevicePrimaryCtxRelease()
    /// even after resetting the device.
    ///
    /// \param dev - Device for which primary context is destroyed
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRetain,
    /// ::cuDevicePrimaryCtxRelease,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cudaDeviceReset
    pub fn cuDevicePrimaryCtxReset(dev: CUdevice) -> CUresult;
}
extern "C" {
    pub fn cuCtxCreate_v2(
        pctx: *mut CUcontext,
        flags: ::std::os::raw::c_uint,
        dev: CUdevice,
    ) -> CUresult;
}
extern "C" {
    pub fn cuCtxDestroy_v2(ctx: CUcontext) -> CUresult;
}
extern "C" {
    pub fn cuCtxPushCurrent_v2(ctx: CUcontext) -> CUresult;
}
extern "C" {
    pub fn cuCtxPopCurrent_v2(pctx: *mut CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Binds the specified CUDA context to the calling CPU thread
    ///
    /// Binds the specified CUDA context to the calling CPU thread.
    /// If \p ctx is NULL then the CUDA context previously bound to the
    /// calling CPU thread is unbound and ::CUDA_SUCCESS is returned.
    ///
    /// If there exists a CUDA context stack on the calling CPU thread, this
    /// will replace the top of that stack with \p ctx.
    /// If \p ctx is NULL then this will be equivalent to popping the top
    /// of the calling CPU thread's CUDA context stack (or a no-op if the
    /// calling CPU thread's CUDA context stack is empty).
    ///
    /// \param ctx - Context to bind to the calling CPU thread
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa
    /// ::cuCtxGetCurrent,
    /// ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cudaSetDevice
    pub fn cuCtxSetCurrent(ctx: CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Returns the CUDA context bound to the calling CPU thread.
    ///
    /// Returns in \p *pctx the CUDA context bound to the calling CPU thread.
    /// If no context is bound to the calling CPU thread then \p *pctx is
    /// set to NULL and ::CUDA_SUCCESS is returned.
    ///
    /// \param pctx - Returned context handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuCtxSetCurrent,
    /// ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cudaGetDevice
    pub fn cuCtxGetCurrent(pctx: *mut CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Returns the device ID for the current context
    ///
    /// Returns in \p *device the ordinal of the current context's device.
    ///
    /// \param device - Returned device ID for the current context
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cudaGetDevice
    pub fn cuCtxGetDevice(device: *mut CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Returns the flags for the current context
    ///
    /// Returns in \p *flags the flags of the current context. See ::cuCtxCreate
    /// for flag values.
    ///
    /// \param flags - Pointer to store flags of current context
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetCurrent,
    /// ::cuCtxGetDevice
    /// ::cuCtxGetLimit,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuCtxGetStreamPriorityRange,
    /// ::cudaGetDeviceFlags
    pub fn cuCtxGetFlags(flags: *mut ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Block for a context's tasks to complete
    ///
    /// Blocks until the device has completed all preceding requested tasks.
    /// ::cuCtxSynchronize() returns an error if one of the preceding tasks failed.
    /// If the context was created with the ::CU_CTX_SCHED_BLOCKING_SYNC flag, the
    /// CPU thread will block until the GPU context has finished its work.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cudaDeviceSynchronize
    pub fn cuCtxSynchronize() -> CUresult;
}
extern "C" {
    /// \brief Set resource limits
    ///
    /// Setting \p limit to \p value is a request by the application to update
    /// the current limit maintained by the context. The driver is free to
    /// modify the requested value to meet h/w requirements (this could be
    /// clamping to minimum or maximum values, rounding up to nearest element
    /// size, etc). The application can use ::cuCtxGetLimit() to find out exactly
    /// what the limit has been set to.
    ///
    /// Setting each ::CUlimit has its own specific restrictions, so each is
    /// discussed here.
    ///
    /// - ::CU_LIMIT_STACK_SIZE controls the stack size in bytes of each GPU thread.
    ///
    /// - ::CU_LIMIT_PRINTF_FIFO_SIZE controls the size in bytes of the FIFO used
    ///   by the ::printf() device system call. Setting ::CU_LIMIT_PRINTF_FIFO_SIZE
    ///   must be performed before launching any kernel that uses the ::printf()
    ///   device system call, otherwise ::CUDA_ERROR_INVALID_VALUE will be returned.
    ///
    /// - ::CU_LIMIT_MALLOC_HEAP_SIZE controls the size in bytes of the heap used
    ///   by the ::malloc() and ::free() device system calls. Setting
    ///   ::CU_LIMIT_MALLOC_HEAP_SIZE must be performed before launching any kernel
    ///   that uses the ::malloc() or ::free() device system calls, otherwise
    ///   ::CUDA_ERROR_INVALID_VALUE will be returned.
    ///
    /// - ::CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH controls the maximum nesting depth of
    ///   a grid at which a thread can safely call ::cudaDeviceSynchronize(). Setting
    ///   this limit must be performed before any launch of a kernel that uses the
    ///   device runtime and calls ::cudaDeviceSynchronize() above the default sync
    ///   depth, two levels of grids. Calls to ::cudaDeviceSynchronize() will fail
    ///   with error code ::cudaErrorSyncDepthExceeded if the limitation is
    ///   violated. This limit can be set smaller than the default or up the maximum
    ///   launch depth of 24. When setting this limit, keep in mind that additional
    ///   levels of sync depth require the driver to reserve large amounts of device
    ///   memory which can no longer be used for user allocations. If these
    ///   reservations of device memory fail, ::cuCtxSetLimit will return
    ///   ::CUDA_ERROR_OUT_OF_MEMORY, and the limit can be reset to a lower value.
    ///   This limit is only applicable to devices of compute capability 3.5 and
    ///   higher. Attempting to set this limit on devices of compute capability less
    ///   than 3.5 will result in the error ::CUDA_ERROR_UNSUPPORTED_LIMIT being
    ///   returned.
    ///
    /// - ::CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT controls the maximum number of
    ///   outstanding device runtime launches that can be made from the current
    ///   context. A grid is outstanding from the point of launch up until the grid
    ///   is known to have been completed. Device runtime launches which violate
    ///   this limitation fail and return ::cudaErrorLaunchPendingCountExceeded when
    ///   ::cudaGetLastError() is called after launch. If more pending launches than
    ///   the default (2048 launches) are needed for a module using the device
    ///   runtime, this limit can be increased. Keep in mind that being able to
    ///   sustain additional pending launches will require the driver to reserve
    ///   larger amounts of device memory upfront which can no longer be used for
    ///   allocations. If these reservations fail, ::cuCtxSetLimit will return
    ///   ::CUDA_ERROR_OUT_OF_MEMORY, and the limit can be reset to a lower value.
    ///   This limit is only applicable to devices of compute capability 3.5 and
    ///   higher. Attempting to set this limit on devices of compute capability less
    ///   than 3.5 will result in the error ::CUDA_ERROR_UNSUPPORTED_LIMIT being
    ///   returned.
    ///
    /// \param limit - Limit to set
    /// \param value - Size of limit
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNSUPPORTED_LIMIT,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSynchronize,
    /// ::cudaDeviceSetLimit
    pub fn cuCtxSetLimit(limit: CUlimit, value: usize) -> CUresult;
}
extern "C" {
    /// \brief Returns resource limits
    ///
    /// Returns in \p *pvalue the current size of \p limit.  The supported
    /// ::CUlimit values are:
    /// - ::CU_LIMIT_STACK_SIZE: stack size in bytes of each GPU thread.
    /// - ::CU_LIMIT_PRINTF_FIFO_SIZE: size in bytes of the FIFO used by the
    ///   ::printf() device system call.
    /// - ::CU_LIMIT_MALLOC_HEAP_SIZE: size in bytes of the heap used by the
    ///   ::malloc() and ::free() device system calls.
    /// - ::CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH: maximum grid depth at which a thread
    ///   can issue the device runtime call ::cudaDeviceSynchronize() to wait on
    ///   child grid launches to complete.
    /// - ::CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT: maximum number of outstanding
    ///   device runtime launches that can be made from this context.
    ///
    /// \param limit  - Limit to query
    /// \param pvalue - Returned size of limit
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNSUPPORTED_LIMIT
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cudaDeviceGetLimit
    pub fn cuCtxGetLimit(pvalue: *mut usize, limit: CUlimit) -> CUresult;
}
extern "C" {
    /// \brief Returns the preferred cache configuration for the current context.
    ///
    /// On devices where the L1 cache and shared memory use the same hardware
    /// resources, this function returns through \p pconfig the preferred cache configuration
    /// for the current context. This is only a preference. The driver will use
    /// the requested configuration if possible, but it is free to choose a different
    /// configuration if required to execute functions.
    ///
    /// This will return a \p pconfig of ::CU_FUNC_CACHE_PREFER_NONE on devices
    /// where the size of the L1 cache and shared memory are fixed.
    ///
    /// The supported cache configurations are:
    /// - ::CU_FUNC_CACHE_PREFER_NONE: no preference for shared memory or L1 (default)
    /// - ::CU_FUNC_CACHE_PREFER_SHARED: prefer larger shared memory and smaller L1 cache
    /// - ::CU_FUNC_CACHE_PREFER_L1: prefer larger L1 cache and smaller shared memory
    /// - ::CU_FUNC_CACHE_PREFER_EQUAL: prefer equal sized L1 cache and shared memory
    ///
    /// \param pconfig - Returned cache configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuFuncSetCacheConfig,
    /// ::cudaDeviceGetCacheConfig
    pub fn cuCtxGetCacheConfig(pconfig: *mut CUfunc_cache) -> CUresult;
}
extern "C" {
    /// \brief Sets the preferred cache configuration for the current context.
    ///
    /// On devices where the L1 cache and shared memory use the same hardware
    /// resources, this sets through \p config the preferred cache configuration for
    /// the current context. This is only a preference. The driver will use
    /// the requested configuration if possible, but it is free to choose a different
    /// configuration if required to execute the function. Any function preference
    /// set via ::cuFuncSetCacheConfig() will be preferred over this context-wide
    /// setting. Setting the context-wide cache configuration to
    /// ::CU_FUNC_CACHE_PREFER_NONE will cause subsequent kernel launches to prefer
    /// to not change the cache configuration unless required to launch the kernel.
    ///
    /// This setting does nothing on devices where the size of the L1 cache and
    /// shared memory are fixed.
    ///
    /// Launching a kernel with a different preference than the most recent
    /// preference setting may insert a device-side synchronization point.
    ///
    /// The supported cache configurations are:
    /// - ::CU_FUNC_CACHE_PREFER_NONE: no preference for shared memory or L1 (default)
    /// - ::CU_FUNC_CACHE_PREFER_SHARED: prefer larger shared memory and smaller L1 cache
    /// - ::CU_FUNC_CACHE_PREFER_L1: prefer larger L1 cache and smaller shared memory
    /// - ::CU_FUNC_CACHE_PREFER_EQUAL: prefer equal sized L1 cache and shared memory
    ///
    /// \param config - Requested cache configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuFuncSetCacheConfig,
    /// ::cudaDeviceSetCacheConfig
    pub fn cuCtxSetCacheConfig(config: CUfunc_cache) -> CUresult;
}
extern "C" {
    /// \brief Returns the current shared memory configuration for the current context.
    ///
    /// This function will return in \p pConfig the current size of shared memory banks
    /// in the current context. On devices with configurable shared memory banks,
    /// ::cuCtxSetSharedMemConfig can be used to change this setting, so that all
    /// subsequent kernel launches will by default use the new bank size. When
    /// ::cuCtxGetSharedMemConfig is called on devices without configurable shared
    /// memory, it will return the fixed bank size of the hardware.
    ///
    /// The returned bank configurations can be either:
    /// - ::CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE:  shared memory bank width is
    ///   four bytes.
    /// - ::CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE: shared memory bank width will
    ///   eight bytes.
    ///
    /// \param pConfig - returned shared memory configuration
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cudaDeviceGetSharedMemConfig
    pub fn cuCtxGetSharedMemConfig(pConfig: *mut CUsharedconfig) -> CUresult;
}
extern "C" {
    /// \brief Sets the shared memory configuration for the current context.
    ///
    /// On devices with configurable shared memory banks, this function will set
    /// the context's shared memory bank size which is used for subsequent kernel
    /// launches.
    ///
    /// Changed the shared memory configuration between launches may insert a device
    /// side synchronization point between those launches.
    ///
    /// Changing the shared memory bank size will not increase shared memory usage
    /// or affect occupancy of kernels, but may have major effects on performance.
    /// Larger bank sizes will allow for greater potential bandwidth to shared memory,
    /// but will change what kinds of accesses to shared memory will result in bank
    /// conflicts.
    ///
    /// This function will do nothing on devices with fixed shared memory bank size.
    ///
    /// The supported bank configurations are:
    /// - ::CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE: set bank width to the default initial
    ///   setting (currently, four bytes).
    /// - ::CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively four bytes.
    /// - ::CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively eight bytes.
    ///
    /// \param config - requested shared memory configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cudaDeviceSetSharedMemConfig
    pub fn cuCtxSetSharedMemConfig(config: CUsharedconfig) -> CUresult;
}
extern "C" {
    /// \brief Gets the context's API version.
    ///
    /// Returns a version number in \p version corresponding to the capabilities of
    /// the context (e.g. 3010 or 3020), which library developers can use to direct
    /// callers to a specific API version. If \p ctx is NULL, returns the API version
    /// used to create the currently bound context.
    ///
    /// Note that new API versions are only introduced when context capabilities are
    /// changed that break binary compatibility, so the API version and driver version
    /// may be different. For example, it is valid for the API version to be 3020 while
    /// the driver version is 4020.
    ///
    /// \param ctx     - Context to check
    /// \param version - Pointer to version
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    pub fn cuCtxGetApiVersion(ctx: CUcontext, version: *mut ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Returns numerical values that correspond to the least and
    /// greatest stream priorities.
    ///
    /// Returns in \p *leastPriority and \p *greatestPriority the numerical values that correspond
    /// to the least and greatest stream priorities respectively. Stream priorities
    /// follow a convention where lower numbers imply greater priorities. The range of
    /// meaningful stream priorities is given by [\p *greatestPriority, \p *leastPriority].
    /// If the user attempts to create a stream with a priority value that is
    /// outside the meaningful range as specified by this API, the priority is
    /// automatically clamped down or up to either \p *leastPriority or \p *greatestPriority
    /// respectively. See ::cuStreamCreateWithPriority for details on creating a
    /// priority stream.
    /// A NULL may be passed in for \p *leastPriority or \p *greatestPriority if the value
    /// is not desired.
    ///
    /// This function will return '0' in both \p *leastPriority and \p *greatestPriority if
    /// the current context's device does not support stream priorities
    /// (see ::cuDeviceGetAttribute).
    ///
    /// \param leastPriority    - Pointer to an int in which the numerical value for least
    ///                           stream priority is returned
    /// \param greatestPriority - Pointer to an int in which the numerical value for greatest
    ///                           stream priority is returned
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreateWithPriority,
    /// ::cuStreamGetPriority,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cudaDeviceGetStreamPriorityRange
    pub fn cuCtxGetStreamPriorityRange(
        leastPriority: *mut ::std::os::raw::c_int,
        greatestPriority: *mut ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Increment a context's usage-count
    ///
    /// \deprecated
    ///
    /// Note that this function is deprecated and should not be used.
    ///
    /// Increments the usage count of the context and passes back a context handle
    /// in \p *pctx that must be passed to ::cuCtxDetach() when the application is
    /// done with the context. ::cuCtxAttach() fails if there is no context current
    /// to the thread.
    ///
    /// Currently, the \p flags parameter must be 0.
    ///
    /// \param pctx  - Returned context handle of the current context
    /// \param flags - Context attach flags (must be 0)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxDetach,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    pub fn cuCtxAttach(pctx: *mut CUcontext, flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Decrement a context's usage-count
    ///
    /// \deprecated
    ///
    /// Note that this function is deprecated and should not be used.
    ///
    /// Decrements the usage count of the context \p ctx, and destroys the context
    /// if the usage count goes to 0. The context must be a handle that was passed
    /// back by ::cuCtxCreate() or ::cuCtxAttach(), and must be current to the
    /// calling thread.
    ///
    /// \param ctx - Context to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    pub fn cuCtxDetach(ctx: CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Loads a compute module
    ///
    /// Takes a filename \p fname and loads the corresponding module \p module into
    /// the current context. The CUDA driver API does not attempt to lazily
    /// allocate the resources needed by a module; if the memory for functions and
    /// data (constant and global) needed by the module cannot be allocated,
    /// ::cuModuleLoad() fails. The file should be a \e cubin file as output by
    /// \b nvcc, or a \e PTX file either as output by \b nvcc or handwritten, or
    /// a \e fatbin file as output by \b nvcc from toolchain 4.0 or later.
    ///
    /// \param module - Returned module
    /// \param fname  - Filename of module to load
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_NOT_FOUND,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_FILE_NOT_FOUND,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,
    /// ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    pub fn cuModuleLoad(module: *mut CUmodule, fname: *const ::std::os::raw::c_char) -> CUresult;
}
extern "C" {
    /// \brief Load a module's data
    ///
    /// Takes a pointer \p image and loads the corresponding module \p module into
    /// the current context. The pointer may be obtained by mapping a \e cubin or
    /// \e PTX or \e fatbin file, passing a \e cubin or \e PTX or \e fatbin file
    /// as a NULL-terminated text string, or incorporating a \e cubin or \e fatbin
    /// object into the executable resources and using operating system calls such
    /// as Windows \c FindResource() to obtain the pointer.
    ///
    /// \param module - Returned module
    /// \param image  - Module data to load
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,
    /// ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    pub fn cuModuleLoadData(
        module: *mut CUmodule,
        image: *const ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Load a module's data with options
    ///
    /// Takes a pointer \p image and loads the corresponding module \p module into
    /// the current context. The pointer may be obtained by mapping a \e cubin or
    /// \e PTX or \e fatbin file, passing a \e cubin or \e PTX or \e fatbin file
    /// as a NULL-terminated text string, or incorporating a \e cubin or \e fatbin
    /// object into the executable resources and using operating system calls such
    /// as Windows \c FindResource() to obtain the pointer. Options are passed as
    /// an array via \p options and any corresponding parameters are passed in
    /// \p optionValues. The number of total options is supplied via \p numOptions.
    /// Any outputs will be returned via \p optionValues.
    ///
    /// \param module       - Returned module
    /// \param image        - Module data to load
    /// \param numOptions   - Number of options
    /// \param options      - Options for JIT
    /// \param optionValues - Option values for JIT
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,
    /// ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    pub fn cuModuleLoadDataEx(
        module: *mut CUmodule,
        image: *const ::std::os::raw::c_void,
        numOptions: ::std::os::raw::c_uint,
        options: *mut CUjit_option,
        optionValues: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Load a module's data
    ///
    /// Takes a pointer \p fatCubin and loads the corresponding module \p module
    /// into the current context. The pointer represents a <i>fat binary</i> object,
    /// which is a collection of different \e cubin and/or \e PTX files, all
    /// representing the same device code, but compiled and optimized for different
    /// architectures.
    ///
    /// Prior to CUDA 4.0, there was no documented API for constructing and using
    /// fat binary objects by programmers.  Starting with CUDA 4.0, fat binary
    /// objects can be constructed by providing the <i>-fatbin option</i> to \b nvcc.
    /// More information can be found in the \b nvcc document.
    ///
    /// \param module   - Returned module
    /// \param fatCubin - Fat binary to load
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_NOT_FOUND,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,
    /// ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleUnload
    pub fn cuModuleLoadFatBinary(
        module: *mut CUmodule,
        fatCubin: *const ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Unloads a module
    ///
    /// Unloads a module \p hmod from the current context.
    ///
    /// \param hmod - Module to unload
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary
    pub fn cuModuleUnload(hmod: CUmodule) -> CUresult;
}
extern "C" {
    /// \brief Returns a function handle
    ///
    /// Returns in \p *hfunc the handle of the function of name \p name located in
    /// module \p hmod. If no function of that name exists, ::cuModuleGetFunction()
    /// returns ::CUDA_ERROR_NOT_FOUND.
    ///
    /// \param hfunc - Returned function handle
    /// \param hmod  - Module to retrieve function from
    /// \param name  - Name of function to retrieve
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    pub fn cuModuleGetFunction(
        hfunc: *mut CUfunction,
        hmod: CUmodule,
        name: *const ::std::os::raw::c_char,
    ) -> CUresult;
}
extern "C" {
    pub fn cuModuleGetGlobal_v2(
        dptr: *mut CUdeviceptr,
        bytes: *mut usize,
        hmod: CUmodule,
        name: *const ::std::os::raw::c_char,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a texture reference
    ///
    /// Returns in \p *pTexRef the handle of the texture reference of name \p name
    /// in the module \p hmod. If no texture reference of that name exists,
    /// ::cuModuleGetTexRef() returns ::CUDA_ERROR_NOT_FOUND. This texture reference
    /// handle should not be destroyed, since it will be destroyed when the module
    /// is unloaded.
    ///
    /// \param pTexRef  - Returned texture reference
    /// \param hmod     - Module to retrieve texture reference from
    /// \param name     - Name of texture reference to retrieve
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetSurfRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload,
    /// ::cudaGetTextureReference
    pub fn cuModuleGetTexRef(
        pTexRef: *mut CUtexref,
        hmod: CUmodule,
        name: *const ::std::os::raw::c_char,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a surface reference
    ///
    /// Returns in \p *pSurfRef the handle of the surface reference of name \p name
    /// in the module \p hmod. If no surface reference of that name exists,
    /// ::cuModuleGetSurfRef() returns ::CUDA_ERROR_NOT_FOUND.
    ///
    /// \param pSurfRef  - Returned surface reference
    /// \param hmod     - Module to retrieve surface reference from
    /// \param name     - Name of surface reference to retrieve
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload,
    /// ::cudaGetSurfaceReference
    pub fn cuModuleGetSurfRef(
        pSurfRef: *mut CUsurfref,
        hmod: CUmodule,
        name: *const ::std::os::raw::c_char,
    ) -> CUresult;
}
extern "C" {
    pub fn cuLinkCreate_v2(
        numOptions: ::std::os::raw::c_uint,
        options: *mut CUjit_option,
        optionValues: *mut *mut ::std::os::raw::c_void,
        stateOut: *mut CUlinkState,
    ) -> CUresult;
}
extern "C" {
    pub fn cuLinkAddData_v2(
        state: CUlinkState,
        type_: CUjitInputType,
        data: *mut ::std::os::raw::c_void,
        size: usize,
        name: *const ::std::os::raw::c_char,
        numOptions: ::std::os::raw::c_uint,
        options: *mut CUjit_option,
        optionValues: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    pub fn cuLinkAddFile_v2(
        state: CUlinkState,
        type_: CUjitInputType,
        path: *const ::std::os::raw::c_char,
        numOptions: ::std::os::raw::c_uint,
        options: *mut CUjit_option,
        optionValues: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Complete a pending linker invocation
    ///
    /// Completes the pending linker action and returns the cubin image for the linked
    /// device code, which can be used with ::cuModuleLoadData.  The cubin is owned by
    /// \p state, so it should be loaded before \p state is destroyed via ::cuLinkDestroy.
    /// This call does not destroy \p state.
    ///
    /// \param state    A pending linker invocation
    /// \param cubinOut On success, this will point to the output image
    /// \param sizeOut  Optional parameter to receive the size of the generated image
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    ///
    /// \sa ::cuLinkCreate,
    /// ::cuLinkAddData,
    /// ::cuLinkAddFile,
    /// ::cuLinkDestroy,
    /// ::cuModuleLoadData
    pub fn cuLinkComplete(
        state: CUlinkState,
        cubinOut: *mut *mut ::std::os::raw::c_void,
        sizeOut: *mut usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Destroys state for a JIT linker invocation.
    ///
    /// \param state State object for the linker invocation
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE
    ///
    /// \sa ::cuLinkCreate
    pub fn cuLinkDestroy(state: CUlinkState) -> CUresult;
}
extern "C" {
    pub fn cuMemGetInfo_v2(free: *mut usize, total: *mut usize) -> CUresult;
}
extern "C" {
    pub fn cuMemAlloc_v2(dptr: *mut CUdeviceptr, bytesize: usize) -> CUresult;
}
extern "C" {
    pub fn cuMemAllocPitch_v2(
        dptr: *mut CUdeviceptr,
        pPitch: *mut usize,
        WidthInBytes: usize,
        Height: usize,
        ElementSizeBytes: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemFree_v2(dptr: CUdeviceptr) -> CUresult;
}
extern "C" {
    pub fn cuMemGetAddressRange_v2(
        pbase: *mut CUdeviceptr,
        psize: *mut usize,
        dptr: CUdeviceptr,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemAllocHost_v2(pp: *mut *mut ::std::os::raw::c_void, bytesize: usize) -> CUresult;
}
extern "C" {
    /// \brief Frees page-locked host memory
    ///
    /// Frees the memory space pointed to by \p p, which must have been returned by
    /// a previous call to ::cuMemAllocHost().
    ///
    /// \param p - Pointer to memory to free
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32,
    /// ::cudaFreeHost
    pub fn cuMemFreeHost(p: *mut ::std::os::raw::c_void) -> CUresult;
}
extern "C" {
    /// \brief Allocates page-locked host memory
    ///
    /// Allocates \p bytesize bytes of host memory that is page-locked and accessible
    /// to the device. The driver tracks the virtual memory ranges allocated with
    /// this function and automatically accelerates calls to functions such as
    /// ::cuMemcpyHtoD(). Since the memory can be accessed directly by the device,
    /// it can be read or written with much higher bandwidth than pageable memory
    /// obtained with functions such as ::malloc(). Allocating excessive amounts of
    /// pinned memory may degrade system performance, since it reduces the amount
    /// of memory available to the system for paging. As a result, this function is
    /// best used sparingly to allocate staging areas for data exchange between
    /// host and device.
    ///
    /// The \p Flags parameter enables different options to be specified that
    /// affect the allocation, as follows.
    ///
    /// - ::CU_MEMHOSTALLOC_PORTABLE: The memory returned by this call will be
    ///   considered as pinned memory by all CUDA contexts, not just the one that
    ///   performed the allocation.
    ///
    /// - ::CU_MEMHOSTALLOC_DEVICEMAP: Maps the allocation into the CUDA address
    ///   space. The device pointer to the memory may be obtained by calling
    ///   ::cuMemHostGetDevicePointer().
    ///
    /// - ::CU_MEMHOSTALLOC_WRITECOMBINED: Allocates the memory as write-combined
    ///   (WC). WC memory can be transferred across the PCI Express bus more
    ///   quickly on some system configurations, but cannot be read efficiently by
    ///   most CPUs. WC memory is a good option for buffers that will be written by
    ///   the CPU and read by the GPU via mapped pinned memory or host->device
    ///   transfers.
    ///
    /// All of these flags are orthogonal to one another: a developer may allocate
    /// memory that is portable, mapped and/or write-combined with no restrictions.
    ///
    /// The CUDA context must have been created with the ::CU_CTX_MAP_HOST flag in
    /// order for the ::CU_MEMHOSTALLOC_DEVICEMAP flag to have any effect.
    ///
    /// The ::CU_MEMHOSTALLOC_DEVICEMAP flag may be specified on CUDA contexts for
    /// devices that do not support mapped pinned memory. The failure is deferred
    /// to ::cuMemHostGetDevicePointer() because the memory may be mapped into
    /// other CUDA contexts via the ::CU_MEMHOSTALLOC_PORTABLE flag.
    ///
    /// The memory allocated by this function must be freed with ::cuMemFreeHost().
    ///
    /// Note all host memory allocated using ::cuMemHostAlloc() will automatically
    /// be immediately accessible to all contexts on all devices which support unified
    /// addressing (as may be queried using ::CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING).
    /// Unless the flag ::CU_MEMHOSTALLOC_WRITECOMBINED is specified, the device pointer
    /// that may be used to access this host memory from those contexts is always equal
    /// to the returned host pointer \p *pp.  If the flag ::CU_MEMHOSTALLOC_WRITECOMBINED
    /// is specified, then the function ::cuMemHostGetDevicePointer() must be used
    /// to query the device pointer, even if the context supports unified addressing.
    /// See \ref CUDA_UNIFIED for additional details.
    ///
    /// \param pp       - Returned host pointer to page-locked memory
    /// \param bytesize - Requested allocation size in bytes
    /// \param Flags    - Flags for allocation request
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32,
    /// ::cudaHostAlloc
    pub fn cuMemHostAlloc(
        pp: *mut *mut ::std::os::raw::c_void,
        bytesize: usize,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemHostGetDevicePointer_v2(
        pdptr: *mut CUdeviceptr,
        p: *mut ::std::os::raw::c_void,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Passes back flags that were used for a pinned allocation
    ///
    /// Passes back the flags \p pFlags that were specified when allocating
    /// the pinned host buffer \p p allocated by ::cuMemHostAlloc.
    ///
    /// ::cuMemHostGetFlags() will fail if the pointer does not reside in
    /// an allocation performed by ::cuMemAllocHost() or ::cuMemHostAlloc().
    ///
    /// \param pFlags - Returned flags word
    /// \param p     - Host pointer
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemAllocHost,
    /// ::cuMemHostAlloc,
    /// ::cudaHostGetFlags
    pub fn cuMemHostGetFlags(
        pFlags: *mut ::std::os::raw::c_uint,
        p: *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Allocates memory that will be automatically managed by the Unified Memory system
    ///
    /// Allocates \p bytesize bytes of managed memory on the device and returns in
    /// \p *dptr a pointer to the allocated memory. If the device doesn't support
    /// allocating managed memory, ::CUDA_ERROR_NOT_SUPPORTED is returned. Support
    /// for managed memory can be queried using the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY. The allocated memory is suitably
    /// aligned for any kind of variable. The memory is not cleared. If \p bytesize
    /// is 0, ::cuMemAllocManaged returns ::CUDA_ERROR_INVALID_VALUE. The pointer
    /// is valid on the CPU and on all GPUs in the system that support managed memory.
    /// All accesses to this pointer must obey the Unified Memory programming model.
    ///
    /// \p flags specifies the default stream association for this allocation.
    /// \p flags must be one of ::CU_MEM_ATTACH_GLOBAL or ::CU_MEM_ATTACH_HOST. If
    /// ::CU_MEM_ATTACH_GLOBAL is specified, then this memory is accessible from
    /// any stream on any device. If ::CU_MEM_ATTACH_HOST is specified, then the
    /// allocation should not be accessed from devices that have a zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS; an explicit call to
    /// ::cuStreamAttachMemAsync will be required to enable access on such devices.
    ///
    /// If the association is later changed via ::cuStreamAttachMemAsync to
    /// a single stream, the default association as specifed during ::cuMemAllocManaged
    /// is restored when that stream is destroyed. For __managed__ variables, the
    /// default association is always ::CU_MEM_ATTACH_GLOBAL. Note that destroying a
    /// stream is an asynchronous operation, and as a result, the change to default
    /// association won't happen until all work in the stream has completed.
    ///
    /// Memory allocated with ::cuMemAllocManaged should be released with ::cuMemFree.
    ///
    /// Device memory oversubscription is possible for GPUs that have a non-zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS. Managed memory on
    /// such GPUs may be evicted from device memory to host memory at any time by the Unified
    /// Memory driver in order to make room for other allocations.
    ///
    /// In a multi-GPU system where all GPUs have a non-zero value for the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS, managed memory may not be populated when this
    /// API returns and instead may be populated on access. In such systems, managed memory can
    /// migrate to any processor's memory at any time. The Unified Memory driver will employ heuristics to
    /// maintain data locality and prevent excessive page faults to the extent possible. The application
    /// can also guide the driver about memory usage patterns via ::cuMemAdvise. The application
    /// can also explicitly migrate memory to a desired processor's memory via
    /// ::cuMemPrefetchAsync.
    ///
    /// In a multi-GPU system where all of the GPUs have a zero value for the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS and all the GPUs have peer-to-peer support
    /// with each other, the physical storage for managed memory is created on the GPU which is active
    /// at the time ::cuMemAllocManaged is called. All other GPUs will reference the data at reduced
    /// bandwidth via peer mappings over the PCIe bus. The Unified Memory driver does not migrate
    /// memory among such GPUs.
    ///
    /// In a multi-GPU system where not all GPUs have peer-to-peer support with each other and
    /// where the value of the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS
    /// is zero for at least one of those GPUs, the location chosen for physical storage of managed
    /// memory is system-dependent.
    /// - On Linux, the location chosen will be device memory as long as the current set of active
    /// contexts are on devices that either have peer-to-peer support with each other or have a
    /// non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    /// If there is an active context on a GPU that does not have a non-zero value for that device
    /// attribute and it does not have peer-to-peer support with the other devices that have active
    /// contexts on them, then the location for physical storage will be 'zero-copy' or host memory.
    /// Note that this means that managed memory that is located in device memory is migrated to
    /// host memory if a new context is created on a GPU that doesn't have a non-zero value for
    /// the device attribute and does not support peer-to-peer with at least one of the other devices
    /// that has an active context. This in turn implies that context creation may fail if there is
    /// insufficient host memory to migrate all managed allocations.
    /// - On Windows, the physical storage is always created in 'zero-copy' or host memory.
    /// All GPUs will reference the data at reduced bandwidth over the PCIe bus. In these
    /// circumstances, use of the environment variable CUDA_VISIBLE_DEVICES is recommended to
    /// restrict CUDA to only use those GPUs that have peer-to-peer support.
    /// Alternatively, users can also set CUDA_MANAGED_FORCE_DEVICE_ALLOC to a
    /// non-zero value to force the driver to always use device memory for physical storage.
    /// When this environment variable is set to a non-zero value, all contexts created in
    /// that process on devices that support managed memory have to be peer-to-peer compatible
    /// with each other. Context creation will fail if a context is created on a device that
    /// supports managed memory and is not peer-to-peer compatible with any of the other
    /// managed memory supporting devices on which contexts were previously created, even if
    /// those contexts have been destroyed. These environment variables are described
    /// in the CUDA programming guide under the "CUDA environment variables" section.
    /// - On ARM, managed memory is not available on discrete gpu with Drive PX-2.
    ///
    /// \param dptr     - Returned device pointer
    /// \param bytesize - Requested allocation size in bytes
    /// \param flags    - Must be one of ::CU_MEM_ATTACH_GLOBAL or ::CU_MEM_ATTACH_HOST
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_NOT_SUPPORTED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32,
    /// ::cuDeviceGetAttribute, ::cuStreamAttachMemAsync,
    /// ::cudaMallocManaged
    pub fn cuMemAllocManaged(
        dptr: *mut CUdeviceptr,
        bytesize: usize,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a compute device
    ///
    /// Returns in \p *device a device handle given a PCI bus ID string.
    ///
    /// \param dev      - Returned device handle
    ///
    /// \param pciBusId - String in one of the following forms:
    /// [domain]:[bus]:[device].[function]
    /// [domain]:[bus]:[device]
    /// [bus]:[device].[function]
    /// where \p domain, \p bus, \p device, and \p function are all hexadecimal values
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGet,
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetPCIBusId,
    /// ::cudaDeviceGetByPCIBusId
    pub fn cuDeviceGetByPCIBusId(
        dev: *mut CUdevice,
        pciBusId: *const ::std::os::raw::c_char,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a PCI Bus Id string for the device
    ///
    /// Returns an ASCII string identifying the device \p dev in the NULL-terminated
    /// string pointed to by \p pciBusId. \p len specifies the maximum length of the
    /// string that may be returned.
    ///
    /// \param pciBusId - Returned identifier string for the device in the following format
    /// [domain]:[bus]:[device].[function]
    /// where \p domain, \p bus, \p device, and \p function are all hexadecimal values.
    /// pciBusId should be large enough to store 13 characters including the NULL-terminator.
    ///
    /// \param len      - Maximum length of string to store in \p name
    ///
    /// \param dev      - Device to get identifier string for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGet,
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetByPCIBusId,
    /// ::cudaDeviceGetPCIBusId
    pub fn cuDeviceGetPCIBusId(
        pciBusId: *mut ::std::os::raw::c_char,
        len: ::std::os::raw::c_int,
        dev: CUdevice,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets an interprocess handle for a previously allocated event
    ///
    /// Takes as input a previously allocated event. This event must have been
    /// created with the ::CU_EVENT_INTERPROCESS and ::CU_EVENT_DISABLE_TIMING
    /// flags set. This opaque handle may be copied into other processes and
    /// opened with ::cuIpcOpenEventHandle to allow efficient hardware
    /// synchronization between GPU work in different processes.
    ///
    /// After the event has been opened in the importing process,
    /// ::cuEventRecord, ::cuEventSynchronize, ::cuStreamWaitEvent and
    /// ::cuEventQuery may be used in either process. Performing operations
    /// on the imported event after the exported event has been freed
    /// with ::cuEventDestroy will result in undefined behavior.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux and Windows operating systems.
    /// IPC functionality on Windows is restricted to GPUs in TCC mode.
    /// IPC functionality is not supported on Tegra platforms.
    ///
    /// \param pHandle - Pointer to a user allocated CUipcEventHandle
    ///                    in which to return the opaque event handle
    /// \param event   - Event allocated with ::CU_EVENT_INTERPROCESS and
    ///                    ::CU_EVENT_DISABLE_TIMING flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuEventCreate,
    /// ::cuEventDestroy,
    /// ::cuEventSynchronize,
    /// ::cuEventQuery,
    /// ::cuStreamWaitEvent,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcOpenMemHandle,
    /// ::cuIpcCloseMemHandle,
    /// ::cudaIpcGetEventHandle
    pub fn cuIpcGetEventHandle(pHandle: *mut CUipcEventHandle, event: CUevent) -> CUresult;
}
extern "C" {
    /// \brief Opens an interprocess event handle for use in the current process
    ///
    /// Opens an interprocess event handle exported from another process with
    /// ::cuIpcGetEventHandle. This function returns a ::CUevent that behaves like
    /// a locally created event with the ::CU_EVENT_DISABLE_TIMING flag specified.
    /// This event must be freed with ::cuEventDestroy.
    ///
    /// Performing operations on the imported event after the exported event has
    /// been freed with ::cuEventDestroy will result in undefined behavior.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux and Windows operating systems.
    /// IPC functionality on Windows is restricted to GPUs in TCC mode.
    /// IPC functionality is not supported on Tegra platforms.
    ///
    /// \param phEvent - Returns the imported event
    /// \param handle  - Interprocess handle to open
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_PEER_ACCESS_UNSUPPORTED,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuEventCreate,
    /// ::cuEventDestroy,
    /// ::cuEventSynchronize,
    /// ::cuEventQuery,
    /// ::cuStreamWaitEvent,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcOpenMemHandle,
    /// ::cuIpcCloseMemHandle,
    /// ::cudaIpcOpenEventHandle
    pub fn cuIpcOpenEventHandle(phEvent: *mut CUevent, handle: CUipcEventHandle) -> CUresult;
}
extern "C" {
    /// \brief Gets an interprocess memory handle for an existing device memory
    /// allocation
    ///
    /// Takes a pointer to the base of an existing device memory allocation created
    /// with ::cuMemAlloc and exports it for use in another process. This is a
    /// lightweight operation and may be called multiple times on an allocation
    /// without adverse effects.
    ///
    /// If a region of memory is freed with ::cuMemFree and a subsequent call
    /// to ::cuMemAlloc returns memory with the same device address,
    /// ::cuIpcGetMemHandle will return a unique handle for the
    /// new memory.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux and Windows operating systems.
    /// IPC functionality on Windows is restricted to GPUs in TCC mode.
    /// IPC functionality is not supported on Tegra platforms.
    ///
    /// \param pHandle - Pointer to user allocated ::CUipcMemHandle to return
    ///                    the handle in.
    /// \param dptr    - Base pointer to previously allocated device memory
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcOpenMemHandle,
    /// ::cuIpcCloseMemHandle,
    /// ::cudaIpcGetMemHandle
    pub fn cuIpcGetMemHandle(pHandle: *mut CUipcMemHandle, dptr: CUdeviceptr) -> CUresult;
}
extern "C" {
    /// \brief Opens an interprocess memory handle exported from another process
    /// and returns a device pointer usable in the local process.
    ///
    /// Maps memory exported from another process with ::cuIpcGetMemHandle into
    /// the current device address space. For contexts on different devices
    /// ::cuIpcOpenMemHandle can attempt to enable peer access between the
    /// devices as if the user called ::cuCtxEnablePeerAccess. This behavior is
    /// controlled by the ::CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS flag.
    /// ::cuDeviceCanAccessPeer can determine if a mapping is possible.
    ///
    /// Contexts that may open ::CUipcMemHandles are restricted in the following way.
    /// ::CUipcMemHandles from each ::CUdevice in a given process may only be opened
    /// by one ::CUcontext per ::CUdevice per other process.
    ///
    /// Memory returned from ::cuIpcOpenMemHandle must be freed with
    /// ::cuIpcCloseMemHandle.
    ///
    /// Calling ::cuMemFree on an exported memory region before calling
    /// ::cuIpcCloseMemHandle in the importing context will result in undefined
    /// behavior.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux and Windows operating systems.
    /// IPC functionality on Windows is restricted to GPUs in TCC mode.
    /// IPC functionality is not supported on Tegra platforms.
    ///
    /// \param pdptr  - Returned device pointer
    /// \param handle - ::CUipcMemHandle to open
    /// \param Flags  - Flags for this operation. Must be specified as ::CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_TOO_MANY_PEERS,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \note No guarantees are made about the address returned in \p *pdptr.
    /// In particular, multiple processes may not receive the same address for the same \p handle.
    ///
    /// \sa
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcCloseMemHandle,
    /// ::cuCtxEnablePeerAccess,
    /// ::cuDeviceCanAccessPeer,
    /// ::cudaIpcOpenMemHandle
    pub fn cuIpcOpenMemHandle(
        pdptr: *mut CUdeviceptr,
        handle: CUipcMemHandle,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Close memory mapped with ::cuIpcOpenMemHandle
    ///
    /// Unmaps memory returnd by ::cuIpcOpenMemHandle. The original allocation
    /// in the exporting process as well as imported mappings in other processes
    /// will be unaffected.
    ///
    /// Any resources used to enable peer access will be freed if this is the
    /// last mapping using them.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux and Windows operating systems.
    /// IPC functionality on Windows is restricted to GPUs in TCC mode.
    /// IPC functionality is not supported on Tegra platforms.
    ///
    /// \param dptr - Device pointer returned by ::cuIpcOpenMemHandle
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \sa
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcOpenMemHandle,
    /// ::cudaIpcCloseMemHandle
    pub fn cuIpcCloseMemHandle(dptr: CUdeviceptr) -> CUresult;
}
extern "C" {
    pub fn cuMemHostRegister_v2(
        p: *mut ::std::os::raw::c_void,
        bytesize: usize,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Unregisters a memory range that was registered with cuMemHostRegister.
    ///
    /// Unmaps the memory range whose base address is specified by \p p, and makes
    /// it pageable again.
    ///
    /// The base address must be the same one specified to ::cuMemHostRegister().
    ///
    /// \param p - Host pointer to memory to unregister
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_HOST_MEMORY_NOT_REGISTERED,
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemHostRegister,
    /// ::cudaHostUnregister
    pub fn cuMemHostUnregister(p: *mut ::std::os::raw::c_void) -> CUresult;
}
extern "C" {
    /// \brief Copies memory
    ///
    /// Copies data between two pointers.
    /// \p dst and \p src are base pointers of the destination and source, respectively.
    /// \p ByteCount specifies the number of bytes to copy.
    /// Note that this function infers the type of the transfer (host to host, host to
    ///   device, device to device, or device to host) from the pointer values.  This
    ///   function is only allowed in contexts which support unified addressing.
    ///
    /// \param dst - Destination unified virtual address space pointer
    /// \param src - Source unified virtual address space pointer
    /// \param ByteCount - Size of memory copy in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_sync
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32,
    /// ::cudaMemcpy,
    /// ::cudaMemcpyToSymbol,
    /// ::cudaMemcpyFromSymbol
    pub fn cuMemcpy(dst: CUdeviceptr, src: CUdeviceptr, ByteCount: usize) -> CUresult;
}
extern "C" {
    /// \brief Copies device memory between two contexts
    ///
    /// Copies from device memory in one context to device memory in another
    /// context. \p dstDevice is the base device pointer of the destination memory
    /// and \p dstContext is the destination context.  \p srcDevice is the base
    /// device pointer of the source memory and \p srcContext is the source pointer.
    /// \p ByteCount specifies the number of bytes to copy.
    ///
    /// \param dstDevice  - Destination device pointer
    /// \param dstContext - Destination context
    /// \param srcDevice  - Source device pointer
    /// \param srcContext - Source context
    /// \param ByteCount  - Size of memory copy in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_sync
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpy3DPeer, ::cuMemcpyDtoDAsync, ::cuMemcpyPeerAsync,
    /// ::cuMemcpy3DPeerAsync,
    /// ::cudaMemcpyPeer
    pub fn cuMemcpyPeer(
        dstDevice: CUdeviceptr,
        dstContext: CUcontext,
        srcDevice: CUdeviceptr,
        srcContext: CUcontext,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoD_v2(
        dstDevice: CUdeviceptr,
        srcHost: *const ::std::os::raw::c_void,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoH_v2(
        dstHost: *mut ::std::os::raw::c_void,
        srcDevice: CUdeviceptr,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoD_v2(
        dstDevice: CUdeviceptr,
        srcDevice: CUdeviceptr,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoA_v2(
        dstArray: CUarray,
        dstOffset: usize,
        srcDevice: CUdeviceptr,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoD_v2(
        dstDevice: CUdeviceptr,
        srcArray: CUarray,
        srcOffset: usize,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoA_v2(
        dstArray: CUarray,
        dstOffset: usize,
        srcHost: *const ::std::os::raw::c_void,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoH_v2(
        dstHost: *mut ::std::os::raw::c_void,
        srcArray: CUarray,
        srcOffset: usize,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoA_v2(
        dstArray: CUarray,
        dstOffset: usize,
        srcArray: CUarray,
        srcOffset: usize,
        ByteCount: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpy2D_v2(pCopy: *const CUDA_MEMCPY2D) -> CUresult;
}
extern "C" {
    pub fn cuMemcpy2DUnaligned_v2(pCopy: *const CUDA_MEMCPY2D) -> CUresult;
}
extern "C" {
    pub fn cuMemcpy3D_v2(pCopy: *const CUDA_MEMCPY3D) -> CUresult;
}
extern "C" {
    /// \brief Copies memory between contexts
    ///
    /// Perform a 3D memory copy according to the parameters specified in
    /// \p pCopy.  See the definition of the ::CUDA_MEMCPY3D_PEER structure
    /// for documentation of its parameters.
    ///
    /// \param pCopy - Parameters for the memory copy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_sync
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpyPeer, ::cuMemcpyDtoDAsync, ::cuMemcpyPeerAsync,
    /// ::cuMemcpy3DPeerAsync,
    /// ::cudaMemcpy3DPeer
    pub fn cuMemcpy3DPeer(pCopy: *const CUDA_MEMCPY3D_PEER) -> CUresult;
}
extern "C" {
    /// \brief Copies memory asynchronously
    ///
    /// Copies data between two pointers.
    /// \p dst and \p src are base pointers of the destination and source, respectively.
    /// \p ByteCount specifies the number of bytes to copy.
    /// Note that this function infers the type of the transfer (host to host, host to
    ///   device, device to device, or device to host) from the pointer values.  This
    ///   function is only allowed in contexts which support unified addressing.
    ///
    /// \param dst       - Destination unified virtual address space pointer
    /// \param src       - Source unified virtual address space pointer
    /// \param ByteCount - Size of memory copy in bytes
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async,
    /// ::cudaMemcpyAsync,
    /// ::cudaMemcpyToSymbolAsync,
    /// ::cudaMemcpyFromSymbolAsync
    pub fn cuMemcpyAsync(
        dst: CUdeviceptr,
        src: CUdeviceptr,
        ByteCount: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Copies device memory between two contexts asynchronously.
    ///
    /// Copies from device memory in one context to device memory in another
    /// context. \p dstDevice is the base device pointer of the destination memory
    /// and \p dstContext is the destination context.  \p srcDevice is the base
    /// device pointer of the source memory and \p srcContext is the source pointer.
    /// \p ByteCount specifies the number of bytes to copy.
    ///
    /// \param dstDevice  - Destination device pointer
    /// \param dstContext - Destination context
    /// \param srcDevice  - Source device pointer
    /// \param srcContext - Source context
    /// \param ByteCount  - Size of memory copy in bytes
    /// \param hStream    - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpyPeer, ::cuMemcpy3DPeer, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpy3DPeerAsync,
    /// ::cudaMemcpyPeerAsync
    pub fn cuMemcpyPeerAsync(
        dstDevice: CUdeviceptr,
        dstContext: CUcontext,
        srcDevice: CUdeviceptr,
        srcContext: CUcontext,
        ByteCount: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoDAsync_v2(
        dstDevice: CUdeviceptr,
        srcHost: *const ::std::os::raw::c_void,
        ByteCount: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoHAsync_v2(
        dstHost: *mut ::std::os::raw::c_void,
        srcDevice: CUdeviceptr,
        ByteCount: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoDAsync_v2(
        dstDevice: CUdeviceptr,
        srcDevice: CUdeviceptr,
        ByteCount: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoAAsync_v2(
        dstArray: CUarray,
        dstOffset: usize,
        srcHost: *const ::std::os::raw::c_void,
        ByteCount: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoHAsync_v2(
        dstHost: *mut ::std::os::raw::c_void,
        srcArray: CUarray,
        srcOffset: usize,
        ByteCount: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemcpy2DAsync_v2(pCopy: *const CUDA_MEMCPY2D, hStream: CUstream) -> CUresult;
}
extern "C" {
    pub fn cuMemcpy3DAsync_v2(pCopy: *const CUDA_MEMCPY3D, hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Copies memory between contexts asynchronously.
    ///
    /// Perform a 3D memory copy according to the parameters specified in
    /// \p pCopy.  See the definition of the ::CUDA_MEMCPY3D_PEER structure
    /// for documentation of its parameters.
    ///
    /// \param pCopy - Parameters for the memory copy
    /// \param hStream - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpyPeer, ::cuMemcpyDtoDAsync, ::cuMemcpyPeerAsync,
    /// ::cuMemcpy3DPeerAsync,
    /// ::cudaMemcpy3DPeerAsync
    pub fn cuMemcpy3DPeerAsync(pCopy: *const CUDA_MEMCPY3D_PEER, hStream: CUstream) -> CUresult;
}
extern "C" {
    pub fn cuMemsetD8_v2(dstDevice: CUdeviceptr, uc: ::std::os::raw::c_uchar, N: usize)
        -> CUresult;
}
extern "C" {
    pub fn cuMemsetD16_v2(
        dstDevice: CUdeviceptr,
        us: ::std::os::raw::c_ushort,
        N: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemsetD32_v2(dstDevice: CUdeviceptr, ui: ::std::os::raw::c_uint, N: usize)
        -> CUresult;
}
extern "C" {
    pub fn cuMemsetD2D8_v2(
        dstDevice: CUdeviceptr,
        dstPitch: usize,
        uc: ::std::os::raw::c_uchar,
        Width: usize,
        Height: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemsetD2D16_v2(
        dstDevice: CUdeviceptr,
        dstPitch: usize,
        us: ::std::os::raw::c_ushort,
        Width: usize,
        Height: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuMemsetD2D32_v2(
        dstDevice: CUdeviceptr,
        dstPitch: usize,
        ui: ::std::os::raw::c_uint,
        Width: usize,
        Height: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the memory range of \p N 8-bit values to the specified value
    /// \p uc.
    ///
    /// \param dstDevice - Destination device pointer
    /// \param uc        - Value to set
    /// \param N         - Number of elements
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async,
    /// ::cudaMemsetAsync
    pub fn cuMemsetD8Async(
        dstDevice: CUdeviceptr,
        uc: ::std::os::raw::c_uchar,
        N: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the memory range of \p N 16-bit values to the specified value
    /// \p us. The \p dstDevice pointer must be two byte aligned.
    ///
    /// \param dstDevice - Destination device pointer
    /// \param us        - Value to set
    /// \param N         - Number of elements
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16,
    /// ::cuMemsetD32, ::cuMemsetD32Async,
    /// ::cudaMemsetAsync
    pub fn cuMemsetD16Async(
        dstDevice: CUdeviceptr,
        us: ::std::os::raw::c_ushort,
        N: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the memory range of \p N 32-bit values to the specified value
    /// \p ui. The \p dstDevice pointer must be four byte aligned.
    ///
    /// \param dstDevice - Destination device pointer
    /// \param ui        - Value to set
    /// \param N         - Number of elements
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async, ::cuMemsetD32,
    /// ::cudaMemsetAsync
    pub fn cuMemsetD32Async(
        dstDevice: CUdeviceptr,
        ui: ::std::os::raw::c_uint,
        N: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the 2D memory range of \p Width 8-bit values to the specified value
    /// \p uc. \p Height specifies the number of rows to set, and \p dstPitch
    /// specifies the number of bytes between each row. This function performs
    /// fastest when the pitch is one that has been passed back by
    /// ::cuMemAllocPitch().
    ///
    /// \param dstDevice - Destination device pointer
    /// \param dstPitch  - Pitch of destination device pointer
    /// \param uc        - Value to set
    /// \param Width     - Width of row
    /// \param Height    - Number of rows
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async,
    /// ::cudaMemset2DAsync
    pub fn cuMemsetD2D8Async(
        dstDevice: CUdeviceptr,
        dstPitch: usize,
        uc: ::std::os::raw::c_uchar,
        Width: usize,
        Height: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the 2D memory range of \p Width 16-bit values to the specified value
    /// \p us. \p Height specifies the number of rows to set, and \p dstPitch
    /// specifies the number of bytes between each row. The \p dstDevice pointer
    /// and \p dstPitch offset must be two byte aligned. This function performs
    /// fastest when the pitch is one that has been passed back by
    /// ::cuMemAllocPitch().
    ///
    /// \param dstDevice - Destination device pointer
    /// \param dstPitch  - Pitch of destination device pointer
    /// \param us        - Value to set
    /// \param Width     - Width of row
    /// \param Height    - Number of rows
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async,
    /// ::cudaMemset2DAsync
    pub fn cuMemsetD2D16Async(
        dstDevice: CUdeviceptr,
        dstPitch: usize,
        us: ::std::os::raw::c_ushort,
        Width: usize,
        Height: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the 2D memory range of \p Width 32-bit values to the specified value
    /// \p ui. \p Height specifies the number of rows to set, and \p dstPitch
    /// specifies the number of bytes between each row. The \p dstDevice pointer
    /// and \p dstPitch offset must be four byte aligned. This function performs
    /// fastest when the pitch is one that has been passed back by
    /// ::cuMemAllocPitch().
    ///
    /// \param dstDevice - Destination device pointer
    /// \param dstPitch  - Pitch of destination device pointer
    /// \param ui        - Value to set
    /// \param Width     - Width of row
    /// \param Height    - Number of rows
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async,
    /// ::cudaMemset2DAsync
    pub fn cuMemsetD2D32Async(
        dstDevice: CUdeviceptr,
        dstPitch: usize,
        ui: ::std::os::raw::c_uint,
        Width: usize,
        Height: usize,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    pub fn cuArrayCreate_v2(
        pHandle: *mut CUarray,
        pAllocateArray: *const CUDA_ARRAY_DESCRIPTOR,
    ) -> CUresult;
}
extern "C" {
    pub fn cuArrayGetDescriptor_v2(
        pArrayDescriptor: *mut CUDA_ARRAY_DESCRIPTOR,
        hArray: CUarray,
    ) -> CUresult;
}
extern "C" {
    /// \brief Destroys a CUDA array
    ///
    /// Destroys the CUDA array \p hArray.
    ///
    /// \param hArray - Array to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_ARRAY_IS_MAPPED,
    /// ::CUDA_ERROR_CONTEXT_IS_DESTROYED
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32,
    /// ::cudaFreeArray
    pub fn cuArrayDestroy(hArray: CUarray) -> CUresult;
}
extern "C" {
    pub fn cuArray3DCreate_v2(
        pHandle: *mut CUarray,
        pAllocateArray: *const CUDA_ARRAY3D_DESCRIPTOR,
    ) -> CUresult;
}
extern "C" {
    pub fn cuArray3DGetDescriptor_v2(
        pArrayDescriptor: *mut CUDA_ARRAY3D_DESCRIPTOR,
        hArray: CUarray,
    ) -> CUresult;
}
extern "C" {
    /// \brief Creates a CUDA mipmapped array
    ///
    /// Creates a CUDA mipmapped array according to the ::CUDA_ARRAY3D_DESCRIPTOR structure
    /// \p pMipmappedArrayDesc and returns a handle to the new CUDA mipmapped array in \p *pHandle.
    /// \p numMipmapLevels specifies the number of mipmap levels to be allocated. This value is
    /// clamped to the range [1, 1 + floor(log2(max(width, height, depth)))].
    ///
    /// The ::CUDA_ARRAY3D_DESCRIPTOR is defined as:
    ///
    /// \code
    ///typedef struct {
    ///unsigned int Width;
    ///unsigned int Height;
    ///unsigned int Depth;
    ///CUarray_format Format;
    ///unsigned int NumChannels;
    ///unsigned int Flags;
    ///} CUDA_ARRAY3D_DESCRIPTOR;
    /// \endcode
    /// where:
    ///
    /// - \p Width, \p Height, and \p Depth are the width, height, and depth of the
    /// CUDA array (in elements); the following types of CUDA arrays can be allocated:
    ///     - A 1D mipmapped array is allocated if \p Height and \p Depth extents are both zero.
    ///     - A 2D mipmapped array is allocated if only \p Depth extent is zero.
    ///     - A 3D mipmapped array is allocated if all three extents are non-zero.
    ///     - A 1D layered CUDA mipmapped array is allocated if only \p Height is zero and the
    ///       ::CUDA_ARRAY3D_LAYERED flag is set. Each layer is a 1D array. The number
    ///       of layers is determined by the depth extent.
    ///     - A 2D layered CUDA mipmapped array is allocated if all three extents are non-zero and
    ///       the ::CUDA_ARRAY3D_LAYERED flag is set. Each layer is a 2D array. The number
    ///       of layers is determined by the depth extent.
    ///     - A cubemap CUDA mipmapped array is allocated if all three extents are non-zero and the
    ///       ::CUDA_ARRAY3D_CUBEMAP flag is set. \p Width must be equal to \p Height, and
    ///       \p Depth must be six. A cubemap is a special type of 2D layered CUDA array,
    ///       where the six layers represent the six faces of a cube. The order of the six
    ///       layers in memory is the same as that listed in ::CUarray_cubemap_face.
    ///     - A cubemap layered CUDA mipmapped array is allocated if all three extents are non-zero,
    ///       and both, ::CUDA_ARRAY3D_CUBEMAP and ::CUDA_ARRAY3D_LAYERED flags are set.
    ///       \p Width must be equal to \p Height, and \p Depth must be a multiple of six.
    ///       A cubemap layered CUDA array is a special type of 2D layered CUDA array that
    ///       consists of a collection of cubemaps. The first six layers represent the first
    ///       cubemap, the next six layers form the second cubemap, and so on.
    ///
    /// - ::Format specifies the format of the elements; ::CUarray_format is
    /// defined as:
    /// \code
    ///typedef enum CUarray_format_enum {
    ///CU_AD_FORMAT_UNSIGNED_INT8 = 0x01,
    ///CU_AD_FORMAT_UNSIGNED_INT16 = 0x02,
    ///CU_AD_FORMAT_UNSIGNED_INT32 = 0x03,
    ///CU_AD_FORMAT_SIGNED_INT8 = 0x08,
    ///CU_AD_FORMAT_SIGNED_INT16 = 0x09,
    ///CU_AD_FORMAT_SIGNED_INT32 = 0x0a,
    ///CU_AD_FORMAT_HALF = 0x10,
    ///CU_AD_FORMAT_FLOAT = 0x20
    ///} CUarray_format;
    ///  \endcode
    ///
    /// - \p NumChannels specifies the number of packed components per CUDA array
    /// element; it may be 1, 2, or 4;
    ///
    /// - ::Flags may be set to
    ///   - ::CUDA_ARRAY3D_LAYERED to enable creation of layered CUDA mipmapped arrays. If this flag is set,
    ///     \p Depth specifies the number of layers, not the depth of a 3D array.
    ///   - ::CUDA_ARRAY3D_SURFACE_LDST to enable surface references to be bound to individual mipmap levels of
    ///     the CUDA mipmapped array. If this flag is not set, ::cuSurfRefSetArray will fail when attempting to
    ///     bind a mipmap level of the CUDA mipmapped array to a surface reference.
    ///   - ::CUDA_ARRAY3D_CUBEMAP to enable creation of mipmapped cubemaps. If this flag is set, \p Width must be
    ///     equal to \p Height, and \p Depth must be six. If the ::CUDA_ARRAY3D_LAYERED flag is also set,
    ///     then \p Depth must be a multiple of six.
    ///   - ::CUDA_ARRAY3D_TEXTURE_GATHER to indicate that the CUDA mipmapped array will be used for texture gather.
    ///     Texture gather can only be performed on 2D CUDA mipmapped arrays.
    ///
    /// \p Width, \p Height and \p Depth must meet certain size requirements as listed in the following table.
    /// All values are specified in elements. Note that for brevity's sake, the full name of the device attribute
    /// is not specified. For ex., TEXTURE1D_MIPMAPPED_WIDTH refers to the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH.
    ///
    /// <table>
    /// <tr><td><b>CUDA array type</b></td>
    /// <td><b>Valid extents that must always be met<br>{(width range in elements), (height range),
    /// (depth range)}</b></td>
    /// <td><b>Valid extents with CUDA_ARRAY3D_SURFACE_LDST set<br>
    /// {(width range in elements), (height range), (depth range)}</b></td></tr>
    /// <tr><td>1D</td>
    /// <td><small>{ (1,TEXTURE1D_MIPMAPPED_WIDTH), 0, 0 }</small></td>
    /// <td><small>{ (1,SURFACE1D_WIDTH), 0, 0 }</small></td></tr>
    /// <tr><td>2D</td>
    /// <td><small>{ (1,TEXTURE2D_MIPMAPPED_WIDTH), (1,TEXTURE2D_MIPMAPPED_HEIGHT), 0 }</small></td>
    /// <td><small>{ (1,SURFACE2D_WIDTH), (1,SURFACE2D_HEIGHT), 0 }</small></td></tr>
    /// <tr><td>3D</td>
    /// <td><small>{ (1,TEXTURE3D_WIDTH), (1,TEXTURE3D_HEIGHT), (1,TEXTURE3D_DEPTH) }
    /// <br>OR<br>{ (1,TEXTURE3D_WIDTH_ALTERNATE), (1,TEXTURE3D_HEIGHT_ALTERNATE),
    /// (1,TEXTURE3D_DEPTH_ALTERNATE) }</small></td>
    /// <td><small>{ (1,SURFACE3D_WIDTH), (1,SURFACE3D_HEIGHT),
    /// (1,SURFACE3D_DEPTH) }</small></td></tr>
    /// <tr><td>1D Layered</td>
    /// <td><small>{ (1,TEXTURE1D_LAYERED_WIDTH), 0,
    /// (1,TEXTURE1D_LAYERED_LAYERS) }</small></td>
    /// <td><small>{ (1,SURFACE1D_LAYERED_WIDTH), 0,
    /// (1,SURFACE1D_LAYERED_LAYERS) }</small></td></tr>
    /// <tr><td>2D Layered</td>
    /// <td><small>{ (1,TEXTURE2D_LAYERED_WIDTH), (1,TEXTURE2D_LAYERED_HEIGHT),
    /// (1,TEXTURE2D_LAYERED_LAYERS) }</small></td>
    /// <td><small>{ (1,SURFACE2D_LAYERED_WIDTH), (1,SURFACE2D_LAYERED_HEIGHT),
    /// (1,SURFACE2D_LAYERED_LAYERS) }</small></td></tr>
    /// <tr><td>Cubemap</td>
    /// <td><small>{ (1,TEXTURECUBEMAP_WIDTH), (1,TEXTURECUBEMAP_WIDTH), 6 }</small></td>
    /// <td><small>{ (1,SURFACECUBEMAP_WIDTH),
    /// (1,SURFACECUBEMAP_WIDTH), 6 }</small></td></tr>
    /// <tr><td>Cubemap Layered</td>
    /// <td><small>{ (1,TEXTURECUBEMAP_LAYERED_WIDTH), (1,TEXTURECUBEMAP_LAYERED_WIDTH),
    /// (1,TEXTURECUBEMAP_LAYERED_LAYERS) }</small></td>
    /// <td><small>{ (1,SURFACECUBEMAP_LAYERED_WIDTH), (1,SURFACECUBEMAP_LAYERED_WIDTH),
    /// (1,SURFACECUBEMAP_LAYERED_LAYERS) }</small></td></tr>
    /// </table>
    ///
    ///
    /// \param pHandle             - Returned mipmapped array
    /// \param pMipmappedArrayDesc - mipmapped array descriptor
    /// \param numMipmapLevels     - Number of mipmap levels
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMipmappedArrayDestroy,
    /// ::cuMipmappedArrayGetLevel,
    /// ::cuArrayCreate,
    /// ::cudaMallocMipmappedArray
    pub fn cuMipmappedArrayCreate(
        pHandle: *mut CUmipmappedArray,
        pMipmappedArrayDesc: *const CUDA_ARRAY3D_DESCRIPTOR,
        numMipmapLevels: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets a mipmap level of a CUDA mipmapped array
    ///
    /// Returns in \p *pLevelArray a CUDA array that represents a single mipmap level
    /// of the CUDA mipmapped array \p hMipmappedArray.
    ///
    /// If \p level is greater than the maximum number of levels in this mipmapped array,
    /// ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    /// \param pLevelArray     - Returned mipmap level CUDA array
    /// \param hMipmappedArray - CUDA mipmapped array
    /// \param level           - Mipmap level
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMipmappedArrayCreate,
    /// ::cuMipmappedArrayDestroy,
    /// ::cuArrayCreate,
    /// ::cudaGetMipmappedArrayLevel
    pub fn cuMipmappedArrayGetLevel(
        pLevelArray: *mut CUarray,
        hMipmappedArray: CUmipmappedArray,
        level: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Destroys a CUDA mipmapped array
    ///
    /// Destroys the CUDA mipmapped array \p hMipmappedArray.
    ///
    /// \param hMipmappedArray - Mipmapped array to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_ARRAY_IS_MAPPED,
    /// ::CUDA_ERROR_CONTEXT_IS_DESTROYED
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMipmappedArrayCreate,
    /// ::cuMipmappedArrayGetLevel,
    /// ::cuArrayCreate,
    /// ::cudaFreeMipmappedArray
    pub fn cuMipmappedArrayDestroy(hMipmappedArray: CUmipmappedArray) -> CUresult;
}
extern "C" {
    /// \brief Returns information about a pointer
    ///
    /// The supported attributes are:
    ///
    /// - ::CU_POINTER_ATTRIBUTE_CONTEXT:
    ///
    ///      Returns in \p *data the ::CUcontext in which \p ptr was allocated or
    ///      registered.
    ///      The type of \p data must be ::CUcontext *.
    ///
    ///      If \p ptr was not allocated by, mapped by, or registered with
    ///      a ::CUcontext which uses unified virtual addressing then
    ///      ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_MEMORY_TYPE:
    ///
    ///      Returns in \p *data the physical memory type of the memory that
    ///      \p ptr addresses as a ::CUmemorytype enumerated value.
    ///      The type of \p data must be unsigned int.
    ///
    ///      If \p ptr addresses device memory then \p *data is set to
    ///      ::CU_MEMORYTYPE_DEVICE.  The particular ::CUdevice on which the
    ///      memory resides is the ::CUdevice of the ::CUcontext returned by the
    ///      ::CU_POINTER_ATTRIBUTE_CONTEXT attribute of \p ptr.
    ///
    ///      If \p ptr addresses host memory then \p *data is set to
    ///      ::CU_MEMORYTYPE_HOST.
    ///
    ///      If \p ptr was not allocated by, mapped by, or registered with
    ///      a ::CUcontext which uses unified virtual addressing then
    ///      ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    ///      If the current ::CUcontext does not support unified virtual
    ///      addressing then ::CUDA_ERROR_INVALID_CONTEXT is returned.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_DEVICE_POINTER:
    ///
    ///      Returns in \p *data the device pointer value through which
    ///      \p ptr may be accessed by kernels running in the current
    ///      ::CUcontext.
    ///      The type of \p data must be CUdeviceptr *.
    ///
    ///      If there exists no device pointer value through which
    ///      kernels running in the current ::CUcontext may access
    ///      \p ptr then ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    ///      If there is no current ::CUcontext then
    ///      ::CUDA_ERROR_INVALID_CONTEXT is returned.
    ///
    ///      Except in the exceptional disjoint addressing cases discussed
    ///      below, the value returned in \p *data will equal the input
    ///      value \p ptr.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_HOST_POINTER:
    ///
    ///      Returns in \p *data the host pointer value through which
    ///      \p ptr may be accessed by by the host program.
    ///      The type of \p data must be void **.
    ///      If there exists no host pointer value through which
    ///      the host program may directly access \p ptr then
    ///      ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    ///      Except in the exceptional disjoint addressing cases discussed
    ///      below, the value returned in \p *data will equal the input
    ///      value \p ptr.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_P2P_TOKENS:
    ///
    ///      Returns in \p *data two tokens for use with the nv-p2p.h Linux
    ///      kernel interface. \p data must be a struct of type
    ///      CUDA_POINTER_ATTRIBUTE_P2P_TOKENS.
    ///
    ///      \p ptr must be a pointer to memory obtained from :cuMemAlloc().
    ///      Note that p2pToken and vaSpaceToken are only valid for the
    ///      lifetime of the source allocation. A subsequent allocation at
    ///      the same address may return completely different tokens.
    ///      Querying this attribute has a side effect of setting the attribute
    ///      ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS for the region of memory that
    ///      \p ptr points to.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS:
    ///
    ///      A boolean attribute which when set, ensures that synchronous memory operations
    ///      initiated on the region of memory that \p ptr points to will always synchronize.
    ///      See further documentation in the section titled "API synchronization behavior"
    ///      to learn more about cases when synchronous memory operations can
    ///      exhibit asynchronous behavior.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_BUFFER_ID:
    ///
    ///      Returns in \p *data a buffer ID which is guaranteed to be unique within the process.
    ///      \p data must point to an unsigned long long.
    ///
    ///      \p ptr must be a pointer to memory obtained from a CUDA memory allocation API.
    ///      Every memory allocation from any of the CUDA memory allocation APIs will
    ///      have a unique ID over a process lifetime. Subsequent allocations do not reuse IDs
    ///      from previous freed allocations. IDs are only unique within a single process.
    ///
    ///
    /// - ::CU_POINTER_ATTRIBUTE_IS_MANAGED:
    ///
    ///      Returns in \p *data a boolean that indicates whether the pointer points to
    ///      managed memory or not.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_DEVICE_ORDINAL:
    ///
    ///      Returns in \p *data an integer representing a device ordinal of a device against
    ///      which the memory was allocated or registered.
    ///
    /// \par
    ///
    /// Note that for most allocations in the unified virtual address space
    /// the host and device pointer for accessing the allocation will be the
    /// same.  The exceptions to this are
    ///  - user memory registered using ::cuMemHostRegister
    ///  - host memory allocated using ::cuMemHostAlloc with the
    ///    ::CU_MEMHOSTALLOC_WRITECOMBINED flag
    /// For these types of allocation there will exist separate, disjoint host
    /// and device addresses for accessing the allocation.  In particular
    ///  - The host address will correspond to an invalid unmapped device address
    ///    (which will result in an exception if accessed from the device)
    ///  - The device address will correspond to an invalid unmapped host address
    ///    (which will result in an exception if accessed from the host).
    /// For these types of allocations, querying ::CU_POINTER_ATTRIBUTE_HOST_POINTER
    /// and ::CU_POINTER_ATTRIBUTE_DEVICE_POINTER may be used to retrieve the host
    /// and device addresses from either address.
    ///
    /// \param data      - Returned pointer attribute value
    /// \param attribute - Pointer attribute to query
    /// \param ptr       - Pointer
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuPointerSetAttribute,
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuMemAllocHost,
    /// ::cuMemFreeHost,
    /// ::cuMemHostAlloc,
    /// ::cuMemHostRegister,
    /// ::cuMemHostUnregister,
    /// ::cudaPointerGetAttributes
    pub fn cuPointerGetAttribute(
        data: *mut ::std::os::raw::c_void,
        attribute: CUpointer_attribute,
        ptr: CUdeviceptr,
    ) -> CUresult;
}
extern "C" {
    /// \brief Prefetches memory to the specified destination device
    ///
    /// Prefetches memory to the specified destination device.  \p devPtr is the
    /// base device pointer of the memory to be prefetched and \p dstDevice is the
    /// destination device. \p count specifies the number of bytes to copy. \p hStream
    /// is the stream in which the operation is enqueued. The memory range must refer
    /// to managed memory allocated via ::cuMemAllocManaged or declared via __managed__ variables.
    ///
    /// Passing in CU_DEVICE_CPU for \p dstDevice will prefetch the data to host memory. If
    /// \p dstDevice is a GPU, then the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS
    /// must be non-zero. Additionally, \p hStream must be associated with a device that has a
    /// non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    ///
    /// The start address and end address of the memory range will be rounded down and rounded up
    /// respectively to be aligned to CPU page size before the prefetch operation is enqueued
    /// in the stream.
    ///
    /// If no physical memory has been allocated for this region, then this memory region
    /// will be populated and mapped on the destination device. If there's insufficient
    /// memory to prefetch the desired region, the Unified Memory driver may evict pages from other
    /// ::cuMemAllocManaged allocations to host memory in order to make room. Device memory
    /// allocated using ::cuMemAlloc or ::cuArrayCreate will not be evicted.
    ///
    /// By default, any mappings to the previous location of the migrated pages are removed and
    /// mappings for the new location are only setup on \p dstDevice. The exact behavior however
    /// also depends on the settings applied to this memory range via ::cuMemAdvise as described
    /// below:
    ///
    /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY was set on any subset of this memory range,
    /// then that subset will create a read-only copy of the pages on \p dstDevice.
    ///
    /// If ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION was called on any subset of this memory
    /// range, then the pages will be migrated to \p dstDevice even if \p dstDevice is not the
    /// preferred location of any pages in the memory range.
    ///
    /// If ::CU_MEM_ADVISE_SET_ACCESSED_BY was called on any subset of this memory range,
    /// then mappings to those pages from all the appropriate processors are updated to
    /// refer to the new location if establishing such a mapping is possible. Otherwise,
    /// those mappings are cleared.
    ///
    /// Note that this API is not required for functionality and only serves to improve performance
    /// by allowing the application to migrate data to a suitable location before it is accessed.
    /// Memory accesses to this range are always coherent and are allowed even when the data is
    /// actively being migrated.
    ///
    /// Note that this function is asynchronous with respect to the host and all work
    /// on other devices.
    ///
    /// \param devPtr    - Pointer to be prefetched
    /// \param count     - Size in bytes
    /// \param dstDevice - Destination device to prefetch to
    /// \param hStream    - Stream to enqueue prefetch operation
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpy, ::cuMemcpyPeer, ::cuMemcpyAsync,
    /// ::cuMemcpy3DPeerAsync, ::cuMemAdvise,
    /// ::cudaMemPrefetchAsync
    pub fn cuMemPrefetchAsync(
        devPtr: CUdeviceptr,
        count: usize,
        dstDevice: CUdevice,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Advise about the usage of a given memory range
    ///
    /// Advise the Unified Memory subsystem about the usage pattern for the memory range
    /// starting at \p devPtr with a size of \p count bytes. The start address and end address of the memory
    /// range will be rounded down and rounded up respectively to be aligned to CPU page size before the
    /// advice is applied. The memory range must refer to managed memory allocated via ::cuMemAllocManaged
    /// or declared via __managed__ variables. The memory range could also refer to system-allocated pageable
    /// memory provided it represents a valid, host-accessible region of memory and all additional constraints
    /// imposed by \p advice as outlined below are also satisfied. Specifying an invalid system-allocated pageable
    /// memory range results in an error being returned.
    ///
    /// The \p advice parameter can take the following values:
    /// - ::CU_MEM_ADVISE_SET_READ_MOSTLY: This implies that the data is mostly going to be read
    /// from and only occasionally written to. Any read accesses from any processor to this region will create a
    /// read-only copy of at least the accessed pages in that processor's memory. Additionally, if ::cuMemPrefetchAsync
    /// is called on this region, it will create a read-only copy of the data on the destination processor.
    /// If any processor writes to this region, all copies of the corresponding page will be invalidated
    /// except for the one where the write occurred. The \p device argument is ignored for this advice.
    /// Note that for a page to be read-duplicated, the accessing processor must either be the CPU or a GPU
    /// that has a non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    /// Also, if a context is created on a device that does not have the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS set, then read-duplication will not occur until
    /// all such contexts are destroyed.
    /// If the memory region refers to valid system-allocated pageable memory, then the accessing device must
    /// have a non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS for a read-only
    /// copy to be created on that device. Note however that if the accessing device also has a non-zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES, then setting this advice
    /// will not create a read-only copy when that device accesses this memory region.
    ///
    /// - ::CU_MEM_ADVISE_UNSET_READ_MOSTLY:  Undoes the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY and also prevents the
    /// Unified Memory driver from attempting heuristic read-duplication on the memory range. Any read-duplicated
    /// copies of the data will be collapsed into a single copy. The location for the collapsed
    /// copy will be the preferred location if the page has a preferred location and one of the read-duplicated
    /// copies was resident at that location. Otherwise, the location chosen is arbitrary.
    ///
    /// - ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION: This advice sets the preferred location for the
    /// data to be the memory belonging to \p device. Passing in CU_DEVICE_CPU for \p device sets the
    /// preferred location as host memory. If \p device is a GPU, then it must have a non-zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS. Setting the preferred location
    /// does not cause data to migrate to that location immediately. Instead, it guides the migration policy
    /// when a fault occurs on that memory region. If the data is already in its preferred location and the
    /// faulting processor can establish a mapping without requiring the data to be migrated, then
    /// data migration will be avoided. On the other hand, if the data is not in its preferred location
    /// or if a direct mapping cannot be established, then it will be migrated to the processor accessing
    /// it. It is important to note that setting the preferred location does not prevent data prefetching
    /// done using ::cuMemPrefetchAsync.
    /// Having a preferred location can override the page thrash detection and resolution logic in the Unified
    /// Memory driver. Normally, if a page is detected to be constantly thrashing between for example host and device
    /// memory, the page may eventually be pinned to host memory by the Unified Memory driver. But
    /// if the preferred location is set as device memory, then the page will continue to thrash indefinitely.
    /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
    /// policies associated with that advice will override the policies of this advice, unless read accesses from
    /// \p device will not result in a read-only copy being created on that device as outlined in description for
    /// the advice ::CU_MEM_ADVISE_SET_READ_MOSTLY.
    /// If the memory region refers to valid system-allocated pageable memory, then \p device must have a non-zero
    /// value for the device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS. Additionally, if \p device has
    /// a non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,
    /// then this call has no effect. Note however that this behavior may change in the future.
    ///
    /// - ::CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION: Undoes the effect of ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION
    /// and changes the preferred location to none.
    ///
    /// - ::CU_MEM_ADVISE_SET_ACCESSED_BY: This advice implies that the data will be accessed by \p device.
    /// Passing in ::CU_DEVICE_CPU for \p device will set the advice for the CPU. If \p device is a GPU, then
    /// the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS must be non-zero.
    /// This advice does not cause data migration and has no impact on the location of the data per se. Instead,
    /// it causes the data to always be mapped in the specified processor's page tables, as long as the
    /// location of the data permits a mapping to be established. If the data gets migrated for any reason,
    /// the mappings are updated accordingly.
    /// This advice is recommended in scenarios where data locality is not important, but avoiding faults is.
    /// Consider for example a system containing multiple GPUs with peer-to-peer access enabled, where the
    /// data located on one GPU is occasionally accessed by peer GPUs. In such scenarios, migrating data
    /// over to the other GPUs is not as important because the accesses are infrequent and the overhead of
    /// migration may be too high. But preventing faults can still help improve performance, and so having
    /// a mapping set up in advance is useful. Note that on CPU access of this data, the data may be migrated
    /// to host memory because the CPU typically cannot access device memory directly. Any GPU that had the
    /// ::CU_MEM_ADVISE_SET_ACCESSED_BY flag set for this data will now have its mapping updated to point to the
    /// page in host memory.
    /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
    /// policies associated with that advice will override the policies of this advice. Additionally, if the
    /// preferred location of this memory region or any subset of it is also \p device, then the policies
    /// associated with ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION will override the policies of this advice.
    /// If the memory region refers to valid system-allocated pageable memory, then \p device must have a non-zero
    /// value for the device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS. Additionally, if \p device has
    /// a non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,
    /// then this call has no effect.
    ///
    /// - ::CU_MEM_ADVISE_UNSET_ACCESSED_BY: Undoes the effect of ::CU_MEM_ADVISE_SET_ACCESSED_BY. Any mappings to
    /// the data from \p device may be removed at any time causing accesses to result in non-fatal page faults.
    /// If the memory region refers to valid system-allocated pageable memory, then \p device must have a non-zero
    /// value for the device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS. Additionally, if \p device has
    /// a non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES,
    /// then this call has no effect.
    ///
    /// \param devPtr - Pointer to memory to set the advice for
    /// \param count  - Size in bytes of the memory range
    /// \param advice - Advice to be applied for the specified memory range
    /// \param device - Device to apply the advice for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpy, ::cuMemcpyPeer, ::cuMemcpyAsync,
    /// ::cuMemcpy3DPeerAsync, ::cuMemPrefetchAsync,
    /// ::cudaMemAdvise
    pub fn cuMemAdvise(
        devPtr: CUdeviceptr,
        count: usize,
        advice: CUmem_advise,
        device: CUdevice,
    ) -> CUresult;
}
extern "C" {
    /// \brief Query an attribute of a given memory range
    ///
    /// Query an attribute about the memory range starting at \p devPtr with a size of \p count bytes. The
    /// memory range must refer to managed memory allocated via ::cuMemAllocManaged or declared via
    /// __managed__ variables.
    ///
    /// The \p attribute parameter can take the following values:
    /// - ::CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY: If this attribute is specified, \p data will be interpreted
    /// as a 32-bit integer, and \p dataSize must be 4. The result returned will be 1 if all pages in the given
    /// memory range have read-duplication enabled, or 0 otherwise.
    /// - ::CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION: If this attribute is specified, \p data will be
    /// interpreted as a 32-bit integer, and \p dataSize must be 4. The result returned will be a GPU device
    /// id if all pages in the memory range have that GPU as their preferred location, or it will be CU_DEVICE_CPU
    /// if all pages in the memory range have the CPU as their preferred location, or it will be CU_DEVICE_INVALID
    /// if either all the pages don't have the same preferred location or some of the pages don't have a
    /// preferred location at all. Note that the actual location of the pages in the memory range at the time of
    /// the query may be different from the preferred location.
    /// - ::CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY: If this attribute is specified, \p data will be interpreted
    /// as an array of 32-bit integers, and \p dataSize must be a non-zero multiple of 4. The result returned
    /// will be a list of device ids that had ::CU_MEM_ADVISE_SET_ACCESSED_BY set for that entire memory range.
    /// If any device does not have that advice set for the entire memory range, that device will not be included.
    /// If \p data is larger than the number of devices that have that advice set for that memory range,
    /// CU_DEVICE_INVALID will be returned in all the extra space provided. For ex., if \p dataSize is 12
    /// (i.e. \p data has 3 elements) and only device 0 has the advice set, then the result returned will be
    /// { 0, CU_DEVICE_INVALID, CU_DEVICE_INVALID }. If \p data is smaller than the number of devices that have
    /// that advice set, then only as many devices will be returned as can fit in the array. There is no
    /// guarantee on which specific devices will be returned, however.
    /// - ::CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION: If this attribute is specified, \p data will be
    /// interpreted as a 32-bit integer, and \p dataSize must be 4. The result returned will be the last location
    /// to which all pages in the memory range were prefetched explicitly via ::cuMemPrefetchAsync. This will either be
    /// a GPU id or CU_DEVICE_CPU depending on whether the last location for prefetch was a GPU or the CPU
    /// respectively. If any page in the memory range was never explicitly prefetched or if all pages were not
    /// prefetched to the same location, CU_DEVICE_INVALID will be returned. Note that this simply returns the
    /// last location that the applicaton requested to prefetch the memory range to. It gives no indication as to
    /// whether the prefetch operation to that location has completed or even begun.
    ///
    /// \param data      - A pointers to a memory location where the result
    ///                    of each attribute query will be written to.
    /// \param dataSize  - Array containing the size of data
    /// \param attribute - The attribute to query
    /// \param devPtr    - Start of the range to query
    /// \param count     - Size of the range to query
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemRangeGetAttributes, ::cuMemPrefetchAsync,
    /// ::cuMemAdvise,
    /// ::cudaMemRangeGetAttribute
    pub fn cuMemRangeGetAttribute(
        data: *mut ::std::os::raw::c_void,
        dataSize: usize,
        attribute: CUmem_range_attribute,
        devPtr: CUdeviceptr,
        count: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Query attributes of a given memory range.
    ///
    /// Query attributes of the memory range starting at \p devPtr with a size of \p count bytes. The
    /// memory range must refer to managed memory allocated via ::cuMemAllocManaged or declared via
    /// __managed__ variables. The \p attributes array will be interpreted to have \p numAttributes
    /// entries. The \p dataSizes array will also be interpreted to have \p numAttributes entries.
    /// The results of the query will be stored in \p data.
    ///
    /// The list of supported attributes are given below. Please refer to ::cuMemRangeGetAttribute for
    /// attribute descriptions and restrictions.
    ///
    /// - ::CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY
    /// - ::CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION
    /// - ::CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY
    /// - ::CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION
    ///
    /// \param data          - A two-dimensional array containing pointers to memory
    ///                        locations where the result of each attribute query will be written to.
    /// \param dataSizes     - Array containing the sizes of each result
    /// \param attributes    - An array of attributes to query
    ///                        (numAttributes and the number of attributes in this array should match)
    /// \param numAttributes - Number of attributes to query
    /// \param devPtr        - Start of the range to query
    /// \param count         - Size of the range to query
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuMemRangeGetAttribute, ::cuMemAdvise
    /// ::cuMemPrefetchAsync,
    /// ::cudaMemRangeGetAttributes
    pub fn cuMemRangeGetAttributes(
        data: *mut *mut ::std::os::raw::c_void,
        dataSizes: *mut usize,
        attributes: *mut CUmem_range_attribute,
        numAttributes: usize,
        devPtr: CUdeviceptr,
        count: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Set attributes on a previously allocated memory region
    ///
    /// The supported attributes are:
    ///
    /// - ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS:
    ///
    ///      A boolean attribute that can either be set (1) or unset (0). When set,
    ///      the region of memory that \p ptr points to is guaranteed to always synchronize
    ///      memory operations that are synchronous. If there are some previously initiated
    ///      synchronous memory operations that are pending when this attribute is set, the
    ///      function does not return until those memory operations are complete.
    ///      See further documentation in the section titled "API synchronization behavior"
    ///      to learn more about cases when synchronous memory operations can
    ///      exhibit asynchronous behavior.
    ///      \p value will be considered as a pointer to an unsigned integer to which this attribute is to be set.
    ///
    /// \param value     - Pointer to memory containing the value to be set
    /// \param attribute - Pointer attribute to set
    /// \param ptr       - Pointer to a memory region allocated using CUDA memory allocation APIs
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuPointerGetAttribute,
    /// ::cuPointerGetAttributes,
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuMemAllocHost,
    /// ::cuMemFreeHost,
    /// ::cuMemHostAlloc,
    /// ::cuMemHostRegister,
    /// ::cuMemHostUnregister
    pub fn cuPointerSetAttribute(
        value: *const ::std::os::raw::c_void,
        attribute: CUpointer_attribute,
        ptr: CUdeviceptr,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns information about a pointer.
    ///
    /// The supported attributes are (refer to ::cuPointerGetAttribute for attribute descriptions and restrictions):
    ///
    /// - ::CU_POINTER_ATTRIBUTE_CONTEXT
    /// - ::CU_POINTER_ATTRIBUTE_MEMORY_TYPE
    /// - ::CU_POINTER_ATTRIBUTE_DEVICE_POINTER
    /// - ::CU_POINTER_ATTRIBUTE_HOST_POINTER
    /// - ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS
    /// - ::CU_POINTER_ATTRIBUTE_BUFFER_ID
    /// - ::CU_POINTER_ATTRIBUTE_IS_MANAGED
    /// - ::CU_POINTER_ATTRIBUTE_DEVICE_ORDINAL
    ///
    /// \param numAttributes - Number of attributes to query
    /// \param attributes    - An array of attributes to query
    ///                      (numAttributes and the number of attributes in this array should match)
    /// \param data          - A two-dimensional array containing pointers to memory
    ///                      locations where the result of each attribute query will be written to.
    /// \param ptr           - Pointer to query
    ///
    /// Unlike ::cuPointerGetAttribute, this function will not return an error when the \p ptr
    /// encountered is not a valid CUDA pointer. Instead, the attributes are assigned default NULL values
    /// and CUDA_SUCCESS is returned.
    ///
    /// If \p ptr was not allocated by, mapped by, or registered with a ::CUcontext which uses UVA
    /// (Unified Virtual Addressing), ::CUDA_ERROR_INVALID_CONTEXT is returned.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuPointerGetAttribute,
    /// ::cuPointerSetAttribute,
    /// ::cudaPointerGetAttributes
    pub fn cuPointerGetAttributes(
        numAttributes: ::std::os::raw::c_uint,
        attributes: *mut CUpointer_attribute,
        data: *mut *mut ::std::os::raw::c_void,
        ptr: CUdeviceptr,
    ) -> CUresult;
}
extern "C" {
    /// \brief Create a stream
    ///
    /// Creates a stream and returns a handle in \p phStream.  The \p Flags argument
    /// determines behaviors of the stream.  Valid values for \p Flags are:
    /// - ::CU_STREAM_DEFAULT: Default stream creation flag.
    /// - ::CU_STREAM_NON_BLOCKING: Specifies that work running in the created
    ///   stream may run concurrently with work in stream 0 (the NULL stream), and that
    ///   the created stream should perform no implicit synchronization with stream 0.
    ///
    /// \param phStream - Returned newly created stream
    /// \param Flags    - Parameters for stream creation
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreateWithPriority,
    /// ::cuStreamGetPriority,
    /// ::cuStreamGetFlags,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback,
    /// ::cudaStreamCreate,
    /// ::cudaStreamCreateWithFlags
    pub fn cuStreamCreate(phStream: *mut CUstream, Flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Create a stream with the given priority
    ///
    /// Creates a stream with the specified priority and returns a handle in \p phStream.
    /// This API alters the scheduler priority of work in the stream. Work in a higher
    /// priority stream may preempt work already executing in a low priority stream.
    ///
    /// \p priority follows a convention where lower numbers represent higher priorities.
    /// '0' represents default priority. The range of meaningful numerical priorities can
    /// be queried using ::cuCtxGetStreamPriorityRange. If the specified priority is
    /// outside the numerical range returned by ::cuCtxGetStreamPriorityRange,
    /// it will automatically be clamped to the lowest or the highest number in the range.
    ///
    /// \param phStream    - Returned newly created stream
    /// \param flags       - Flags for stream creation. See ::cuStreamCreate for a list of
    ///                      valid flags
    /// \param priority    - Stream priority. Lower numbers represent higher priorities.
    ///                      See ::cuCtxGetStreamPriorityRange for more information about
    ///                      meaningful stream priorities that can be passed.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \note Stream priorities are supported only on GPUs
    /// with compute capability 3.5 or higher.
    ///
    /// \note In the current implementation, only compute kernels launched in
    /// priority streams are affected by the stream's priority. Stream priorities have
    /// no effect on host-to-device and device-to-host memory operations.
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreate,
    /// ::cuStreamGetPriority,
    /// ::cuCtxGetStreamPriorityRange,
    /// ::cuStreamGetFlags,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback,
    /// ::cudaStreamCreateWithPriority
    pub fn cuStreamCreateWithPriority(
        phStream: *mut CUstream,
        flags: ::std::os::raw::c_uint,
        priority: ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Query the priority of a given stream
    ///
    /// Query the priority of a stream created using ::cuStreamCreate or ::cuStreamCreateWithPriority
    /// and return the priority in \p priority. Note that if the stream was created with a
    /// priority outside the numerical range returned by ::cuCtxGetStreamPriorityRange,
    /// this function returns the clamped priority.
    /// See ::cuStreamCreateWithPriority for details about priority clamping.
    ///
    /// \param hStream    - Handle to the stream to be queried
    /// \param priority   - Pointer to a signed integer in which the stream's priority is returned
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreate,
    /// ::cuStreamCreateWithPriority,
    /// ::cuCtxGetStreamPriorityRange,
    /// ::cuStreamGetFlags,
    /// ::cudaStreamGetPriority
    pub fn cuStreamGetPriority(hStream: CUstream, priority: *mut ::std::os::raw::c_int)
        -> CUresult;
}
extern "C" {
    /// \brief Query the flags of a given stream
    ///
    /// Query the flags of a stream created using ::cuStreamCreate or ::cuStreamCreateWithPriority
    /// and return the flags in \p flags.
    ///
    /// \param hStream    - Handle to the stream to be queried
    /// \param flags      - Pointer to an unsigned integer in which the stream's flags are returned
    ///                     The value returned in \p flags is a logical 'OR' of all flags that
    ///                     were used while creating this stream. See ::cuStreamCreate for the list
    ///                     of valid flags
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreate,
    /// ::cuStreamGetPriority,
    /// ::cudaStreamGetFlags
    pub fn cuStreamGetFlags(hStream: CUstream, flags: *mut ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Query the context associated with a stream
    ///
    /// Returns the CUDA context that the stream is associated with.
    ///
    /// The stream handle \p hStream can refer to any of the following:
    /// <ul>
    ///   <li>a stream created via any of the CUDA driver APIs such as ::cuStreamCreate
    ///   and ::cuStreamCreateWithPriority, or their runtime API equivalents such as
    ///   ::cudaStreamCreate, ::cudaStreamCreateWithFlags and ::cudaStreamCreateWithPriority.
    ///   The returned context is the context that was active in the calling thread when the
    ///   stream was created. Passing an invalid handle will result in undefined behavior.</li>
    ///   <li>any of the special streams such as the NULL stream, ::CU_STREAM_LEGACY and
    ///   ::CU_STREAM_PER_THREAD. The runtime API equivalents of these are also accepted,
    ///   which are NULL, ::cudaStreamLegacy and ::cudaStreamPerThread respectively.
    ///   Specifying any of the special handles will return the context current to the
    ///   calling thread. If no context is current to the calling thread,
    ///   ::CUDA_ERROR_INVALID_CONTEXT is returned.</li>
    /// </ul>
    ///
    /// \param hStream - Handle to the stream to be queried
    /// \param pctx    - Returned context associated with the stream
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// \notefnerr
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreateWithPriority,
    /// ::cuStreamGetPriority,
    /// ::cuStreamGetFlags,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback,
    /// ::cudaStreamCreate,
    /// ::cudaStreamCreateWithFlags
    pub fn cuStreamGetCtx(hStream: CUstream, pctx: *mut CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Make a compute stream wait on an event
    ///
    /// Makes all future work submitted to \p hStream wait for all work captured in
    /// \p hEvent.  See ::cuEventRecord() for details on what is captured by an event.
    /// The synchronization will be performed efficiently on the device when applicable.
    /// \p hEvent may be from a different context or device than \p hStream.
    ///
    /// \param hStream - Stream to wait
    /// \param hEvent  - Event to wait on (may not be NULL)
    /// \param Flags   - Parameters for the operation (must be 0)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuEventRecord,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback,
    /// ::cuStreamDestroy,
    /// ::cudaStreamWaitEvent
    pub fn cuStreamWaitEvent(
        hStream: CUstream,
        hEvent: CUevent,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Add a callback to a compute stream
    ///
    /// \note This function is slated for eventual deprecation and removal. If
    /// you do not require the callback to execute in case of a device error,
    /// consider using ::cuLaunchHostFunc. Additionally, this function is not
    /// supported with ::cuStreamBeginCapture and ::cuStreamEndCapture, unlike
    /// ::cuLaunchHostFunc.
    ///
    /// Adds a callback to be called on the host after all currently enqueued
    /// items in the stream have completed.  For each
    /// cuStreamAddCallback call, the callback will be executed exactly once.
    /// The callback will block later work in the stream until it is finished.
    ///
    /// The callback may be passed ::CUDA_SUCCESS or an error code.  In the event
    /// of a device error, all subsequently executed callbacks will receive an
    /// appropriate ::CUresult.
    ///
    /// Callbacks must not make any CUDA API calls.  Attempting to use a CUDA API
    /// will result in ::CUDA_ERROR_NOT_PERMITTED.  Callbacks must not perform any
    /// synchronization that may depend on outstanding device work or other callbacks
    /// that are not mandated to run earlier.  Callbacks without a mandated order
    /// (in independent streams) execute in undefined order and may be serialized.
    ///
    /// For the purposes of Unified Memory, callback execution makes a number of
    /// guarantees:
    /// <ul>
    ///   <li>The callback stream is considered idle for the duration of the
    ///   callback.  Thus, for example, a callback may always use memory attached
    ///   to the callback stream.</li>
    ///   <li>The start of execution of a callback has the same effect as
    ///   synchronizing an event recorded in the same stream immediately prior to
    ///   the callback.  It thus synchronizes streams which have been "joined"
    ///   prior to the callback.</li>
    ///   <li>Adding device work to any stream does not have the effect of making
    ///   the stream active until all preceding host functions and stream callbacks
    ///   have executed.  Thus, for
    ///   example, a callback might use global attached memory even if work has
    ///   been added to another stream, if the work has been ordered behind the
    ///   callback with an event.</li>
    ///   <li>Completion of a callback does not cause a stream to become
    ///   active except as described above.  The callback stream will remain idle
    ///   if no device work follows the callback, and will remain idle across
    ///   consecutive callbacks without device work in between.  Thus, for example,
    ///   stream synchronization can be done by signaling from a callback at the
    ///   end of the stream.</li>
    /// </ul>
    ///
    /// \param hStream  - Stream to add callback to
    /// \param callback - The function to call once preceding stream operations are complete
    /// \param userData - User specified data to be passed to the callback function
    /// \param flags    - Reserved for future use, must be 0
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamDestroy,
    /// ::cuMemAllocManaged,
    /// ::cuStreamAttachMemAsync,
    /// ::cuStreamLaunchHostFunc,
    /// ::cudaStreamAddCallback
    pub fn cuStreamAddCallback(
        hStream: CUstream,
        callback: CUstreamCallback,
        userData: *mut ::std::os::raw::c_void,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Begins graph capture on a stream
    ///
    /// Begin graph capture on \p hStream. When a stream is in capture mode, all operations
    /// pushed into the stream will not be executed, but will instead be captured into
    /// a graph, which will be returned via ::cuStreamEndCapture. Capture may not be initiated
    /// if \p stream is CU_STREAM_LEGACY. Capture must be ended on the same stream in which
    /// it was initiated, and it may only be initiated if the stream is not already in capture
    /// mode. The capture mode may be queried via ::cuStreamIsCapturing.
    ///
    /// \param hStream - Stream in which to initiate capture
    ///
    /// \note Kernels captured using this API must not use texture and surface references.
    ///       Reading or writing through any texture or surface reference is undefined
    ///       behavior. This restriction does not apply to texture and surface objects.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuStreamCreate,
    /// ::cuStreamIsCapturing,
    /// ::cuStreamEndCapture
    pub fn cuStreamBeginCapture(hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Ends capture on a stream, returning the captured graph
    ///
    /// End capture on \p hStream, returning the captured graph via \p phGraph.
    /// Capture must have been initiated on \p hStream via a call to ::cuStreamBeginCapture.
    /// If capture was invalidated, due to a violation of the rules of stream capture, then
    /// a NULL graph will be returned.
    ///
    /// \param hStream - Stream to query
    /// \param phGraph - The captured graph
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuStreamCreate,
    /// ::cuStreamBeginCapture,
    /// ::cuStreamIsCapturing
    pub fn cuStreamEndCapture(hStream: CUstream, phGraph: *mut CUgraph) -> CUresult;
}
extern "C" {
    /// \brief Returns a stream's capture status
    ///
    /// Return the capture status of \p hStream via \p captureStatus. After a successful
    /// call, \p *captureStatus will contain one of the following:
    /// - ::CU_STREAM_CAPTURE_STATUS_NONE: The stream is not capturing.
    /// - ::CU_STREAM_CAPTURE_STATUS_ACTIVE: The stream is capturing.
    /// - ::CU_STREAM_CAPTURE_STATUS_INVALIDATED: The stream was capturing but an error
    ///   has invalidated the capture sequence. The capture sequence must be terminated
    ///   with ::cuStreamEndCapture on the stream where it was initiated in order to
    ///   continue using \p hStream.
    ///
    /// Note that, if this is called on ::CU_STREAM_LEGACY (the "null stream") while
    /// a blocking stream in the same context is capturing, it will return
    /// ::CUDA_ERROR_STREAM_CAPTURE_IMPLICIT and \p *captureStatus is unspecified
    /// after the call. The blocking stream capture is not invalidated.
    ///
    /// When a blocking stream is capturing, the legacy stream is in an
    /// unusable state until the blocking stream capture is terminated. The legacy
    /// stream is not supported for stream capture, but attempted use would have an
    /// implicit dependency on the capturing stream(s).
    ///
    /// \param hStream       - Stream to query
    /// \param captureStatus - Returns the stream's capture status
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_STREAM_CAPTURE_IMPLICIT
    /// \notefnerr
    ///
    /// \sa
    /// ::cuStreamCreate,
    /// ::cuStreamBeginCapture,
    /// ::cuStreamEndCapture
    pub fn cuStreamIsCapturing(
        hStream: CUstream,
        captureStatus: *mut CUstreamCaptureStatus,
    ) -> CUresult;
}
extern "C" {
    /// \brief Attach memory to a stream asynchronously
    ///
    /// Enqueues an operation in \p hStream to specify stream association of
    /// \p length bytes of memory starting from \p dptr. This function is a
    /// stream-ordered operation, meaning that it is dependent on, and will
    /// only take effect when, previous work in stream has completed. Any
    /// previous association is automatically replaced.
    ///
    /// \p dptr must point to one of the following types of memories:
    /// - managed memory declared using the __managed__ keyword or allocated with
    ///   ::cuMemAllocManaged.
    /// - a valid host-accessible region of system-allocated pageable memory. This
    ///   type of memory may only be specified if the device associated with the
    ///   stream reports a non-zero value for the device attribute
    ///   ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS.
    ///
    /// For managed allocations, \p length must be either zero or the entire
    /// allocation's size. Both indicate that the entire allocation's stream
    /// association is being changed. Currently, it is not possible to change stream
    /// association for a portion of a managed allocation.
    ///
    /// For pageable host allocations, \p length must be non-zero.
    ///
    /// The stream association is specified using \p flags which must be
    /// one of ::CUmemAttach_flags.
    /// If the ::CU_MEM_ATTACH_GLOBAL flag is specified, the memory can be accessed
    /// by any stream on any device.
    /// If the ::CU_MEM_ATTACH_HOST flag is specified, the program makes a guarantee
    /// that it won't access the memory on the device from any stream on a device that
    /// has a zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    /// If the ::CU_MEM_ATTACH_SINGLE flag is specified and \p hStream is associated with
    /// a device that has a zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS,
    /// the program makes a guarantee that it will only access the memory on the device
    /// from \p hStream. It is illegal to attach singly to the NULL stream, because the
    /// NULL stream is a virtual global stream and not a specific stream. An error will
    /// be returned in this case.
    ///
    /// When memory is associated with a single stream, the Unified Memory system will
    /// allow CPU access to this memory region so long as all operations in \p hStream
    /// have completed, regardless of whether other streams are active. In effect,
    /// this constrains exclusive ownership of the managed memory region by
    /// an active GPU to per-stream activity instead of whole-GPU activity.
    ///
    /// Accessing memory on the device from streams that are not associated with
    /// it will produce undefined results. No error checking is performed by the
    /// Unified Memory system to ensure that kernels launched into other streams
    /// do not access this region.
    ///
    /// It is a program's responsibility to order calls to ::cuStreamAttachMemAsync
    /// via events, synchronization or other means to ensure legal access to memory
    /// at all times. Data visibility and coherency will be changed appropriately
    /// for all kernels which follow a stream-association change.
    ///
    /// If \p hStream is destroyed while data is associated with it, the association is
    /// removed and the association reverts to the default visibility of the allocation
    /// as specified at ::cuMemAllocManaged. For __managed__ variables, the default
    /// association is always ::CU_MEM_ATTACH_GLOBAL. Note that destroying a stream is an
    /// asynchronous operation, and as a result, the change to default association won't
    /// happen until all work in the stream has completed.
    ///
    /// \param hStream - Stream in which to enqueue the attach operation
    /// \param dptr    - Pointer to memory (must be a pointer to managed memory or
    ///                  to a valid host-accessible region of system-allocated
    ///                  pageable memory)
    /// \param length  - Length of memory
    /// \param flags   - Must be one of ::CUmemAttach_flags
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamDestroy,
    /// ::cuMemAllocManaged,
    /// ::cudaStreamAttachMemAsync
    pub fn cuStreamAttachMemAsync(
        hStream: CUstream,
        dptr: CUdeviceptr,
        length: usize,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Determine status of a compute stream
    ///
    /// Returns ::CUDA_SUCCESS if all operations in the stream specified by
    /// \p hStream have completed, or ::CUDA_ERROR_NOT_READY if not.
    ///
    /// For the purposes of Unified Memory, a return value of ::CUDA_SUCCESS
    /// is equivalent to having called ::cuStreamSynchronize().
    ///
    /// \param hStream - Stream to query status of
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_READY
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamDestroy,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback,
    /// ::cudaStreamQuery
    pub fn cuStreamQuery(hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Wait until a stream's tasks are completed
    ///
    /// Waits until the device has completed all operations in the stream specified
    /// by \p hStream. If the context was created with the
    /// ::CU_CTX_SCHED_BLOCKING_SYNC flag, the CPU thread will block until the
    /// stream is finished with all of its tasks.
    ///
    /// \param hStream - Stream to wait for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE
    ///
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamDestroy,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamQuery,
    /// ::cuStreamAddCallback,
    /// ::cudaStreamSynchronize
    pub fn cuStreamSynchronize(hStream: CUstream) -> CUresult;
}
extern "C" {
    pub fn cuStreamDestroy_v2(hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Creates an event
    ///
    /// Creates an event *phEvent for the current context with the flags specified via
    /// \p Flags. Valid flags include:
    /// - ::CU_EVENT_DEFAULT: Default event creation flag.
    /// - ::CU_EVENT_BLOCKING_SYNC: Specifies that the created event should use blocking
    ///   synchronization.  A CPU thread that uses ::cuEventSynchronize() to wait on
    ///   an event created with this flag will block until the event has actually
    ///   been recorded.
    /// - ::CU_EVENT_DISABLE_TIMING: Specifies that the created event does not need
    ///   to record timing data.  Events created with this flag specified and
    ///   the ::CU_EVENT_BLOCKING_SYNC flag not specified will provide the best
    ///   performance when used with ::cuStreamWaitEvent() and ::cuEventQuery().
    /// - ::CU_EVENT_INTERPROCESS: Specifies that the created event may be used as an
    ///   interprocess event by ::cuIpcGetEventHandle(). ::CU_EVENT_INTERPROCESS must
    ///   be specified along with ::CU_EVENT_DISABLE_TIMING.
    ///
    /// \param phEvent - Returns newly created event
    /// \param Flags   - Event creation flags
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa
    /// ::cuEventRecord,
    /// ::cuEventQuery,
    /// ::cuEventSynchronize,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime,
    /// ::cudaEventCreate,
    /// ::cudaEventCreateWithFlags
    pub fn cuEventCreate(phEvent: *mut CUevent, Flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Records an event
    ///
    /// Captures in \p hEvent the contents of \p hStream at the time of this call.
    /// \p hEvent and \p hStream must be from the same context.
    /// Calls such as ::cuEventQuery() or ::cuStreamWaitEvent() will then
    /// examine or wait for completion of the work that was captured. Uses of
    /// \p hStream after this call do not modify \p hEvent. See note on default
    /// stream behavior for what is captured in the default case.
    ///
    /// ::cuEventRecord() can be called multiple times on the same event and
    /// will overwrite the previously captured state. Other APIs such as
    /// ::cuStreamWaitEvent() use the most recently captured state at the time
    /// of the API call, and are not affected by later calls to
    /// ::cuEventRecord(). Before the first call to ::cuEventRecord(), an
    /// event represents an empty set of work, so for example ::cuEventQuery()
    /// would return ::CUDA_SUCCESS.
    ///
    /// \param hEvent  - Event to record
    /// \param hStream - Stream to record event for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventQuery,
    /// ::cuEventSynchronize,
    /// ::cuStreamWaitEvent,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime,
    /// ::cudaEventRecord
    pub fn cuEventRecord(hEvent: CUevent, hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Queries an event's status
    ///
    /// Queries the status of all work currently captured by \p hEvent. See
    /// ::cuEventRecord() for details on what is captured by an event.
    ///
    /// Returns ::CUDA_SUCCESS if all captured work has been completed, or
    /// ::CUDA_ERROR_NOT_READY if any captured work is incomplete.
    ///
    /// For the purposes of Unified Memory, a return value of ::CUDA_SUCCESS
    /// is equivalent to having called ::cuEventSynchronize().
    ///
    /// \param hEvent - Event to query
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_READY
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventRecord,
    /// ::cuEventSynchronize,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime,
    /// ::cudaEventQuery
    pub fn cuEventQuery(hEvent: CUevent) -> CUresult;
}
extern "C" {
    /// \brief Waits for an event to complete
    ///
    /// Waits until the completion of all work currently captured in \p hEvent.
    /// See ::cuEventRecord() for details on what is captured by an event.
    ///
    /// Waiting for an event that was created with the ::CU_EVENT_BLOCKING_SYNC
    /// flag will cause the calling CPU thread to block until the event has
    /// been completed by the device.  If the ::CU_EVENT_BLOCKING_SYNC flag has
    /// not been set, then the CPU thread will busy-wait until the event has
    /// been completed by the device.
    ///
    /// \param hEvent - Event to wait for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventRecord,
    /// ::cuEventQuery,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime,
    /// ::cudaEventSynchronize
    pub fn cuEventSynchronize(hEvent: CUevent) -> CUresult;
}
extern "C" {
    pub fn cuEventDestroy_v2(hEvent: CUevent) -> CUresult;
}
extern "C" {
    /// \brief Computes the elapsed time between two events
    ///
    /// Computes the elapsed time between two events (in milliseconds with a
    /// resolution of around 0.5 microseconds).
    ///
    /// If either event was last recorded in a non-NULL stream, the resulting time
    /// may be greater than expected (even if both used the same stream handle). This
    /// happens because the ::cuEventRecord() operation takes place asynchronously
    /// and there is no guarantee that the measured latency is actually just between
    /// the two events. Any number of other different stream operations could execute
    /// in between the two measured events, thus altering the timing in a significant
    /// way.
    ///
    /// If ::cuEventRecord() has not been called on either event then
    /// ::CUDA_ERROR_INVALID_HANDLE is returned. If ::cuEventRecord() has been called
    /// on both events but one or both of them has not yet been completed (that is,
    /// ::cuEventQuery() would return ::CUDA_ERROR_NOT_READY on at least one of the
    /// events), ::CUDA_ERROR_NOT_READY is returned. If either event was created with
    /// the ::CU_EVENT_DISABLE_TIMING flag, then this function will return
    /// ::CUDA_ERROR_INVALID_HANDLE.
    ///
    /// \param pMilliseconds - Time between \p hStart and \p hEnd in ms
    /// \param hStart        - Starting event
    /// \param hEnd          - Ending event
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_READY
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventRecord,
    /// ::cuEventQuery,
    /// ::cuEventSynchronize,
    /// ::cuEventDestroy,
    /// ::cudaEventElapsedTime
    pub fn cuEventElapsedTime(pMilliseconds: *mut f32, hStart: CUevent, hEnd: CUevent) -> CUresult;
}
extern "C" {
    /// \brief Imports an external memory object
    ///
    /// Imports an externally allocated memory object and returns
    /// a handle to that in \p extMem_out.
    ///
    /// The properties of the handle being imported must be described in
    /// \p memHandleDesc. The ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC structure
    /// is defined as follows:
    ///
    /// \code
    ///typedef struct CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st {
    ///CUexternalMemoryHandleType type;
    ///union {
    ///int fd;
    ///struct {
    ///void *handle;
    ///const void *name;
    ///} win32;
    ///} handle;
    ///unsigned int flags;
    ///} CUDA_EXTERNAL_MEMORY_HANDLE_DESC;
    /// \endcode
    ///
    /// where ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::type specifies the type
    /// of handle being imported. ::CUexternalMemoryHandleType is
    /// defined as:
    ///
    /// \code
    ///typedef enum CUexternalMemoryHandleType_enum {
    ///CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD        = 1,
    ///CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32     = 2,
    ///CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT = 3,
    ///CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP       = 4,
    ///CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE   = 5
    ///} CUexternalMemoryHandleType;
    /// \endcode
    ///
    /// If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD, then
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::fd must be a valid
    /// file descriptor referencing a memory object. Ownership of
    /// the file descriptor is transferred to the CUDA driver when the
    /// handle is imported successfully. Performing any operations on the
    /// file descriptor after it is imported results in undefined behavior.
    ///
    /// If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32, then exactly one
    /// of ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::handle and
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::name must not be
    /// NULL. If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::handle
    /// is not NULL, then it must represent a valid shared NT handle that
    /// references a memory object. Ownership of this handle is
    /// not transferred to CUDA after the import operation, so the
    /// application must release the handle using the appropriate system
    /// call. If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::name
    /// is not NULL, then it must point to a NULL-terminated array of
    /// UTF-16 characters that refers to a memory object.
    ///
    /// If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT, then
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::handle must
    /// be non-NULL and
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::name
    /// must be NULL. The handle specified must be a globally shared KMT
    /// handle. This handle does not hold a reference to the underlying
    /// object, and thus will be invalid when all references to the
    /// memory object are destroyed.
    ///
    /// If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP, then exactly one
    /// of ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::handle and
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::name must not be
    /// NULL. If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::handle
    /// is not NULL, then it must represent a valid shared NT handle that
    /// is returned by ID3DDevice::CreateSharedHandle when referring to a
    /// ID3D12Heap object. This handle holds a reference to the underlying
    /// object. If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::name
    /// is not NULL, then it must point to a NULL-terminated array of
    /// UTF-16 characters that refers to a ID3D12Heap object.
    ///
    /// If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE, then exactly one
    /// of ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::handle and
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::name must not be
    /// NULL. If ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::handle
    /// is not NULL, then it must represent a valid shared NT handle that
    /// is returned by ID3DDevice::CreateSharedHandle when referring to a
    /// ID3D12Resource object. This handle holds a reference to the
    /// underlying object. If
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::handle::win32::name
    /// is not NULL, then it must point to a NULL-terminated array of
    /// UTF-16 characters that refers to a ID3D12Resource object.
    ///
    /// Specifying the flag ::CUDA_EXTERNAL_MEMORY_DEDICATED in
    /// ::CUDA_EXTERNAL_MEMORY_HANDLE_DESC::flags indicates that the
    /// resource is a dedicated resource. The definition of what a
    /// dedicated resource is outside the scope of this extension.
    ///
    /// \param extMem_out    - Returned handle to an external memory object
    /// \param memHandleDesc - Memory import handle descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \note If the Vulkan memory imported into CUDA is mapped on the CPU then the
    /// application must use vkInvalidateMappedMemoryRanges/vkFlushMappedMemoryRanges
    /// as well as appropriate Vulkan pipeline barriers to maintain coherence between
    /// CPU and GPU. For more information on these APIs, please refer to "Synchronization
    /// and Cache Control" chapter from Vulkan specification.
    ///
    /// \sa ::cuDestroyExternalMemory,
    /// ::cuExternalMemoryGetMappedBuffer,
    /// ::cuExternalMemoryGetMappedMipmappedArray
    pub fn cuImportExternalMemory(
        extMem_out: *mut CUexternalMemory,
        memHandleDesc: *const CUDA_EXTERNAL_MEMORY_HANDLE_DESC,
    ) -> CUresult;
}
extern "C" {
    /// \brief Maps a buffer onto an imported memory object
    ///
    /// Maps a buffer onto an imported memory object and returns a device
    /// pointer in \p devPtr.
    ///
    /// The properties of the buffer being mapped must be described in
    /// \p bufferDesc. The ::CUDA_EXTERNAL_MEMORY_BUFFER_DESC structure is
    /// defined as follows:
    ///
    /// \code
    ///typedef struct CUDA_EXTERNAL_MEMORY_BUFFER_DESC_st {
    ///unsigned long long offset;
    ///unsigned long long size;
    ///unsigned int flags;
    ///} CUDA_EXTERNAL_MEMORY_BUFFER_DESC;
    /// \endcode
    ///
    /// where ::CUDA_EXTERNAL_MEMORY_BUFFER_DESC::offset is the offset in
    /// the memory object where the buffer's base address is.
    /// ::CUDA_EXTERNAL_MEMORY_BUFFER_DESC::size is the size of the buffer.
    /// ::CUDA_EXTERNAL_MEMORY_BUFFER_DESC::flags must be zero.
    ///
    /// The offset and size have to be suitably aligned to match the
    /// requirements of the external API. Mapping two buffers whose ranges
    /// overlap may or may not result in the same virtual address being
    /// returned for the overlapped portion. In such cases, the application
    /// must ensure that all accesses to that region from the GPU are
    /// volatile. Otherwise writes made via one address are not guaranteed
    /// to be visible via the other address, even if they're issued by the
    /// same thread. It is recommended that applications map the combined
    /// range instead of mapping separate buffers and then apply the
    /// appropriate offsets to the returned pointer to derive the
    /// individual buffers.
    ///
    /// \param devPtr     - Returned device pointer to buffer
    /// \param extMem     - Handle to external memory object
    /// \param bufferDesc - Buffer descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuImportExternalMemory
    /// ::cuDestroyExternalMemory,
    /// ::cuExternalMemoryGetMappedMipmappedArray
    pub fn cuExternalMemoryGetMappedBuffer(
        devPtr: *mut CUdeviceptr,
        extMem: CUexternalMemory,
        bufferDesc: *const CUDA_EXTERNAL_MEMORY_BUFFER_DESC,
    ) -> CUresult;
}
extern "C" {
    /// \brief Maps a CUDA mipmapped array onto an external memory object
    ///
    /// Maps a CUDA mipmapped array onto an external object and returns a
    /// handle to it in \p mipmap.
    ///
    /// The properties of the CUDA mipmapped array being mapped must be
    /// described in \p mipmapDesc. The structure
    /// ::CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC is defined as follows:
    ///
    /// \code
    ///typedef struct CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_st {
    ///unsigned long long offset;
    ///CUDA_ARRAY3D_DESCRIPTOR arrayDesc;
    ///unsigned int numLevels;
    ///} CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC;
    /// \endcode
    ///
    /// where ::CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC::offset is the
    /// offset in the memory object where the base level of the mipmap
    /// chain is.
    /// ::CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC::arrayDesc describes
    /// the format, dimensions and type of the base level of the mipmap
    /// chain. For further details on these parameters, please refer to the
    /// documentation for ::cuMipmappedArrayCreate. Note that if the mipmapped
    /// array is bound as a color target in the graphics API, then the flag
    /// ::CUDA_ARRAY3D_COLOR_ATTACHMENT must be specified in
    /// ::CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC::arrayDesc::Flags.
    /// ::CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC::numLevels specifies
    /// the total number of levels in the mipmap chain.
    ///
    /// \param mipmap     - Returned CUDA mipmapped array
    /// \param extMem     - Handle to external memory object
    /// \param mipmapDesc - CUDA array descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuImportExternalMemory
    /// ::cuDestroyExternalMemory,
    /// ::cuExternalMemoryGetMappedBuffer
    pub fn cuExternalMemoryGetMappedMipmappedArray(
        mipmap: *mut CUmipmappedArray,
        extMem: CUexternalMemory,
        mipmapDesc: *const CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC,
    ) -> CUresult;
}
extern "C" {
    /// \brief Releases all resources associated with an external memory
    /// object.
    ///
    /// Frees all buffers and CUDA mipmapped arrays that were
    /// mapped onto this external memory object and releases any reference
    /// on the underlying memory itself.
    ///
    /// \param extMem - External memory object to be destroyed
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuImportExternalMemory
    /// ::cuExternalMemoryGetMappedBuffer,
    /// ::cuExternalMemoryGetMappedMipmappedArray
    pub fn cuDestroyExternalMemory(extMem: CUexternalMemory) -> CUresult;
}
extern "C" {
    /// \brief Imports an external semaphore
    ///
    /// Imports an externally allocated synchronization object and returns
    /// a handle to that in \p extSem_out.
    ///
    /// The properties of the handle being imported must be described in
    /// \p semHandleDesc. The ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC is
    /// defined as follows:
    ///
    /// \code
    ///typedef struct CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_st {
    ///CUexternalSemaphoreHandleType type;
    ///union {
    ///int fd;
    ///struct {
    ///void *handle;
    ///const void *name;
    ///} win32;
    ///} handle;
    ///unsigned int flags;
    ///} CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC;
    /// \endcode
    ///
    /// where ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::type specifies the type of
    /// handle being imported. ::CUexternalSemaphoreHandleType is defined
    /// as:
    ///
    /// \code
    ///typedef enum CUexternalSemaphoreHandleType_enum {
    ///CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD        = 1,
    ///CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32     = 2,
    ///CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT = 3,
    ///CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE      = 4
    ///} CUexternalSemaphoreHandleType;
    /// \endcode
    ///
    /// If ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD, then
    /// ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::fd must be a valid
    /// file descriptor referencing a synchronization object. Ownership of
    /// the file descriptor is transferred to the CUDA driver when the
    /// handle is imported successfully. Performing any operations on the
    /// file descriptor after it is imported results in undefined behavior.
    ///
    /// If ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32, then exactly one
    /// of ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::handle and
    /// ::cudaExternalSemaphoreHandleDesc::handle::win32::name must not be
    /// NULL. If
    /// ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::handle
    /// is not NULL, then it must represent a valid shared NT handle that
    /// references a synchronization object. Ownership of this handle is
    /// not transferred to CUDA after the import operation, so the
    /// application must release the handle using the appropriate system
    /// call. If ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::name
    /// is not NULL, then it must name a valid synchronization object.
    ///
    /// If ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT, then
    /// ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::handle must
    /// be non-NULL and
    /// ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::name
    /// must be NULL. The handle specified must be a globally shared KMT
    /// handle. This handle does not hold a reference to the underlying
    /// object, and thus will be invalid when all references to the
    /// synchronization object are destroyed.
    ///
    /// If ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::type is
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE, then exactly one
    /// of ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::handle and
    /// ::cudaExternalSemaphoreHandleDesc::handle::win32::name must not be
    /// NULL. If
    /// ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::handle
    /// is not NULL, then it must represent a valid shared NT handle that
    /// is returned by ID3DDevice::CreateSharedHandle when referring to a
    /// ID3D12Fence object. This handle holds a reference to the underlying
    /// object. If
    /// ::CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC::handle::win32::name
    /// is not NULL, then it must name a valid synchronization object that
    /// refers to a valid ID3D12Fence object.
    ///
    /// \param extSem_out    - Returned handle to an external semaphore
    /// \param semHandleDesc - Semaphore import handle descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuDestroyExternalSemaphore,
    /// ::cuSignalExternalSemaphoresAsync,
    /// ::cuWaitExternalSemaphoresAsync
    pub fn cuImportExternalSemaphore(
        extSem_out: *mut CUexternalSemaphore,
        semHandleDesc: *const CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC,
    ) -> CUresult;
}
extern "C" {
    /// \brief Signals a set of external semaphore objects
    ///
    /// Enqueues a signal operation on a set of externally allocated
    /// semaphore object in the specified stream. The operations will be
    /// executed when all prior operations in the stream complete.
    ///
    /// The exact semantics of signaling a semaphore depends on the type of
    /// the object.
    ///
    /// If the semaphore object is any one of the following types:
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD,
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32,
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT
    /// then signaling the semaphore will set it to the signaled state.
    ///
    /// If the semaphore object is of the type
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE, then the
    /// semaphore will be set to the value specified in
    /// ::CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS::params::fence::value.
    ///
    /// \param extSemArray - Set of external semaphores to be signaled
    /// \param paramsArray - Array of semaphore parameters
    /// \param numExtSems  - Number of semaphores to signal
    /// \param stream     - Stream to enqueue the signal operations in
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuImportExternalSemaphore,
    /// ::cuDestroyExternalSemaphore,
    /// ::cuWaitExternalSemaphoresAsync
    pub fn cuSignalExternalSemaphoresAsync(
        extSemArray: *const CUexternalSemaphore,
        paramsArray: *const CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS,
        numExtSems: ::std::os::raw::c_uint,
        stream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Waits on a set of external semaphore objects
    ///
    /// Enqueues a wait operation on a set of externally allocated
    /// semaphore object in the specified stream. The operations will be
    /// executed when all prior operations in the stream complete.
    ///
    /// The exact semantics of waiting on a semaphore depends on the type
    /// of the object.
    ///
    /// If the semaphore object is any one of the following types:
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD,
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32,
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT
    /// then waiting on the semaphore will wait until the semaphore reaches
    /// the signaled state. The semaphore will then be reset to the
    /// unsignaled state. Therefore for every signal operation, there can
    /// only be one wait operation.
    ///
    /// If the semaphore object is of the type
    /// ::CU_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE, then waiting on
    /// the semaphore will wait until the value of the semaphore is
    /// greater than or equal to
    /// ::CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS::params::fence::value.
    ///
    /// \param extSemArray - External semaphores to be waited on
    /// \param paramsArray - Array of semaphore parameters
    /// \param numExtSems  - Number of semaphores to wait on
    /// \param stream      - Stream to enqueue the wait operations in
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuImportExternalSemaphore,
    /// ::cuDestroyExternalSemaphore,
    /// ::cuSignalExternalSemaphoresAsync
    pub fn cuWaitExternalSemaphoresAsync(
        extSemArray: *const CUexternalSemaphore,
        paramsArray: *const CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS,
        numExtSems: ::std::os::raw::c_uint,
        stream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Destroys an external semaphore
    ///
    /// Destroys an external semaphore object and releases any references
    /// to the underlying resource. Any outstanding signals or waits must
    /// have completed before the semaphore is destroyed.
    ///
    /// \param extSem - External semaphore to be destroyed
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuImportExternalSemaphore,
    /// ::cuSignalExternalSemaphoresAsync,
    /// ::cuWaitExternalSemaphoresAsync
    pub fn cuDestroyExternalSemaphore(extSem: CUexternalSemaphore) -> CUresult;
}
extern "C" {
    /// \brief Wait on a memory location
    ///
    /// Enqueues a synchronization of the stream on the given memory location. Work
    /// ordered after the operation will block until the given condition on the
    /// memory is satisfied. By default, the condition is to wait for
    /// (int32_t)(*addr - value) >= 0, a cyclic greater-or-equal.
    /// Other condition types can be specified via \p flags.
    ///
    /// If the memory was registered via ::cuMemHostRegister(), the device pointer
    /// should be obtained with ::cuMemHostGetDevicePointer(). This function cannot
    /// be used with managed memory (::cuMemAllocManaged).
    ///
    /// Support for this can be queried with ::cuDeviceGetAttribute() and
    /// ::CU_DEVICE_ATTRIBUTE_CAN_USE_STREAM_MEM_OPS.
    ///
    /// Support for CU_STREAM_WAIT_VALUE_NOR can be queried with ::cuDeviceGetAttribute() and
    /// ::CU_DEVICE_ATTRIBUTE_CAN_USE_STREAM_WAIT_VALUE_NOR.
    ///
    /// \param stream The stream to synchronize on the memory location.
    /// \param addr The memory location to wait on.
    /// \param value The value to compare with the memory location.
    /// \param flags See ::CUstreamWaitValue_flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWaitValue64,
    /// ::cuStreamWriteValue32,
    /// ::cuStreamWriteValue64
    /// ::cuStreamBatchMemOp,
    /// ::cuMemHostRegister,
    /// ::cuStreamWaitEvent
    pub fn cuStreamWaitValue32(
        stream: CUstream,
        addr: CUdeviceptr,
        value: cuuint32_t,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Wait on a memory location
    ///
    /// Enqueues a synchronization of the stream on the given memory location. Work
    /// ordered after the operation will block until the given condition on the
    /// memory is satisfied. By default, the condition is to wait for
    /// (int64_t)(*addr - value) >= 0, a cyclic greater-or-equal.
    /// Other condition types can be specified via \p flags.
    ///
    /// If the memory was registered via ::cuMemHostRegister(), the device pointer
    /// should be obtained with ::cuMemHostGetDevicePointer().
    ///
    /// Support for this can be queried with ::cuDeviceGetAttribute() and
    /// ::CU_DEVICE_ATTRIBUTE_CAN_USE_64_BIT_STREAM_MEM_OPS.
    ///
    /// \param stream The stream to synchronize on the memory location.
    /// \param addr The memory location to wait on.
    /// \param value The value to compare with the memory location.
    /// \param flags See ::CUstreamWaitValue_flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWaitValue32,
    /// ::cuStreamWriteValue32,
    /// ::cuStreamWriteValue64,
    /// ::cuStreamBatchMemOp,
    /// ::cuMemHostRegister,
    /// ::cuStreamWaitEvent
    pub fn cuStreamWaitValue64(
        stream: CUstream,
        addr: CUdeviceptr,
        value: cuuint64_t,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Write a value to memory
    ///
    /// Write a value to memory. Unless the ::CU_STREAM_WRITE_VALUE_NO_MEMORY_BARRIER
    /// flag is passed, the write is preceded by a system-wide memory fence,
    /// equivalent to a __threadfence_system() but scoped to the stream
    /// rather than a CUDA thread.
    ///
    /// If the memory was registered via ::cuMemHostRegister(), the device pointer
    /// should be obtained with ::cuMemHostGetDevicePointer(). This function cannot
    /// be used with managed memory (::cuMemAllocManaged).
    ///
    /// Support for this can be queried with ::cuDeviceGetAttribute() and
    /// ::CU_DEVICE_ATTRIBUTE_CAN_USE_STREAM_MEM_OPS.
    ///
    /// \param stream The stream to do the write in.
    /// \param addr The device address to write to.
    /// \param value The value to write.
    /// \param flags See ::CUstreamWriteValue_flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWriteValue64,
    /// ::cuStreamWaitValue32,
    /// ::cuStreamWaitValue64,
    /// ::cuStreamBatchMemOp,
    /// ::cuMemHostRegister,
    /// ::cuEventRecord
    pub fn cuStreamWriteValue32(
        stream: CUstream,
        addr: CUdeviceptr,
        value: cuuint32_t,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Write a value to memory
    ///
    /// Write a value to memory. Unless the ::CU_STREAM_WRITE_VALUE_NO_MEMORY_BARRIER
    /// flag is passed, the write is preceded by a system-wide memory fence,
    /// equivalent to a __threadfence_system() but scoped to the stream
    /// rather than a CUDA thread.
    ///
    /// If the memory was registered via ::cuMemHostRegister(), the device pointer
    /// should be obtained with ::cuMemHostGetDevicePointer().
    ///
    /// Support for this can be queried with ::cuDeviceGetAttribute() and
    /// ::CU_DEVICE_ATTRIBUTE_CAN_USE_64_BIT_STREAM_MEM_OPS.
    ///
    /// \param stream The stream to do the write in.
    /// \param addr The device address to write to.
    /// \param value The value to write.
    /// \param flags See ::CUstreamWriteValue_flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWriteValue32,
    /// ::cuStreamWaitValue32,
    /// ::cuStreamWaitValue64,
    /// ::cuStreamBatchMemOp,
    /// ::cuMemHostRegister,
    /// ::cuEventRecord
    pub fn cuStreamWriteValue64(
        stream: CUstream,
        addr: CUdeviceptr,
        value: cuuint64_t,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Batch operations to synchronize the stream via memory operations
    ///
    /// This is a batch version of ::cuStreamWaitValue32() and ::cuStreamWriteValue32().
    /// Batching operations may avoid some performance overhead in both the API call
    /// and the device execution versus adding them to the stream in separate API
    /// calls. The operations are enqueued in the order they appear in the array.
    ///
    /// See ::CUstreamBatchMemOpType for the full set of supported operations, and
    /// ::cuStreamWaitValue32(), ::cuStreamWaitValue64(), ::cuStreamWriteValue32(),
    /// and ::cuStreamWriteValue64() for details of specific operations.
    ///
    /// Basic support for this can be queried with ::cuDeviceGetAttribute() and
    /// ::CU_DEVICE_ATTRIBUTE_CAN_USE_STREAM_MEM_OPS. See related APIs for details
    /// on querying support for specific operations.
    ///
    /// \param stream The stream to enqueue the operations in.
    /// \param count The number of operations in the array. Must be less than 256.
    /// \param paramArray The types and parameters of the individual operations.
    /// \param flags Reserved for future expansion; must be 0.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWaitValue32,
    /// ::cuStreamWaitValue64,
    /// ::cuStreamWriteValue32,
    /// ::cuStreamWriteValue64,
    /// ::cuMemHostRegister
    pub fn cuStreamBatchMemOp(
        stream: CUstream,
        count: ::std::os::raw::c_uint,
        paramArray: *mut CUstreamBatchMemOpParams,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns information about a function
    ///
    /// Returns in \p *pi the integer value of the attribute \p attrib on the kernel
    /// given by \p hfunc. The supported attributes are:
    /// - ::CU_FUNC_ATTRIBUTE_MAX_THREADS_PER_BLOCK: The maximum number of threads
    ///   per block, beyond which a launch of the function would fail. This number
    ///   depends on both the function and the device on which the function is
    ///   currently loaded.
    /// - ::CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES: The size in bytes of
    ///   statically-allocated shared memory per block required by this function.
    ///   This does not include dynamically-allocated shared memory requested by
    ///   the user at runtime.
    /// - ::CU_FUNC_ATTRIBUTE_CONST_SIZE_BYTES: The size in bytes of user-allocated
    ///   constant memory required by this function.
    /// - ::CU_FUNC_ATTRIBUTE_LOCAL_SIZE_BYTES: The size in bytes of local memory
    ///   used by each thread of this function.
    /// - ::CU_FUNC_ATTRIBUTE_NUM_REGS: The number of registers used by each thread
    ///   of this function.
    /// - ::CU_FUNC_ATTRIBUTE_PTX_VERSION: The PTX virtual architecture version for
    ///   which the function was compiled. This value is the major PTX version * 10
    ///   + the minor PTX version, so a PTX version 1.3 function would return the
    ///   value 13. Note that this may return the undefined value of 0 for cubins
    ///   compiled prior to CUDA 3.0.
    /// - ::CU_FUNC_ATTRIBUTE_BINARY_VERSION: The binary architecture version for
    ///   which the function was compiled. This value is the major binary
    ///   version * 10 + the minor binary version, so a binary version 1.3 function
    ///   would return the value 13. Note that this will return a value of 10 for
    ///   legacy cubins that do not have a properly-encoded binary architecture
    ///   version.
    /// - ::CU_FUNC_CACHE_MODE_CA: The attribute to indicate whether the function has
    ///   been compiled with user specified option "-Xptxas --dlcm=ca" set .
    /// - ::CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES: The maximum size in bytes of
    ///   dynamically-allocated shared memory.
    /// - ::CU_FUNC_ATTRIBUTE_PREFERRED_SHARED_MEMORY_CARVEOUT: Preferred shared memory-L1
    ///   cache split ratio in percent of shared memory.
    ///
    /// \param pi     - Returned attribute value
    /// \param attrib - Attribute requested
    /// \param hfunc  - Function to query attribute of
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cuLaunchKernel,
    /// ::cudaFuncGetAttributes
    /// ::cudaFuncSetAttribute
    pub fn cuFuncGetAttribute(
        pi: *mut ::std::os::raw::c_int,
        attrib: CUfunction_attribute,
        hfunc: CUfunction,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets information about a function
    ///
    /// This call sets the value of a specified attribute \p attrib on the kernel given
    /// by \p hfunc to an integer value specified by \p val
    /// This function returns CUDA_SUCCESS if the new value of the attribute could be
    /// successfully set. If the set fails, this call will return an error.
    /// Not all attributes can have values set. Attempting to set a value on a read-only
    /// attribute will result in an error (CUDA_ERROR_INVALID_VALUE)
    ///
    /// Supported attributes for the cuFuncSetAttribute call are:
    /// - ::CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES: This maximum size in bytes of
    ///   dynamically-allocated shared memory. The value should contain the requested
    ///   maximum size of dynamically-allocated shared memory. The sum of this value and
    ///   the function attribute ::CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES cannot exceed the
    ///   device attribute ::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN.
    ///   The maximal size of requestable dynamic shared memory may differ by GPU
    ///   architecture.
    /// - ::CU_FUNC_ATTRIBUTE_PREFERRED_SHARED_MEMORY_CARVEOUT: On devices where the L1
    ///   cache and shared memory use the same hardware resources, this sets the shared memory
    ///   carveout preference, in percent of the total resources. This is only a hint, and the
    ///   driver can choose a different ratio if required to execute the function.
    ///
    /// \param hfunc  - Function to query attribute of
    /// \param attrib - Attribute requested
    /// \param value   - The value to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cuLaunchKernel,
    /// ::cudaFuncGetAttributes
    /// ::cudaFuncSetAttribute
    pub fn cuFuncSetAttribute(
        hfunc: CUfunction,
        attrib: CUfunction_attribute,
        value: ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the preferred cache configuration for a device function
    ///
    /// On devices where the L1 cache and shared memory use the same hardware
    /// resources, this sets through \p config the preferred cache configuration for
    /// the device function \p hfunc. This is only a preference. The driver will use
    /// the requested configuration if possible, but it is free to choose a different
    /// configuration if required to execute \p hfunc.  Any context-wide preference
    /// set via ::cuCtxSetCacheConfig() will be overridden by this per-function
    /// setting unless the per-function setting is ::CU_FUNC_CACHE_PREFER_NONE. In
    /// that case, the current context-wide setting will be used.
    ///
    /// This setting does nothing on devices where the size of the L1 cache and
    /// shared memory are fixed.
    ///
    /// Launching a kernel with a different preference than the most recent
    /// preference setting may insert a device-side synchronization point.
    ///
    ///
    /// The supported cache configurations are:
    /// - ::CU_FUNC_CACHE_PREFER_NONE: no preference for shared memory or L1 (default)
    /// - ::CU_FUNC_CACHE_PREFER_SHARED: prefer larger shared memory and smaller L1 cache
    /// - ::CU_FUNC_CACHE_PREFER_L1: prefer larger L1 cache and smaller shared memory
    /// - ::CU_FUNC_CACHE_PREFER_EQUAL: prefer equal sized L1 cache and shared memory
    ///
    /// \param hfunc  - Kernel to configure cache for
    /// \param config - Requested cache configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuLaunchKernel,
    /// ::cudaFuncSetCacheConfig
    pub fn cuFuncSetCacheConfig(hfunc: CUfunction, config: CUfunc_cache) -> CUresult;
}
extern "C" {
    /// \brief Sets the shared memory configuration for a device function.
    ///
    /// On devices with configurable shared memory banks, this function will
    /// force all subsequent launches of the specified device function to have
    /// the given shared memory bank size configuration. On any given launch of the
    /// function, the shared memory configuration of the device will be temporarily
    /// changed if needed to suit the function's preferred configuration. Changes in
    /// shared memory configuration between subsequent launches of functions,
    /// may introduce a device side synchronization point.
    ///
    /// Any per-function setting of shared memory bank size set via
    /// ::cuFuncSetSharedMemConfig will override the context wide setting set with
    /// ::cuCtxSetSharedMemConfig.
    ///
    /// Changing the shared memory bank size will not increase shared memory usage
    /// or affect occupancy of kernels, but may have major effects on performance.
    /// Larger bank sizes will allow for greater potential bandwidth to shared memory,
    /// but will change what kinds of accesses to shared memory will result in bank
    /// conflicts.
    ///
    /// This function will do nothing on devices with fixed shared memory bank size.
    ///
    /// The supported bank configurations are:
    /// - ::CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE: use the context's shared memory
    ///   configuration when launching this function.
    /// - ::CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively four bytes when launching this function.
    /// - ::CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively eight bytes when launching this function.
    ///
    /// \param hfunc  - kernel to be given a shared memory config
    /// \param config - requested shared memory configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuCtxSetSharedMemConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuLaunchKernel,
    /// ::cudaFuncSetSharedMemConfig
    pub fn cuFuncSetSharedMemConfig(hfunc: CUfunction, config: CUsharedconfig) -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// Invokes the kernel \p f on a \p gridDimX x \p gridDimY x \p gridDimZ
    /// grid of blocks. Each block contains \p blockDimX x \p blockDimY x
    /// \p blockDimZ threads.
    ///
    /// \p sharedMemBytes sets the amount of dynamic shared memory that will be
    /// available to each thread block.
    ///
    /// Kernel parameters to \p f can be specified in one of two ways:
    ///
    /// 1) Kernel parameters can be specified via \p kernelParams.  If \p f
    /// has N parameters, then \p kernelParams needs to be an array of N
    /// pointers.  Each of \p kernelParams[0] through \p kernelParams[N-1]
    /// must point to a region of memory from which the actual kernel
    /// parameter will be copied.  The number of kernel parameters and their
    /// offsets and sizes do not need to be specified as that information is
    /// retrieved directly from the kernel's image.
    ///
    /// 2) Kernel parameters can also be packaged by the application into
    /// a single buffer that is passed in via the \p extra parameter.
    /// This places the burden on the application of knowing each kernel
    /// parameter's size and alignment/padding within the buffer.  Here is
    /// an example of using the \p extra parameter in this manner:
    /// \code
    ///size_t argBufferSize;
    ///char argBuffer[256];
    ///
    ///// populate argBuffer and argBufferSize
    ///
    ///void *config[] = {
    ///CU_LAUNCH_PARAM_BUFFER_POINTER, argBuffer,
    ///CU_LAUNCH_PARAM_BUFFER_SIZE,    &argBufferSize,
    ///CU_LAUNCH_PARAM_END
    ///};
    ///status = cuLaunchKernel(f, gx, gy, gz, bx, by, bz, sh, s, NULL, config);
    /// \endcode
    ///
    /// The \p extra parameter exists to allow ::cuLaunchKernel to take
    /// additional less commonly used arguments.  \p extra specifies a list of
    /// names of extra settings and their corresponding values.  Each extra
    /// setting name is immediately followed by the corresponding value.  The
    /// list must be terminated with either NULL or ::CU_LAUNCH_PARAM_END.
    ///
    /// - ::CU_LAUNCH_PARAM_END, which indicates the end of the \p extra
    ///   array;
    /// - ::CU_LAUNCH_PARAM_BUFFER_POINTER, which specifies that the next
    ///   value in \p extra will be a pointer to a buffer containing all
    ///   the kernel parameters for launching kernel \p f;
    /// - ::CU_LAUNCH_PARAM_BUFFER_SIZE, which specifies that the next
    ///   value in \p extra will be a pointer to a size_t containing the
    ///   size of the buffer specified with ::CU_LAUNCH_PARAM_BUFFER_POINTER;
    ///
    /// The error ::CUDA_ERROR_INVALID_VALUE will be returned if kernel
    /// parameters are specified with both \p kernelParams and \p extra
    /// (i.e. both \p kernelParams and \p extra are non-NULL).
    ///
    /// Calling ::cuLaunchKernel() sets persistent function state that is
    /// the same as function state set through the following deprecated APIs:
    ///  ::cuFuncSetBlockShape(),
    ///  ::cuFuncSetSharedSize(),
    ///  ::cuParamSetSize(),
    ///  ::cuParamSeti(),
    ///  ::cuParamSetf(),
    ///  ::cuParamSetv().
    ///
    /// When the kernel \p f is launched via ::cuLaunchKernel(), the previous
    /// block shape, shared size and parameter info associated with \p f
    /// is overwritten.
    ///
    /// Note that to use ::cuLaunchKernel(), the kernel \p f must either have
    /// been compiled with toolchain version 3.2 or later so that it will
    /// contain kernel parameter information, or have no kernel parameters.
    /// If either of these conditions is not met, then ::cuLaunchKernel() will
    /// return ::CUDA_ERROR_INVALID_IMAGE.
    ///
    /// \param f              - Kernel to launch
    /// \param gridDimX       - Width of grid in blocks
    /// \param gridDimY       - Height of grid in blocks
    /// \param gridDimZ       - Depth of grid in blocks
    /// \param blockDimX      - X dimension of each thread block
    /// \param blockDimY      - Y dimension of each thread block
    /// \param blockDimZ      - Z dimension of each thread block
    /// \param sharedMemBytes - Dynamic shared-memory size per thread block in bytes
    /// \param hStream        - Stream identifier
    /// \param kernelParams   - Array of pointers to kernel parameters
    /// \param extra          - Extra options
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_IMAGE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cudaLaunchKernel
    pub fn cuLaunchKernel(
        f: CUfunction,
        gridDimX: ::std::os::raw::c_uint,
        gridDimY: ::std::os::raw::c_uint,
        gridDimZ: ::std::os::raw::c_uint,
        blockDimX: ::std::os::raw::c_uint,
        blockDimY: ::std::os::raw::c_uint,
        blockDimZ: ::std::os::raw::c_uint,
        sharedMemBytes: ::std::os::raw::c_uint,
        hStream: CUstream,
        kernelParams: *mut *mut ::std::os::raw::c_void,
        extra: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function where thread blocks can cooperate and synchronize as they execute
    ///
    /// Invokes the kernel \p f on a \p gridDimX x \p gridDimY x \p gridDimZ
    /// grid of blocks. Each block contains \p blockDimX x \p blockDimY x
    /// \p blockDimZ threads.
    ///
    /// \p sharedMemBytes sets the amount of dynamic shared memory that will be
    /// available to each thread block.
    ///
    /// The device on which this kernel is invoked must have a non-zero value for
    /// the device attribute ::CU_DEVICE_ATTRIBUTE_COOPERATIVE_LAUNCH.
    ///
    /// The total number of blocks launched cannot exceed the maximum number of blocks per
    /// multiprocessor as returned by ::cuOccupancyMaxActiveBlocksPerMultiprocessor (or
    /// ::cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags) times the number of multiprocessors
    /// as specified by the device attribute ::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT.
    ///
    /// The kernel cannot make use of CUDA dynamic parallelism.
    ///
    /// Kernel parameters must be specified via \p kernelParams.  If \p f
    /// has N parameters, then \p kernelParams needs to be an array of N
    /// pointers.  Each of \p kernelParams[0] through \p kernelParams[N-1]
    /// must point to a region of memory from which the actual kernel
    /// parameter will be copied.  The number of kernel parameters and their
    /// offsets and sizes do not need to be specified as that information is
    /// retrieved directly from the kernel's image.
    ///
    /// Calling ::cuLaunchCooperativeKernel() sets persistent function state that is
    /// the same as function state set through ::cuLaunchKernel API
    ///
    /// When the kernel \p f is launched via ::cuLaunchCooperativeKernel(), the previous
    /// block shape, shared size and parameter info associated with \p f
    /// is overwritten.
    ///
    /// Note that to use ::cuLaunchCooperativeKernel(), the kernel \p f must either have
    /// been compiled with toolchain version 3.2 or later so that it will
    /// contain kernel parameter information, or have no kernel parameters.
    /// If either of these conditions is not met, then ::cuLaunchCooperativeKernel() will
    /// return ::CUDA_ERROR_INVALID_IMAGE.
    ///
    /// \param f              - Kernel to launch
    /// \param gridDimX       - Width of grid in blocks
    /// \param gridDimY       - Height of grid in blocks
    /// \param gridDimZ       - Depth of grid in blocks
    /// \param blockDimX      - X dimension of each thread block
    /// \param blockDimY      - Y dimension of each thread block
    /// \param blockDimZ      - Z dimension of each thread block
    /// \param sharedMemBytes - Dynamic shared-memory size per thread block in bytes
    /// \param hStream        - Stream identifier
    /// \param kernelParams   - Array of pointers to kernel parameters
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_IMAGE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_COOPERATIVE_LAUNCH_TOO_LARGE,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuLaunchCooperativeKernelMultiDevice,
    /// ::cudaLaunchCooperativeKernel
    pub fn cuLaunchCooperativeKernel(
        f: CUfunction,
        gridDimX: ::std::os::raw::c_uint,
        gridDimY: ::std::os::raw::c_uint,
        gridDimZ: ::std::os::raw::c_uint,
        blockDimX: ::std::os::raw::c_uint,
        blockDimY: ::std::os::raw::c_uint,
        blockDimZ: ::std::os::raw::c_uint,
        sharedMemBytes: ::std::os::raw::c_uint,
        hStream: CUstream,
        kernelParams: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Launches CUDA functions on multiple devices where thread blocks can cooperate and synchronize as they execute
    ///
    /// Invokes kernels as specified in the \p launchParamsList array where each element
    /// of the array specifies all the parameters required to perform a single kernel launch.
    /// These kernels can cooperate and synchronize as they execute. The size of the array is
    /// specified by \p numDevices.
    ///
    /// No two kernels can be launched on the same device. All the devices targeted by this
    /// multi-device launch must be identical. All devices must have a non-zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_COOPERATIVE_MULTI_DEVICE_LAUNCH.
    ///
    /// All kernels launched must be identical with respect to the compiled code. Note that
    /// any __device__, __constant__ or __managed__ variables present in the module that owns
    /// the kernel launched on each device, are independently instantiated on every device.
    /// It is the application's responsiblity to ensure these variables are initialized and
    /// used appropriately.
    ///
    /// The size of the grids as specified in blocks, the size of the blocks themselves
    /// and the amount of shared memory used by each thread block must also match across
    /// all launched kernels.
    ///
    /// The streams used to launch these kernels must have been created via either ::cuStreamCreate
    /// or ::cuStreamCreateWithPriority. The NULL stream or ::CU_STREAM_LEGACY or ::CU_STREAM_PER_THREAD
    /// cannot be used.
    ///
    /// The total number of blocks launched per kernel cannot exceed the maximum number of blocks
    /// per multiprocessor as returned by ::cuOccupancyMaxActiveBlocksPerMultiprocessor (or
    /// ::cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags) times the number of multiprocessors
    /// as specified by the device attribute ::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT. Since the
    /// total number of blocks launched per device has to match across all devices, the maximum
    /// number of blocks that can be launched per device will be limited by the device with the
    /// least number of multiprocessors.
    ///
    /// The kernels cannot make use of CUDA dynamic parallelism.
    ///
    /// The ::CUDA_LAUNCH_PARAMS structure is defined as:
    /// \code
    ///typedef struct CUDA_LAUNCH_PARAMS_st
    ///{
    ///CUfunction function;
    ///unsigned int gridDimX;
    ///unsigned int gridDimY;
    ///unsigned int gridDimZ;
    ///unsigned int blockDimX;
    ///unsigned int blockDimY;
    ///unsigned int blockDimZ;
    ///unsigned int sharedMemBytes;
    ///CUstream hStream;
    ///void **kernelParams;
    ///} CUDA_LAUNCH_PARAMS;
    /// \endcode
    /// where:
    /// - ::CUDA_LAUNCH_PARAMS::function specifies the kernel to be launched. All functions must
    ///   be identical with respect to the compiled code.
    /// - ::CUDA_LAUNCH_PARAMS::gridDimX is the width of the grid in blocks. This must match across
    ///   all kernels launched.
    /// - ::CUDA_LAUNCH_PARAMS::gridDimY is the height of the grid in blocks. This must match across
    ///   all kernels launched.
    /// - ::CUDA_LAUNCH_PARAMS::gridDimZ is the depth of the grid in blocks. This must match across
    ///   all kernels launched.
    /// - ::CUDA_LAUNCH_PARAMS::blockDimX is the X dimension of each thread block. This must match across
    ///   all kernels launched.
    /// - ::CUDA_LAUNCH_PARAMS::blockDimX is the Y dimension of each thread block. This must match across
    ///   all kernels launched.
    /// - ::CUDA_LAUNCH_PARAMS::blockDimZ is the Z dimension of each thread block. This must match across
    ///   all kernels launched.
    /// - ::CUDA_LAUNCH_PARAMS::sharedMemBytes is the dynamic shared-memory size per thread block in bytes.
    ///   This must match across all kernels launched.
    /// - ::CUDA_LAUNCH_PARAMS::hStream is the handle to the stream to perform the launch in. This cannot
    ///   be the NULL stream or ::CU_STREAM_LEGACY or ::CU_STREAM_PER_THREAD. The CUDA context associated
    ///   with this stream must match that associated with ::CUDA_LAUNCH_PARAMS::function.
    /// - ::CUDA_LAUNCH_PARAMS::kernelParams is an array of pointers to kernel parameters. If
    ///   ::CUDA_LAUNCH_PARAMS::function has N parameters, then ::CUDA_LAUNCH_PARAMS::kernelParams
    ///   needs to be an array of N pointers. Each of ::CUDA_LAUNCH_PARAMS::kernelParams[0] through
    ///   ::CUDA_LAUNCH_PARAMS::kernelParams[N-1] must point to a region of memory from which the actual
    ///   kernel parameter will be copied. The number of kernel parameters and their offsets and sizes
    ///   do not need to be specified as that information is retrieved directly from the kernel's image.
    ///
    /// By default, the kernel won't begin execution on any GPU until all prior work in all the specified
    /// streams has completed. This behavior can be overridden by specifying the flag
    /// ::CUDA_COOPERATIVE_LAUNCH_MULTI_DEVICE_NO_PRE_LAUNCH_SYNC. When this flag is specified, each kernel
    /// will only wait for prior work in the stream corresponding to that GPU to complete before it begins
    /// execution.
    ///
    /// Similarly, by default, any subsequent work pushed in any of the specified streams will not begin
    /// execution until the kernels on all GPUs have completed. This behavior can be overridden by specifying
    /// the flag ::CUDA_COOPERATIVE_LAUNCH_MULTI_DEVICE_NO_POST_LAUNCH_SYNC. When this flag is specified,
    /// any subsequent work pushed in any of the specified streams will only wait for the kernel launched
    /// on the GPU corresponding to that stream to complete before it begins execution.
    ///
    /// Calling ::cuLaunchCooperativeKernelMultiDevice() sets persistent function state that is
    /// the same as function state set through ::cuLaunchKernel API when called individually for each
    /// element in \p launchParamsList.
    ///
    /// When kernels are launched via ::cuLaunchCooperativeKernelMultiDevice(), the previous
    /// block shape, shared size and parameter info associated with each ::CUDA_LAUNCH_PARAMS::function
    /// in \p launchParamsList is overwritten.
    ///
    /// Note that to use ::cuLaunchCooperativeKernelMultiDevice(), the kernels must either have
    /// been compiled with toolchain version 3.2 or later so that it will
    /// contain kernel parameter information, or have no kernel parameters.
    /// If either of these conditions is not met, then ::cuLaunchCooperativeKernelMultiDevice() will
    /// return ::CUDA_ERROR_INVALID_IMAGE.
    ///
    /// \param launchParamsList - List of launch parameters, one per device
    /// \param numDevices       - Size of the \p launchParamsList array
    /// \param flags            - Flags to control launch behavior
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_IMAGE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_COOPERATIVE_LAUNCH_TOO_LARGE,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuLaunchCooperativeKernel,
    /// ::cudaLaunchCooperativeKernelMultiDevice
    pub fn cuLaunchCooperativeKernelMultiDevice(
        launchParamsList: *mut CUDA_LAUNCH_PARAMS,
        numDevices: ::std::os::raw::c_uint,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Enqueues a host function call in a stream
    ///
    /// Enqueues a host function to run in a stream.  The function will be called
    /// after currently enqueued work and will block work added after it.
    ///
    /// The host function must not make any CUDA API calls.  Attempting to use a
    /// CUDA API may result in ::CUDA_ERROR_NOT_PERMITTED, but this is not required.
    /// The host function must not perform any synchronization that may depend on
    /// outstanding CUDA work not mandated to run earlier.  Host functions without a
    /// mandated order (such as in independent streams) execute in undefined order
    /// and may be serialized.
    ///
    /// For the purposes of Unified Memory, execution makes a number of guarantees:
    /// <ul>
    ///   <li>The stream is considered idle for the duration of the function's
    ///   execution.  Thus, for example, the function may always use memory attached
    ///   to the stream it was enqueued in.</li>
    ///   <li>The start of execution of the function has the same effect as
    ///   synchronizing an event recorded in the same stream immediately prior to
    ///   the function.  It thus synchronizes streams which have been "joined"
    ///   prior to the function.</li>
    ///   <li>Adding device work to any stream does not have the effect of making
    ///   the stream active until all preceding host functions and stream callbacks
    ///   have executed.  Thus, for
    ///   example, a function might use global attached memory even if work has
    ///   been added to another stream, if the work has been ordered behind the
    ///   function call with an event.</li>
    ///   <li>Completion of the function does not cause a stream to become
    ///   active except as described above.  The stream will remain idle
    ///   if no device work follows the function, and will remain idle across
    ///   consecutive host functions or stream callbacks without device work in
    ///   between.  Thus, for example,
    ///   stream synchronization can be done by signaling from a host function at the
    ///   end of the stream.</li>
    /// </ul>
    ///
    /// Note that, in contrast to ::cuStreamAddCallback, the function will not be
    /// called in the event of an error in the CUDA context.
    ///
    /// \param hStream  - Stream to enqueue function call in
    /// \param fn       - The function to call once preceding stream operations are complete
    /// \param userData - User-specified data to be passed to the function
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamDestroy,
    /// ::cuMemAllocManaged,
    /// ::cuStreamAttachMemAsync,
    /// ::cuStreamAddCallback
    pub fn cuLaunchHostFunc(
        hStream: CUstream,
        fn_: CUhostFn,
        userData: *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the block-dimensions for the function
    ///
    /// \deprecated
    ///
    /// Specifies the \p x, \p y, and \p z dimensions of the thread blocks that are
    /// created when the kernel given by \p hfunc is launched.
    ///
    /// \param hfunc - Kernel to specify dimensions of
    /// \param x     - X dimension
    /// \param y     - Y dimension
    /// \param z     - Z dimension
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetSharedSize,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSeti,
    /// ::cuParamSetf,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuFuncSetBlockShape(
        hfunc: CUfunction,
        x: ::std::os::raw::c_int,
        y: ::std::os::raw::c_int,
        z: ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the dynamic shared-memory size for the function
    ///
    /// \deprecated
    ///
    /// Sets through \p bytes the amount of dynamic shared memory that will be
    /// available to each thread block when the kernel given by \p hfunc is launched.
    ///
    /// \param hfunc - Kernel to specify dynamic shared-memory size for
    /// \param bytes - Dynamic shared-memory size per thread in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSeti,
    /// ::cuParamSetf,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuFuncSetSharedSize(hfunc: CUfunction, bytes: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Sets the parameter size for the function
    ///
    /// \deprecated
    ///
    /// Sets through \p numbytes the total size in bytes needed by the function
    /// parameters of the kernel corresponding to \p hfunc.
    ///
    /// \param hfunc    - Kernel to set parameter size for
    /// \param numbytes - Size of parameter list in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuParamSetSize(hfunc: CUfunction, numbytes: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Adds an integer parameter to the function's argument list
    ///
    /// \deprecated
    ///
    /// Sets an integer parameter that will be specified the next time the
    /// kernel corresponding to \p hfunc will be invoked. \p offset is a byte offset.
    ///
    /// \param hfunc  - Kernel to add parameter to
    /// \param offset - Offset to add parameter to argument list
    /// \param value  - Value of parameter
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuParamSeti(
        hfunc: CUfunction,
        offset: ::std::os::raw::c_int,
        value: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Adds a floating-point parameter to the function's argument list
    ///
    /// \deprecated
    ///
    /// Sets a floating-point parameter that will be specified the next time the
    /// kernel corresponding to \p hfunc will be invoked. \p offset is a byte offset.
    ///
    /// \param hfunc  - Kernel to add parameter to
    /// \param offset - Offset to add parameter to argument list
    /// \param value  - Value of parameter
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuParamSetf(hfunc: CUfunction, offset: ::std::os::raw::c_int, value: f32) -> CUresult;
}
extern "C" {
    /// \brief Adds arbitrary data to the function's argument list
    ///
    /// \deprecated
    ///
    /// Copies an arbitrary amount of data (specified in \p numbytes) from \p ptr
    /// into the parameter space of the kernel corresponding to \p hfunc. \p offset
    /// is a byte offset.
    ///
    /// \param hfunc    - Kernel to add data to
    /// \param offset   - Offset to add data to argument list
    /// \param ptr      - Pointer to arbitrary data
    /// \param numbytes - Size of data to copy in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuParamSetv(
        hfunc: CUfunction,
        offset: ::std::os::raw::c_int,
        ptr: *mut ::std::os::raw::c_void,
        numbytes: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// \deprecated
    ///
    /// Invokes the kernel \p f on a 1 x 1 x 1 grid of blocks. The block
    /// contains the number of threads specified by a previous call to
    /// ::cuFuncSetBlockShape().
    ///
    /// \param f - Kernel to launch
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuLaunch(f: CUfunction) -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// \deprecated
    ///
    /// Invokes the kernel \p f on a \p grid_width x \p grid_height grid of
    /// blocks. Each block contains the number of threads specified by a previous
    /// call to ::cuFuncSetBlockShape().
    ///
    /// \param f           - Kernel to launch
    /// \param grid_width  - Width of grid in blocks
    /// \param grid_height - Height of grid in blocks
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    pub fn cuLaunchGrid(
        f: CUfunction,
        grid_width: ::std::os::raw::c_int,
        grid_height: ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// \deprecated
    ///
    /// Invokes the kernel \p f on a \p grid_width x \p grid_height grid of
    /// blocks. Each block contains the number of threads specified by a previous
    /// call to ::cuFuncSetBlockShape().
    ///
    /// \param f           - Kernel to launch
    /// \param grid_width  - Width of grid in blocks
    /// \param grid_height - Height of grid in blocks
    /// \param hStream     - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    ///
    /// \note In certain cases where cubins are created with no ABI (i.e., using \p ptxas \p --abi-compile \p no),
    ///       this function may serialize kernel launches. In order to force the CUDA driver to retain
    ///       asynchronous behavior, set the ::CU_CTX_LMEM_RESIZE_TO_MAX flag during context creation (see ::cuCtxCreate).
    ///
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchKernel
    pub fn cuLaunchGridAsync(
        f: CUfunction,
        grid_width: ::std::os::raw::c_int,
        grid_height: ::std::os::raw::c_int,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Adds a texture-reference to the function's argument list
    ///
    /// \deprecated
    ///
    /// Makes the CUDA array or linear memory bound to the texture reference
    /// \p hTexRef available to a device program as a texture. In this version of
    /// CUDA, the texture-reference must be obtained via ::cuModuleGetTexRef() and
    /// the \p texunit parameter must be set to ::CU_PARAM_TR_DEFAULT.
    ///
    /// \param hfunc   - Kernel to add texture-reference to
    /// \param texunit - Texture unit (must be ::CU_PARAM_TR_DEFAULT)
    /// \param hTexRef - Texture-reference to add to argument list
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    pub fn cuParamSetTexRef(
        hfunc: CUfunction,
        texunit: ::std::os::raw::c_int,
        hTexRef: CUtexref,
    ) -> CUresult;
}
extern "C" {
    /// \brief Creates a graph
    ///
    /// Creates an empty graph, which is returned via \p phGraph.
    ///
    /// \param phGraph - Returns newly created graph
    /// \param flags   - Graph creation flags, must be 0
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphAddEmptyNode,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphAddMemsetNode,
    /// ::cuGraphInstantiate,
    /// ::cuGraphDestroy,
    /// ::cuGraphGetNodes,
    /// ::cuGraphGetRootNodes,
    /// ::cuGraphGetEdges,
    /// ::cuGraphClone
    pub fn cuGraphCreate(phGraph: *mut CUgraph, flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Creates a kernel execution node and adds it to a graph
    ///
    /// Creates a new kernel execution node and adds it to \p hGraph with \p numDependencies
    /// dependencies specified via \p dependencies and arguments specified in \p nodeParams.
    /// It is possible for \p numDependencies to be 0, in which case the node will be placed
    /// at the root of the graph. \p dependencies may not have any duplicate entries.
    /// A handle to the new node will be returned in \p phGraphNode.
    ///
    /// The CUDA_KERNEL_NODE_PARAMS structure is defined as:
    ///
    /// \code
    ///  typedef struct CUDA_KERNEL_NODE_PARAMS_st {
    ///      CUfunction func;
    ///      unsigned int gridDimX;
    ///      unsigned int gridDimY;
    ///      unsigned int gridDimZ;
    ///      unsigned int blockDimX;
    ///      unsigned int blockDimY;
    ///      unsigned int blockDimZ;
    ///      unsigned int sharedMemBytes;
    ///      void **kernelParams;
    ///      void **extra;
    ///  } CUDA_KERNEL_NODE_PARAMS;
    /// \endcode
    ///
    /// When the graph is launched, the node will invoke kernel \p func on a (\p gridDimX x
    /// \p gridDimY x \p gridDimZ) grid of blocks. Each block contains
    /// (\p blockDimX x \p blockDimY x \p blockDimZ) threads.
    ///
    /// \p sharedMemBytes sets the amount of dynamic shared memory that will be
    /// available to each thread block.
    ///
    /// Kernel parameters to \p func can be specified in one of two ways:
    ///
    /// 1) Kernel parameters can be specified via \p kernelParams. If the kernel has N
    /// parameters, then \p kernelParams needs to be an array of N pointers. Each pointer,
    /// from \p kernelParams[0] to \p kernelParams[N-1], points to the region of memory from which the actual
    /// parameter will be copied. The number of kernel parameters and their offsets and sizes do not need
    /// to be specified as that information is retrieved directly from the kernel's image.
    ///
    /// 2) Kernel parameters can also be packaged by the application into a single buffer that is passed in
    /// via \p extra. This places the burden on the application of knowing each kernel
    /// parameter's size and alignment/padding within the buffer. The \p extra parameter exists
    /// to allow this function to take additional less commonly used arguments. \p extra specifies
    /// a list of names of extra settings and their corresponding values. Each extra setting name is
    /// immediately followed by the corresponding value. The list must be terminated with either NULL or
    /// CU_LAUNCH_PARAM_END.
    ///
    /// - ::CU_LAUNCH_PARAM_END, which indicates the end of the \p extra
    ///   array;
    /// - ::CU_LAUNCH_PARAM_BUFFER_POINTER, which specifies that the next
    ///   value in \p extra will be a pointer to a buffer
    ///   containing all the kernel parameters for launching kernel
    ///   \p func;
    /// - ::CU_LAUNCH_PARAM_BUFFER_SIZE, which specifies that the next
    ///   value in \p extra will be a pointer to a size_t
    ///   containing the size of the buffer specified with
    ///   ::CU_LAUNCH_PARAM_BUFFER_POINTER;
    ///
    /// The error ::CUDA_ERROR_INVALID_VALUE will be returned if kernel parameters are specified with both
    /// \p kernelParams and \p extra (i.e. both \p kernelParams and
    /// \p extra are non-NULL).
    ///
    /// The \p kernelParams or \p extra array, as well as the argument values it points to,
    /// are copied during this call.
    ///
    /// \note Kernels launched using graphs must not use texture and surface references. Reading or
    ///       writing through any texture or surface reference is undefined behavior.
    ///       This restriction does not apply to texture and surface objects.
    ///
    /// \param phGraphNode     - Returns newly created node
    /// \param hGraph          - Graph to which to add the node
    /// \param dependencies    - Dependencies of the node
    /// \param numDependencies - Number of dependencies
    /// \param nodeParams      - Parameters for the GPU execution node
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuLaunchKernel,
    /// ::cuGraphKernelNodeGetParams,
    /// ::cuGraphKernelNodeSetParams,
    /// ::cuGraphCreate,
    /// ::cuGraphDestroyNode,
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphAddEmptyNode,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphAddMemsetNode
    pub fn cuGraphAddKernelNode(
        phGraphNode: *mut CUgraphNode,
        hGraph: CUgraph,
        dependencies: *mut CUgraphNode,
        numDependencies: usize,
        nodeParams: *const CUDA_KERNEL_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a kernel node's parameters
    ///
    /// Returns the parameters of kernel node \p hNode in \p nodeParams.
    /// The \p kernelParams or \p extra array returned in \p nodeParams,
    /// as well as the argument values it points to, are owned by the node.
    /// This memory remains valid until the node is destroyed or its
    /// parameters are modified, and should not be modified
    /// directly. Use ::cuGraphKernelNodeSetParams to update the
    /// parameters of this node.
    ///
    /// The params will contain either \p kernelParams or \p extra,
    /// according to which of these was most recently set on the node.
    ///
    /// \param hNode      - Node to get the parameters for
    /// \param nodeParams - Pointer to return the parameters
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuLaunchKernel,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphKernelNodeSetParams
    pub fn cuGraphKernelNodeGetParams(
        hNode: CUgraphNode,
        nodeParams: *mut CUDA_KERNEL_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets a kernel node's parameters
    ///
    /// Sets the parameters of kernel node \p hNode to \p nodeParams.
    ///
    /// \param hNode      - Node to set the parameters for
    /// \param nodeParams - Parameters to copy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuLaunchKernel,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphKernelNodeGetParams
    pub fn cuGraphKernelNodeSetParams(
        hNode: CUgraphNode,
        nodeParams: *const CUDA_KERNEL_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Creates a memcpy node and adds it to a graph
    ///
    /// Creates a new memcpy node and adds it to \p hGraph with \p numDependencies
    /// dependencies specified via \p dependencies.
    /// It is possible for \p numDependencies to be 0, in which case the node will be placed
    /// at the root of the graph. \p dependencies may not have any duplicate entries.
    /// A handle to the new node will be returned in \p phGraphNode.
    ///
    /// When the graph is launched, the node will perform the memcpy described by \p copyParams.
    /// See ::cuMemcpy3D() for a description of the structure and its restrictions.
    ///
    /// Memcpy nodes have some additional restrictions with regards to managed memory, if the
    /// system contains at least one device which has a zero value for the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS. If one or more of the operands refer
    /// to managed memory, then using the memory type ::CU_MEMORYTYPE_UNIFIED is disallowed
    /// for those operand(s). The managed memory will be treated as residing on either the
    /// host or the device, depending on which memory type is specified.
    ///
    /// \param phGraphNode     - Returns newly created node
    /// \param hGraph          - Graph to which to add the node
    /// \param dependencies    - Dependencies of the node
    /// \param numDependencies - Number of dependencies
    /// \param copyParams      - Parameters for the memory copy
    /// \param ctx             - Context on which to run the node
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemcpy3D,
    /// ::cuGraphMemcpyNodeGetParams,
    /// ::cuGraphMemcpyNodeSetParams,
    /// ::cuGraphCreate,
    /// ::cuGraphDestroyNode,
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphAddEmptyNode,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphAddMemsetNode
    pub fn cuGraphAddMemcpyNode(
        phGraphNode: *mut CUgraphNode,
        hGraph: CUgraph,
        dependencies: *mut CUgraphNode,
        numDependencies: usize,
        copyParams: *const CUDA_MEMCPY3D,
        ctx: CUcontext,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a memcpy node's parameters
    ///
    /// Returns the parameters of memcpy node \p hNode in \p nodeParams.
    ///
    /// \param hNode      - Node to get the parameters for
    /// \param nodeParams - Pointer to return the parameters
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemcpy3D,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphMemcpyNodeSetParams
    pub fn cuGraphMemcpyNodeGetParams(
        hNode: CUgraphNode,
        nodeParams: *mut CUDA_MEMCPY3D,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets a memcpy node's parameters
    ///
    /// Sets the parameters of memcpy node \p hNode to \p nodeParams.
    ///
    /// \param hNode      - Node to set the parameters for
    /// \param nodeParams - Parameters to copy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemcpy3D,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphMemcpyNodeGetParams
    pub fn cuGraphMemcpyNodeSetParams(
        hNode: CUgraphNode,
        nodeParams: *const CUDA_MEMCPY3D,
    ) -> CUresult;
}
extern "C" {
    /// \brief Creates a memset node and adds it to a graph
    ///
    /// Creates a new memset node and adds it to \p hGraph with \p numDependencies
    /// dependencies specified via \p dependencies.
    /// It is possible for \p numDependencies to be 0, in which case the node will be placed
    /// at the root of the graph. \p dependencies may not have any duplicate entries.
    /// A handle to the new node will be returned in \p phGraphNode.
    ///
    /// The element size must be 1, 2, or 4 bytes.
    /// When the graph is launched, the node will perform the memset described by \p memsetParams.
    ///
    /// \param phGraphNode     - Returns newly created node
    /// \param hGraph          - Graph to which to add the node
    /// \param dependencies    - Dependencies of the node
    /// \param numDependencies - Number of dependencies
    /// \param memsetParams    - Parameters for the memory set
    /// \param ctx             - Context on which to run the node
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemsetD2D32,
    /// ::cuGraphMemsetNodeGetParams,
    /// ::cuGraphMemsetNodeSetParams,
    /// ::cuGraphCreate,
    /// ::cuGraphDestroyNode,
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphAddEmptyNode,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphAddMemcpyNode
    pub fn cuGraphAddMemsetNode(
        phGraphNode: *mut CUgraphNode,
        hGraph: CUgraph,
        dependencies: *mut CUgraphNode,
        numDependencies: usize,
        memsetParams: *const CUDA_MEMSET_NODE_PARAMS,
        ctx: CUcontext,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a memset node's parameters
    ///
    /// Returns the parameters of memset node \p hNode in \p nodeParams.
    ///
    /// \param hNode      - Node to get the parameters for
    /// \param nodeParams - Pointer to return the parameters
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemsetD2D32,
    /// ::cuGraphAddMemsetNode,
    /// ::cuGraphMemsetNodeSetParams
    pub fn cuGraphMemsetNodeGetParams(
        hNode: CUgraphNode,
        nodeParams: *mut CUDA_MEMSET_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets a memset node's parameters
    ///
    /// Sets the parameters of memset node \p hNode to \p nodeParams.
    ///
    /// \param hNode      - Node to set the parameters for
    /// \param nodeParams - Parameters to copy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuMemsetD2D32,
    /// ::cuGraphAddMemsetNode,
    /// ::cuGraphMemsetNodeGetParams
    pub fn cuGraphMemsetNodeSetParams(
        hNode: CUgraphNode,
        nodeParams: *const CUDA_MEMSET_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Creates a host execution node and adds it to a graph
    ///
    /// Creates a new CPU execution node and adds it to \p hGraph with \p numDependencies
    /// dependencies specified via \p dependencies and arguments specified in \p nodeParams.
    /// It is possible for \p numDependencies to be 0, in which case the node will be placed
    /// at the root of the graph. \p dependencies may not have any duplicate entries.
    /// A handle to the new node will be returned in \p phGraphNode.
    ///
    /// When the graph is launched, the node will invoke the specified CPU function.
    ///
    /// \param phGraphNode     - Returns newly created node
    /// \param hGraph          - Graph to which to add the node
    /// \param dependencies    - Dependencies of the node
    /// \param numDependencies - Number of dependencies
    /// \param nodeParams      - Parameters for the host node
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuLaunchHostFunc,
    /// ::cuGraphHostNodeGetParams,
    /// ::cuGraphHostNodeSetParams,
    /// ::cuGraphCreate,
    /// ::cuGraphDestroyNode,
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphAddEmptyNode,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphAddMemsetNode
    pub fn cuGraphAddHostNode(
        phGraphNode: *mut CUgraphNode,
        hGraph: CUgraph,
        dependencies: *mut CUgraphNode,
        numDependencies: usize,
        nodeParams: *const CUDA_HOST_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a host node's parameters
    ///
    /// Returns the parameters of host node \p hNode in \p nodeParams.
    ///
    /// \param hNode      - Node to get the parameters for
    /// \param nodeParams - Pointer to return the parameters
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuLaunchHostFunc,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphHostNodeSetParams
    pub fn cuGraphHostNodeGetParams(
        hNode: CUgraphNode,
        nodeParams: *mut CUDA_HOST_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets a host node's parameters
    ///
    /// Sets the parameters of host node \p hNode to \p nodeParams.
    ///
    /// \param hNode      - Node to set the parameters for
    /// \param nodeParams - Parameters to copy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuLaunchHostFunc,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphHostNodeGetParams
    pub fn cuGraphHostNodeSetParams(
        hNode: CUgraphNode,
        nodeParams: *const CUDA_HOST_NODE_PARAMS,
    ) -> CUresult;
}
extern "C" {
    /// \brief Creates a child graph node and adds it to a graph
    ///
    /// Creates a new node which executes an embedded graph, and adds it to \p hGraph with
    /// \p numDependencies dependencies specified via \p dependencies.
    /// It is possible for \p numDependencies to be 0, in which case the node will be placed
    /// at the root of the graph. \p dependencies may not have any duplicate entries.
    /// A handle to the new node will be returned in \p phGraphNode.
    ///
    /// The node executes an embedded child graph. The child graph is cloned in this call.
    ///
    /// \param phGraphNode     - Returns newly created node
    /// \param hGraph          - Graph to which to add the node
    /// \param dependencies    - Dependencies of the node
    /// \param numDependencies - Number of dependencies
    /// \param childGraph      - The graph to clone into this node
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphChildGraphNodeGetGraph,
    /// ::cuGraphCreate,
    /// ::cuGraphDestroyNode,
    /// ::cuGraphAddEmptyNode,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphAddMemsetNode,
    /// ::cuGraphClone
    pub fn cuGraphAddChildGraphNode(
        phGraphNode: *mut CUgraphNode,
        hGraph: CUgraph,
        dependencies: *mut CUgraphNode,
        numDependencies: usize,
        childGraph: CUgraph,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets a handle to the embedded graph of a child graph node
    ///
    /// Gets a handle to the embedded graph in a child graph node. This call
    /// does not clone the graph. Changes to the graph will be reflected in
    /// the node, and the node retains ownership of the graph.
    ///
    /// \param hNode   - Node to get the embedded graph for
    /// \param phGraph - Location to store a handle to the graph
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphNodeFindInClone
    pub fn cuGraphChildGraphNodeGetGraph(hNode: CUgraphNode, phGraph: *mut CUgraph) -> CUresult;
}
extern "C" {
    /// \brief Creates an empty node and adds it to a graph
    ///
    /// Creates a new node which performs no operation, and adds it to \p hGraph with
    /// \p numDependencies dependencies specified via \p dependencies.
    /// It is possible for \p numDependencies to be 0, in which case the node will be placed
    /// at the root of the graph. \p dependencies may not have any duplicate entries.
    /// A handle to the new node will be returned in \p phGraphNode.
    ///
    /// An empty node performs no operation during execution, but can be used for
    /// transitive ordering. For example, a phased execution graph with 2 groups of n
    /// nodes with a barrier between them can be represented using an empty node and
    /// 2*n dependency edges, rather than no empty node and n^2 dependency edges.
    ///
    /// \param phGraphNode     - Returns newly created node
    /// \param hGraph          - Graph to which to add the node
    /// \param dependencies    - Dependencies of the node
    /// \param numDependencies - Number of dependencies
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphCreate,
    /// ::cuGraphDestroyNode,
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphAddMemsetNode
    pub fn cuGraphAddEmptyNode(
        phGraphNode: *mut CUgraphNode,
        hGraph: CUgraph,
        dependencies: *mut CUgraphNode,
        numDependencies: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Clones a graph
    ///
    /// This function creates a copy of \p originalGraph and returns it in \p * phGraphClone.
    /// All parameters are copied into the cloned graph. The original graph may be modified
    /// after this call without affecting the clone.
    ///
    /// Child graph nodes in the original graph are recursively copied into the clone.
    ///
    /// \param phGraphClone  - Returns newly created cloned graph
    /// \param originalGraph - Graph to clone
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphCreate,
    /// ::cuGraphNodeFindInClone
    pub fn cuGraphClone(phGraphClone: *mut CUgraph, originalGraph: CUgraph) -> CUresult;
}
extern "C" {
    /// \brief Finds a cloned version of a node
    ///
    /// This function returns the node in \p hClonedGraph corresponding to \p hOriginalNode
    /// in the original graph.
    ///
    /// \p hClonedGraph must have been cloned from \p hOriginalGraph via ::cuGraphClone.
    /// \p hOriginalNode must have been in \p hOriginalGraph at the time of the call to
    /// ::cuGraphClone, and the corresponding cloned node in \p hClonedGraph must not have
    /// been removed. The cloned node is then returned via \p phClonedNode.
    ///
    /// \param phNode  - Returns handle to the cloned node
    /// \param hOriginalNode - Handle to the original node
    /// \param hClonedGraph - Cloned graph to query
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphClone
    pub fn cuGraphNodeFindInClone(
        phNode: *mut CUgraphNode,
        hOriginalNode: CUgraphNode,
        hClonedGraph: CUgraph,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a node's type
    ///
    /// Returns the node type of \p hNode in \p type.
    ///
    /// \param hNode - Node to query
    /// \param type  - Pointer to return the node type
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphGetNodes,
    /// ::cuGraphGetRootNodes,
    /// ::cuGraphChildGraphNodeGetGraph,
    /// ::cuGraphKernelNodeGetParams,
    /// ::cuGraphKernelNodeSetParams,
    /// ::cuGraphHostNodeGetParams,
    /// ::cuGraphHostNodeSetParams,
    /// ::cuGraphMemcpyNodeGetParams,
    /// ::cuGraphMemcpyNodeSetParams,
    /// ::cuGraphMemsetNodeGetParams,
    /// ::cuGraphMemsetNodeSetParams
    pub fn cuGraphNodeGetType(hNode: CUgraphNode, type_: *mut CUgraphNodeType) -> CUresult;
}
extern "C" {
    /// \brief Returns a graph's nodes
    ///
    /// Returns a list of \p hGraph's nodes. \p nodes may be NULL, in which case this
    /// function will return the number of nodes in \p numNodes. Otherwise,
    /// \p numNodes entries will be filled in. If \p numNodes is higher than the actual
    /// number of nodes, the remaining entries in \p nodes will be set to NULL, and the
    /// number of nodes actually obtained will be returned in \p numNodes.
    ///
    /// \param hGraph   - Graph to query
    /// \param nodes    - Pointer to return the nodes
    /// \param numNodes - See description
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphCreate,
    /// ::cuGraphGetRootNodes,
    /// ::cuGraphGetEdges,
    /// ::cuGraphNodeGetType,
    /// ::cuGraphNodeGetDependencies,
    /// ::cuGraphNodeGetDependentNodes
    pub fn cuGraphGetNodes(
        hGraph: CUgraph,
        nodes: *mut CUgraphNode,
        numNodes: *mut usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a graph's root nodes
    ///
    /// Returns a list of \p hGraph's root nodes. \p rootNodes may be NULL, in which case this
    /// function will return the number of root nodes in \p numRootNodes. Otherwise,
    /// \p numRootNodes entries will be filled in. If \p numRootNodes is higher than the actual
    /// number of root nodes, the remaining entries in \p rootNodes will be set to NULL, and the
    /// number of nodes actually obtained will be returned in \p numRootNodes.
    ///
    /// \param hGraph       - Graph to query
    /// \param rootNodes    - Pointer to return the root nodes
    /// \param numRootNodes - See description
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphCreate,
    /// ::cuGraphGetNodes,
    /// ::cuGraphGetEdges,
    /// ::cuGraphNodeGetType,
    /// ::cuGraphNodeGetDependencies,
    /// ::cuGraphNodeGetDependentNodes
    pub fn cuGraphGetRootNodes(
        hGraph: CUgraph,
        rootNodes: *mut CUgraphNode,
        numRootNodes: *mut usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a graph's dependency edges
    ///
    /// Returns a list of \p hGraph's dependency edges. Edges are returned via corresponding
    /// indices in \p from and \p to; that is, the node in \p to[i] has a dependency on the
    /// node in \p from[i]. \p from and \p to may both be NULL, in which
    /// case this function only returns the number of edges in \p numEdges. Otherwise,
    /// \p numEdges entries will be filled in. If \p numEdges is higher than the actual
    /// number of edges, the remaining entries in \p from and \p to will be set to NULL, and
    /// the number of edges actually returned will be written to \p numEdges.
    ///
    /// \param hGraph   - Graph to get the edges from
    /// \param from     - Location to return edge endpoints
    /// \param to       - Location to return edge endpoints
    /// \param numEdges - See description
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphGetNodes,
    /// ::cuGraphGetRootNodes,
    /// ::cuGraphAddDependencies,
    /// ::cuGraphRemoveDependencies,
    /// ::cuGraphNodeGetDependencies,
    /// ::cuGraphNodeGetDependentNodes
    pub fn cuGraphGetEdges(
        hGraph: CUgraph,
        from: *mut CUgraphNode,
        to: *mut CUgraphNode,
        numEdges: *mut usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a node's dependencies
    ///
    /// Returns a list of \p node's dependencies. \p dependencies may be NULL, in which case this
    /// function will return the number of dependencies in \p numDependencies. Otherwise,
    /// \p numDependencies entries will be filled in. If \p numDependencies is higher than the actual
    /// number of dependencies, the remaining entries in \p dependencies will be set to NULL, and the
    /// number of nodes actually obtained will be returned in \p numDependencies.
    ///
    /// \param hNode           - Node to query
    /// \param dependencies    - Pointer to return the dependencies
    /// \param numDependencies - See description
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphNodeGetDependentNodes,
    /// ::cuGraphGetNodes,
    /// ::cuGraphGetRootNodes,
    /// ::cuGraphGetEdges,
    /// ::cuGraphAddDependencies,
    /// ::cuGraphRemoveDependencies
    pub fn cuGraphNodeGetDependencies(
        hNode: CUgraphNode,
        dependencies: *mut CUgraphNode,
        numDependencies: *mut usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a node's dependent nodes
    ///
    /// Returns a list of \p node's dependent nodes. \p dependentNodes may be NULL, in which
    /// case this function will return the number of dependent nodes in \p numDependentNodes.
    /// Otherwise, \p numDependentNodes entries will be filled in. If \p numDependentNodes is
    /// higher than the actual number of dependent nodes, the remaining entries in
    /// \p dependentNodes will be set to NULL, and the number of nodes actually obtained will
    /// be returned in \p numDependentNodes.
    ///
    /// \param hNode             - Node to query
    /// \param dependentNodes    - Pointer to return the dependent nodes
    /// \param numDependentNodes - See description
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphNodeGetDependencies,
    /// ::cuGraphGetNodes,
    /// ::cuGraphGetRootNodes,
    /// ::cuGraphGetEdges,
    /// ::cuGraphAddDependencies,
    /// ::cuGraphRemoveDependencies
    pub fn cuGraphNodeGetDependentNodes(
        hNode: CUgraphNode,
        dependentNodes: *mut CUgraphNode,
        numDependentNodes: *mut usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Adds dependency edges to a graph
    ///
    /// The number of dependencies to be added is defined by \p numDependencies
    /// Elements in \p from and \p to at corresponding indices define a dependency.
    /// Each node in \p from and \p to must belong to \p hGraph.
    ///
    /// If \p numDependencies is 0, elements in \p from and \p to will be ignored.
    /// Specifying an existing dependency will return an error.
    ///
    /// \param hGraph - Graph to which dependencies are added
    /// \param from - Array of nodes that provide the dependencies
    /// \param to - Array of dependent nodes
    /// \param numDependencies - Number of dependencies to be added
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphRemoveDependencies,
    /// ::cuGraphGetEdges,
    /// ::cuGraphNodeGetDependencies,
    /// ::cuGraphNodeGetDependentNodes
    pub fn cuGraphAddDependencies(
        hGraph: CUgraph,
        from: *mut CUgraphNode,
        to: *mut CUgraphNode,
        numDependencies: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Removes dependency edges from a graph
    ///
    /// The number of \p dependencies to be removed is defined by \p numDependencies.
    /// Elements in \p from and \p to at corresponding indices define a dependency.
    /// Each node in \p from and \p to must belong to \p hGraph.
    ///
    /// If \p numDependencies is 0, elements in \p from and \p to will be ignored.
    /// Specifying a non-existing dependency will return an error.
    ///
    /// \param hGraph - Graph from which to remove dependencies
    /// \param from - Array of nodes that provide the dependencies
    /// \param to - Array of dependent nodes
    /// \param numDependencies - Number of dependencies to be removed
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphAddDependencies,
    /// ::cuGraphGetEdges,
    /// ::cuGraphNodeGetDependencies,
    /// ::cuGraphNodeGetDependentNodes
    pub fn cuGraphRemoveDependencies(
        hGraph: CUgraph,
        from: *mut CUgraphNode,
        to: *mut CUgraphNode,
        numDependencies: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Remove a node from the graph
    ///
    /// Removes \p hNode from its graph. This operation also severs any dependencies of other nodes
    /// on \p hNode and vice versa.
    ///
    /// \param hNode  - Node to remove
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphAddChildGraphNode,
    /// ::cuGraphAddEmptyNode,
    /// ::cuGraphAddKernelNode,
    /// ::cuGraphAddHostNode,
    /// ::cuGraphAddMemcpyNode,
    /// ::cuGraphAddMemsetNode
    pub fn cuGraphDestroyNode(hNode: CUgraphNode) -> CUresult;
}
extern "C" {
    /// \brief Creates an executable graph from a graph
    ///
    /// Instantiates \p hGraph as an executable graph. The graph is validated for any
    /// structural constraints or intra-node constraints which were not previously
    /// validated. If instantiation is successful, a handle to the instantiated graph
    /// is returned in \p graphExec.
    ///
    /// If there are any errors, diagnostic information may be returned in \p errorNode and
    /// \p logBuffer. This is the primary way to inspect instantiation errors. The output
    /// will be null terminated unless the diagnostics overflow
    /// the buffer. In this case, they will be truncated, and the last byte can be
    /// inspected to determine if truncation occurred.
    ///
    /// \param phGraphExec - Returns instantiated graph
    /// \param hGraph      - Graph to instantiate
    /// \param phErrorNode - In case of an instantiation error, this may be modified to
    ///                      indicate a node contributing to the error
    /// \param logBuffer   - A character buffer to store diagnostic messages
    /// \param bufferSize  - Size of the log buffer in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphCreate,
    /// ::cuGraphLaunch,
    /// ::cuGraphExecDestroy
    pub fn cuGraphInstantiate(
        phGraphExec: *mut CUgraphExec,
        hGraph: CUgraph,
        phErrorNode: *mut CUgraphNode,
        logBuffer: *mut ::std::os::raw::c_char,
        bufferSize: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Launches an executable graph in a stream
    ///
    /// Executes \p hGraphExec in \p hStream. Only one instance of \p hGraphExec may be executing
    /// at a time. Each launch is ordered behind both any previous work in \p hStream
    /// and any previous launches of \p hGraphExec. To execute a graph concurrently, it must be
    /// instantiated multiple times into multiple executable graphs.
    ///
    /// \param hGraphExec - Executable graph to launch
    /// \param hStream    - Stream in which to launch the graph
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphInstantiate,
    /// ::cuGraphExecDestroy
    pub fn cuGraphLaunch(hGraphExec: CUgraphExec, hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Destroys an executable graph
    ///
    /// Destroys the executable graph specified by \p hGraphExec, as well
    /// as all of its executable nodes. If the executable graph is
    /// in-flight, it will not be terminated, but rather freed
    /// asynchronously on completion.
    ///
    /// \param hGraphExec - Executable graph to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphInstantiate,
    /// ::cuGraphLaunch
    pub fn cuGraphExecDestroy(hGraphExec: CUgraphExec) -> CUresult;
}
extern "C" {
    /// \brief Destroys a graph
    ///
    /// Destroys the graph specified by \p hGraph, as well as all of its nodes.
    ///
    /// \param hGraph - Graph to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_graph_thread_safety
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphCreate
    pub fn cuGraphDestroy(hGraph: CUgraph) -> CUresult;
}
extern "C" {
    /// \brief Returns occupancy of a function
    ///
    /// Returns in \p *numBlocks the number of the maximum active blocks per
    /// streaming multiprocessor.
    ///
    /// \param numBlocks       - Returned occupancy
    /// \param func            - Kernel for which occupancy is calculated
    /// \param blockSize       - Block size the kernel is intended to be launched with
    /// \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa
    /// ::cudaOccupancyMaxActiveBlocksPerMultiprocessor
    pub fn cuOccupancyMaxActiveBlocksPerMultiprocessor(
        numBlocks: *mut ::std::os::raw::c_int,
        func: CUfunction,
        blockSize: ::std::os::raw::c_int,
        dynamicSMemSize: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns occupancy of a function
    ///
    /// Returns in \p *numBlocks the number of the maximum active blocks per
    /// streaming multiprocessor.
    ///
    /// The \p Flags parameter controls how special cases are handled. The
    /// valid flags are:
    ///
    /// - ::CU_OCCUPANCY_DEFAULT, which maintains the default behavior as
    ///   ::cuOccupancyMaxActiveBlocksPerMultiprocessor;
    ///
    /// - ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE, which suppresses the
    ///   default behavior on platform where global caching affects
    ///   occupancy. On such platforms, if caching is enabled, but
    ///   per-block SM resource usage would result in zero occupancy, the
    ///   occupancy calculator will calculate the occupancy as if caching
    ///   is disabled. Setting ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE makes
    ///   the occupancy calculator to return 0 in such cases. More information
    ///   can be found about this feature in the "Unified L1/Texture Cache"
    ///   section of the Maxwell tuning guide.
    ///
    /// \param numBlocks       - Returned occupancy
    /// \param func            - Kernel for which occupancy is calculated
    /// \param blockSize       - Block size the kernel is intended to be launched with
    /// \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
    /// \param flags           - Requested behavior for the occupancy calculator
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa
    /// ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
    pub fn cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
        numBlocks: *mut ::std::os::raw::c_int,
        func: CUfunction,
        blockSize: ::std::os::raw::c_int,
        dynamicSMemSize: usize,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Suggest a launch configuration with reasonable occupancy
    ///
    /// Returns in \p *blockSize a reasonable block size that can achieve
    /// the maximum occupancy (or, the maximum number of active warps with
    /// the fewest blocks per multiprocessor), and in \p *minGridSize the
    /// minimum grid size to achieve the maximum occupancy.
    ///
    /// If \p blockSizeLimit is 0, the configurator will use the maximum
    /// block size permitted by the device / function instead.
    ///
    /// If per-block dynamic shared memory allocation is not needed, the
    /// user should leave both \p blockSizeToDynamicSMemSize and \p
    /// dynamicSMemSize as 0.
    ///
    /// If per-block dynamic shared memory allocation is needed, then if
    /// the dynamic shared memory size is constant regardless of block
    /// size, the size should be passed through \p dynamicSMemSize, and \p
    /// blockSizeToDynamicSMemSize should be NULL.
    ///
    /// Otherwise, if the per-block dynamic shared memory size varies with
    /// different block sizes, the user needs to provide a unary function
    /// through \p blockSizeToDynamicSMemSize that computes the dynamic
    /// shared memory needed by \p func for any given block size. \p
    /// dynamicSMemSize is ignored. An example signature is:
    ///
    /// \code
    ///    // Take block size, returns dynamic shared memory needed
    ///    size_t blockToSmem(int blockSize);
    /// \endcode
    ///
    /// \param minGridSize - Returned minimum grid size needed to achieve the maximum occupancy
    /// \param blockSize   - Returned maximum block size that can achieve the maximum occupancy
    /// \param func        - Kernel for which launch configuration is calculated
    /// \param blockSizeToDynamicSMemSize - A function that calculates how much per-block dynamic shared memory \p func uses based on the block size
    /// \param dynamicSMemSize - Dynamic shared memory usage intended, in bytes
    /// \param blockSizeLimit  - The maximum block size \p func is designed to handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa
    /// ::cudaOccupancyMaxPotentialBlockSize
    pub fn cuOccupancyMaxPotentialBlockSize(
        minGridSize: *mut ::std::os::raw::c_int,
        blockSize: *mut ::std::os::raw::c_int,
        func: CUfunction,
        blockSizeToDynamicSMemSize: CUoccupancyB2DSize,
        dynamicSMemSize: usize,
        blockSizeLimit: ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Suggest a launch configuration with reasonable occupancy
    ///
    /// An extended version of ::cuOccupancyMaxPotentialBlockSize. In
    /// addition to arguments passed to ::cuOccupancyMaxPotentialBlockSize,
    /// ::cuOccupancyMaxPotentialBlockSizeWithFlags also takes a \p Flags
    /// parameter.
    ///
    /// The \p Flags parameter controls how special cases are handled. The
    /// valid flags are:
    ///
    /// - ::CU_OCCUPANCY_DEFAULT, which maintains the default behavior as
    ///   ::cuOccupancyMaxPotentialBlockSize;
    ///
    /// - ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE, which suppresses the
    ///   default behavior on platform where global caching affects
    ///   occupancy. On such platforms, the launch configurations that
    ///   produces maximal occupancy might not support global
    ///   caching. Setting ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE
    ///   guarantees that the the produced launch configuration is global
    ///   caching compatible at a potential cost of occupancy. More information
    ///   can be found about this feature in the "Unified L1/Texture Cache"
    ///   section of the Maxwell tuning guide.
    ///
    /// \param minGridSize - Returned minimum grid size needed to achieve the maximum occupancy
    /// \param blockSize   - Returned maximum block size that can achieve the maximum occupancy
    /// \param func        - Kernel for which launch configuration is calculated
    /// \param blockSizeToDynamicSMemSize - A function that calculates how much per-block dynamic shared memory \p func uses based on the block size
    /// \param dynamicSMemSize - Dynamic shared memory usage intended, in bytes
    /// \param blockSizeLimit  - The maximum block size \p func is designed to handle
    /// \param flags       - Options
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa
    /// ::cudaOccupancyMaxPotentialBlockSizeWithFlags
    pub fn cuOccupancyMaxPotentialBlockSizeWithFlags(
        minGridSize: *mut ::std::os::raw::c_int,
        blockSize: *mut ::std::os::raw::c_int,
        func: CUfunction,
        blockSizeToDynamicSMemSize: CUoccupancyB2DSize,
        dynamicSMemSize: usize,
        blockSizeLimit: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Binds an array as a texture reference
    ///
    /// Binds the CUDA array \p hArray to the texture reference \p hTexRef. Any
    /// previous address or CUDA array state associated with the texture reference
    /// is superseded by this function. \p Flags must be set to
    /// ::CU_TRSA_OVERRIDE_FORMAT. Any CUDA array previously bound to \p hTexRef is
    /// unbound.
    ///
    /// \param hTexRef - Texture reference to bind
    /// \param hArray  - Array to bind
    /// \param Flags   - Options (must be ::CU_TRSA_OVERRIDE_FORMAT)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTextureToArray
    pub fn cuTexRefSetArray(
        hTexRef: CUtexref,
        hArray: CUarray,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Binds a mipmapped array to a texture reference
    ///
    /// Binds the CUDA mipmapped array \p hMipmappedArray to the texture reference \p hTexRef.
    /// Any previous address or CUDA array state associated with the texture reference
    /// is superseded by this function. \p Flags must be set to ::CU_TRSA_OVERRIDE_FORMAT.
    /// Any CUDA array previously bound to \p hTexRef is unbound.
    ///
    /// \param hTexRef         - Texture reference to bind
    /// \param hMipmappedArray - Mipmapped array to bind
    /// \param Flags           - Options (must be ::CU_TRSA_OVERRIDE_FORMAT)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetMipmappedArray(
        hTexRef: CUtexref,
        hMipmappedArray: CUmipmappedArray,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    pub fn cuTexRefSetAddress_v2(
        ByteOffset: *mut usize,
        hTexRef: CUtexref,
        dptr: CUdeviceptr,
        bytes: usize,
    ) -> CUresult;
}
extern "C" {
    pub fn cuTexRefSetAddress2D_v3(
        hTexRef: CUtexref,
        desc: *const CUDA_ARRAY_DESCRIPTOR,
        dptr: CUdeviceptr,
        Pitch: usize,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the format for a texture reference
    ///
    /// Specifies the format of the data to be read by the texture reference
    /// \p hTexRef. \p fmt and \p NumPackedComponents are exactly analogous to the
    /// ::Format and ::NumChannels members of the ::CUDA_ARRAY_DESCRIPTOR structure:
    /// They specify the format of each component and the number of components per
    /// array element.
    ///
    /// \param hTexRef             - Texture reference
    /// \param fmt                 - Format to set
    /// \param NumPackedComponents - Number of components per array element
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaCreateChannelDesc,
    /// ::cudaBindTexture,
    /// ::cudaBindTexture2D,
    /// ::cudaBindTextureToArray,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetFormat(
        hTexRef: CUtexref,
        fmt: CUarray_format,
        NumPackedComponents: ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the addressing mode for a texture reference
    ///
    /// Specifies the addressing mode \p am for the given dimension \p dim of the
    /// texture reference \p hTexRef. If \p dim is zero, the addressing mode is
    /// applied to the first parameter of the functions used to fetch from the
    /// texture; if \p dim is 1, the second, and so on. ::CUaddress_mode is defined
    /// as:
    /// \code
    ///typedef enum CUaddress_mode_enum {
    ///CU_TR_ADDRESS_MODE_WRAP = 0,
    ///CU_TR_ADDRESS_MODE_CLAMP = 1,
    ///CU_TR_ADDRESS_MODE_MIRROR = 2,
    ///CU_TR_ADDRESS_MODE_BORDER = 3
    ///} CUaddress_mode;
    /// \endcode
    ///
    /// Note that this call has no effect if \p hTexRef is bound to linear memory.
    /// Also, if the flag, ::CU_TRSF_NORMALIZED_COORDINATES, is not set, the only
    /// supported address mode is ::CU_TR_ADDRESS_MODE_CLAMP.
    ///
    /// \param hTexRef - Texture reference
    /// \param dim     - Dimension
    /// \param am      - Addressing mode to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTexture,
    /// ::cudaBindTexture2D,
    /// ::cudaBindTextureToArray,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetAddressMode(
        hTexRef: CUtexref,
        dim: ::std::os::raw::c_int,
        am: CUaddress_mode,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the filtering mode for a texture reference
    ///
    /// Specifies the filtering mode \p fm to be used when reading memory through
    /// the texture reference \p hTexRef. ::CUfilter_mode_enum is defined as:
    ///
    /// \code
    ///typedef enum CUfilter_mode_enum {
    ///CU_TR_FILTER_MODE_POINT = 0,
    ///CU_TR_FILTER_MODE_LINEAR = 1
    ///} CUfilter_mode;
    /// \endcode
    ///
    /// Note that this call has no effect if \p hTexRef is bound to linear memory.
    ///
    /// \param hTexRef - Texture reference
    /// \param fm      - Filtering mode to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTextureToArray
    pub fn cuTexRefSetFilterMode(hTexRef: CUtexref, fm: CUfilter_mode) -> CUresult;
}
extern "C" {
    /// \brief Sets the mipmap filtering mode for a texture reference
    ///
    /// Specifies the mipmap filtering mode \p fm to be used when reading memory through
    /// the texture reference \p hTexRef. ::CUfilter_mode_enum is defined as:
    ///
    /// \code
    ///typedef enum CUfilter_mode_enum {
    ///CU_TR_FILTER_MODE_POINT = 0,
    ///CU_TR_FILTER_MODE_LINEAR = 1
    ///} CUfilter_mode;
    /// \endcode
    ///
    /// Note that this call has no effect if \p hTexRef is not bound to a mipmapped array.
    ///
    /// \param hTexRef - Texture reference
    /// \param fm      - Filtering mode to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetMipmapFilterMode(hTexRef: CUtexref, fm: CUfilter_mode) -> CUresult;
}
extern "C" {
    /// \brief Sets the mipmap level bias for a texture reference
    ///
    /// Specifies the mipmap level bias \p bias to be added to the specified mipmap level when
    /// reading memory through the texture reference \p hTexRef.
    ///
    /// Note that this call has no effect if \p hTexRef is not bound to a mipmapped array.
    ///
    /// \param hTexRef - Texture reference
    /// \param bias    - Mipmap level bias
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetMipmapLevelBias(hTexRef: CUtexref, bias: f32) -> CUresult;
}
extern "C" {
    /// \brief Sets the mipmap min/max mipmap level clamps for a texture reference
    ///
    /// Specifies the min/max mipmap level clamps, \p minMipmapLevelClamp and \p maxMipmapLevelClamp
    /// respectively, to be used when reading memory through the texture reference
    /// \p hTexRef.
    ///
    /// Note that this call has no effect if \p hTexRef is not bound to a mipmapped array.
    ///
    /// \param hTexRef        - Texture reference
    /// \param minMipmapLevelClamp - Mipmap min level clamp
    /// \param maxMipmapLevelClamp - Mipmap max level clamp
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetMipmapLevelClamp(
        hTexRef: CUtexref,
        minMipmapLevelClamp: f32,
        maxMipmapLevelClamp: f32,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the maximum anisotropy for a texture reference
    ///
    /// Specifies the maximum anisotropy \p maxAniso to be used when reading memory through
    /// the texture reference \p hTexRef.
    ///
    /// Note that this call has no effect if \p hTexRef is bound to linear memory.
    ///
    /// \param hTexRef  - Texture reference
    /// \param maxAniso - Maximum anisotropy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTextureToArray,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetMaxAnisotropy(
        hTexRef: CUtexref,
        maxAniso: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Sets the border color for a texture reference
    ///
    /// Specifies the value of the RGBA color via the \p pBorderColor to the texture reference
    /// \p hTexRef. The color value supports only float type and holds color components in
    /// the following sequence:
    /// pBorderColor[0] holds 'R' component
    /// pBorderColor[1] holds 'G' component
    /// pBorderColor[2] holds 'B' component
    /// pBorderColor[3] holds 'A' component
    ///
    /// Note that the color values can be set only when the Address mode is set to
    /// CU_TR_ADDRESS_MODE_BORDER using ::cuTexRefSetAddressMode.
    /// Applications using integer border color values have to "reinterpret_cast" their values to float.
    ///
    /// \param hTexRef       - Texture reference
    /// \param pBorderColor  - RGBA color
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddressMode,
    /// ::cuTexRefGetAddressMode, ::cuTexRefGetBorderColor,
    /// ::cudaBindTexture,
    /// ::cudaBindTexture2D,
    /// ::cudaBindTextureToArray,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetBorderColor(hTexRef: CUtexref, pBorderColor: *mut f32) -> CUresult;
}
extern "C" {
    /// \brief Sets the flags for a texture reference
    ///
    /// Specifies optional flags via \p Flags to specify the behavior of data
    /// returned through the texture reference \p hTexRef. The valid flags are:
    ///
    /// - ::CU_TRSF_READ_AS_INTEGER, which suppresses the default behavior of
    ///   having the texture promote integer data to floating point data in the
    ///   range [0, 1]. Note that texture with 32-bit integer format
    ///   would not be promoted, regardless of whether or not this
    ///   flag is specified;
    /// - ::CU_TRSF_NORMALIZED_COORDINATES, which suppresses the
    ///   default behavior of having the texture coordinates range
    ///   from [0, Dim) where Dim is the width or height of the CUDA
    ///   array. Instead, the texture coordinates [0, 1.0) reference
    ///   the entire breadth of the array dimension;
    ///
    /// \param hTexRef - Texture reference
    /// \param Flags   - Optional flags to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat,
    /// ::cudaBindTexture,
    /// ::cudaBindTexture2D,
    /// ::cudaBindTextureToArray,
    /// ::cudaBindTextureToMipmappedArray
    pub fn cuTexRefSetFlags(hTexRef: CUtexref, Flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    pub fn cuTexRefGetAddress_v2(pdptr: *mut CUdeviceptr, hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Gets the array bound to a texture reference
    ///
    /// Returns in \p *phArray the CUDA array bound to the texture reference
    /// \p hTexRef, or returns ::CUDA_ERROR_INVALID_VALUE if the texture reference
    /// is not bound to any CUDA array.
    ///
    /// \param phArray - Returned array
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetArray(phArray: *mut CUarray, hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Gets the mipmapped array bound to a texture reference
    ///
    /// Returns in \p *phMipmappedArray the CUDA mipmapped array bound to the texture
    /// reference \p hTexRef, or returns ::CUDA_ERROR_INVALID_VALUE if the texture reference
    /// is not bound to any CUDA mipmapped array.
    ///
    /// \param phMipmappedArray - Returned mipmapped array
    /// \param hTexRef          - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetMipmappedArray(
        phMipmappedArray: *mut CUmipmappedArray,
        hTexRef: CUtexref,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets the addressing mode used by a texture reference
    ///
    /// Returns in \p *pam the addressing mode corresponding to the
    /// dimension \p dim of the texture reference \p hTexRef. Currently, the only
    /// valid value for \p dim are 0 and 1.
    ///
    /// \param pam     - Returned addressing mode
    /// \param hTexRef - Texture reference
    /// \param dim     - Dimension
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetAddressMode(
        pam: *mut CUaddress_mode,
        hTexRef: CUtexref,
        dim: ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets the filter-mode used by a texture reference
    ///
    /// Returns in \p *pfm the filtering mode of the texture reference
    /// \p hTexRef.
    ///
    /// \param pfm     - Returned filtering mode
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetFilterMode(pfm: *mut CUfilter_mode, hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Gets the format used by a texture reference
    ///
    /// Returns in \p *pFormat and \p *pNumChannels the format and number
    /// of components of the CUDA array bound to the texture reference \p hTexRef.
    /// If \p pFormat or \p pNumChannels is NULL, it will be ignored.
    ///
    /// \param pFormat      - Returned format
    /// \param pNumChannels - Returned number of components
    /// \param hTexRef      - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags
    pub fn cuTexRefGetFormat(
        pFormat: *mut CUarray_format,
        pNumChannels: *mut ::std::os::raw::c_int,
        hTexRef: CUtexref,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets the mipmap filtering mode for a texture reference
    ///
    /// Returns the mipmap filtering mode in \p pfm that's used when reading memory through
    /// the texture reference \p hTexRef.
    ///
    /// \param pfm     - Returned mipmap filtering mode
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetMipmapFilterMode(pfm: *mut CUfilter_mode, hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Gets the mipmap level bias for a texture reference
    ///
    /// Returns the mipmap level bias in \p pBias that's added to the specified mipmap
    /// level when reading memory through the texture reference \p hTexRef.
    ///
    /// \param pbias   - Returned mipmap level bias
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetMipmapLevelBias(pbias: *mut f32, hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Gets the min/max mipmap level clamps for a texture reference
    ///
    /// Returns the min/max mipmap level clamps in \p pminMipmapLevelClamp and \p pmaxMipmapLevelClamp
    /// that's used when reading memory through the texture reference \p hTexRef.
    ///
    /// \param pminMipmapLevelClamp - Returned mipmap min level clamp
    /// \param pmaxMipmapLevelClamp - Returned mipmap max level clamp
    /// \param hTexRef              - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetMipmapLevelClamp(
        pminMipmapLevelClamp: *mut f32,
        pmaxMipmapLevelClamp: *mut f32,
        hTexRef: CUtexref,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets the maximum anisotropy for a texture reference
    ///
    /// Returns the maximum anisotropy in \p pmaxAniso that's used when reading memory through
    /// the texture reference \p hTexRef.
    ///
    /// \param pmaxAniso - Returned maximum anisotropy
    /// \param hTexRef   - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    pub fn cuTexRefGetMaxAnisotropy(
        pmaxAniso: *mut ::std::os::raw::c_int,
        hTexRef: CUtexref,
    ) -> CUresult;
}
extern "C" {
    /// \brief Gets the border color used by a texture reference
    ///
    /// Returns in \p pBorderColor, values of the RGBA color used by
    /// the texture reference \p hTexRef.
    /// The color value is of type float and holds color components in
    /// the following sequence:
    /// pBorderColor[0] holds 'R' component
    /// pBorderColor[1] holds 'G' component
    /// pBorderColor[2] holds 'B' component
    /// pBorderColor[3] holds 'A' component
    ///
    /// \param hTexRef  - Texture reference
    /// \param pBorderColor   - Returned Type and Value of RGBA color
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddressMode,
    /// ::cuTexRefSetAddressMode, ::cuTexRefSetBorderColor
    pub fn cuTexRefGetBorderColor(pBorderColor: *mut f32, hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Gets the flags used by a texture reference
    ///
    /// Returns in \p *pFlags the flags of the texture reference \p hTexRef.
    ///
    /// \param pFlags  - Returned flags
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFormat
    pub fn cuTexRefGetFlags(pFlags: *mut ::std::os::raw::c_uint, hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Creates a texture reference
    ///
    /// \deprecated
    ///
    /// Creates a texture reference and returns its handle in \p *pTexRef. Once
    /// created, the application must call ::cuTexRefSetArray() or
    /// ::cuTexRefSetAddress() to associate the reference with allocated memory.
    /// Other texture reference functions are used to specify the format and
    /// interpretation (addressing, filtering, etc.) to be used when the memory is
    /// read through this texture reference.
    ///
    /// \param pTexRef - Returned texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefDestroy
    pub fn cuTexRefCreate(pTexRef: *mut CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Destroys a texture reference
    ///
    /// \deprecated
    ///
    /// Destroys the texture reference specified by \p hTexRef.
    ///
    /// \param hTexRef - Texture reference to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefCreate
    pub fn cuTexRefDestroy(hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Sets the CUDA array for a surface reference.
    ///
    /// Sets the CUDA array \p hArray to be read and written by the surface reference
    /// \p hSurfRef.  Any previous CUDA array state associated with the surface
    /// reference is superseded by this function.  \p Flags must be set to 0.
    /// The ::CUDA_ARRAY3D_SURFACE_LDST flag must have been set for the CUDA array.
    /// Any CUDA array previously bound to \p hSurfRef is unbound.
    ///
    /// \param hSurfRef - Surface reference handle
    /// \param hArray - CUDA array handle
    /// \param Flags - set to 0
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuModuleGetSurfRef,
    /// ::cuSurfRefGetArray,
    /// ::cudaBindSurfaceToArray
    pub fn cuSurfRefSetArray(
        hSurfRef: CUsurfref,
        hArray: CUarray,
        Flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Passes back the CUDA array bound to a surface reference.
    ///
    /// Returns in \p *phArray the CUDA array bound to the surface reference
    /// \p hSurfRef, or returns ::CUDA_ERROR_INVALID_VALUE if the surface reference
    /// is not bound to any CUDA array.
    ///
    /// \param phArray - Surface reference handle
    /// \param hSurfRef - Surface reference handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuModuleGetSurfRef, ::cuSurfRefSetArray
    pub fn cuSurfRefGetArray(phArray: *mut CUarray, hSurfRef: CUsurfref) -> CUresult;
}
extern "C" {
    /// \brief Creates a texture object
    ///
    /// Creates a texture object and returns it in \p pTexObject. \p pResDesc describes
    /// the data to texture from. \p pTexDesc describes how the data should be sampled.
    /// \p pResViewDesc is an optional argument that specifies an alternate format for
    /// the data described by \p pResDesc, and also describes the subresource region
    /// to restrict access to when texturing. \p pResViewDesc can only be specified if
    /// the type of resource is a CUDA array or a CUDA mipmapped array.
    ///
    /// Texture objects are only supported on devices of compute capability 3.0 or higher.
    /// Additionally, a texture object is an opaque value, and, as such, should only be
    /// accessed through CUDA API calls.
    ///
    /// The ::CUDA_RESOURCE_DESC structure is defined as:
    /// \code
    ///typedef struct CUDA_RESOURCE_DESC_st
    ///{
    ///CUresourcetype resType;
    ///
    ///union {
    ///struct {
    ///CUarray hArray;
    ///} array;
    ///struct {
    ///CUmipmappedArray hMipmappedArray;
    ///} mipmap;
    ///struct {
    ///CUdeviceptr devPtr;
    ///CUarray_format format;
    ///unsigned int numChannels;
    ///size_t sizeInBytes;
    ///} linear;
    ///struct {
    ///CUdeviceptr devPtr;
    ///CUarray_format format;
    ///unsigned int numChannels;
    ///size_t width;
    ///size_t height;
    ///size_t pitchInBytes;
    ///} pitch2D;
    ///} res;
    ///
    ///unsigned int flags;
    ///} CUDA_RESOURCE_DESC;
    ///
    /// \endcode
    /// where:
    /// - ::CUDA_RESOURCE_DESC::resType specifies the type of resource to texture from.
    /// CUresourceType is defined as:
    /// \code
    ///typedef enum CUresourcetype_enum {
    ///CU_RESOURCE_TYPE_ARRAY           = 0x00,
    ///CU_RESOURCE_TYPE_MIPMAPPED_ARRAY = 0x01,
    ///CU_RESOURCE_TYPE_LINEAR          = 0x02,
    ///CU_RESOURCE_TYPE_PITCH2D         = 0x03
    ///} CUresourcetype;
    /// \endcode
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_ARRAY, ::CUDA_RESOURCE_DESC::res::array::hArray
    /// must be set to a valid CUDA array handle.
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_MIPMAPPED_ARRAY, ::CUDA_RESOURCE_DESC::res::mipmap::hMipmappedArray
    /// must be set to a valid CUDA mipmapped array handle.
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_LINEAR, ::CUDA_RESOURCE_DESC::res::linear::devPtr
    /// must be set to a valid device pointer, that is aligned to ::CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT.
    /// ::CUDA_RESOURCE_DESC::res::linear::format and ::CUDA_RESOURCE_DESC::res::linear::numChannels
    /// describe the format of each component and the number of components per array element. ::CUDA_RESOURCE_DESC::res::linear::sizeInBytes
    /// specifies the size of the array in bytes. The total number of elements in the linear address range cannot exceed
    /// ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH. The number of elements is computed as (sizeInBytes / (sizeof(format) * numChannels)).
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_PITCH2D, ::CUDA_RESOURCE_DESC::res::pitch2D::devPtr
    /// must be set to a valid device pointer, that is aligned to ::CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT.
    /// ::CUDA_RESOURCE_DESC::res::pitch2D::format and ::CUDA_RESOURCE_DESC::res::pitch2D::numChannels
    /// describe the format of each component and the number of components per array element. ::CUDA_RESOURCE_DESC::res::pitch2D::width
    /// and ::CUDA_RESOURCE_DESC::res::pitch2D::height specify the width and height of the array in elements, and cannot exceed
    /// ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH and ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT respectively.
    /// ::CUDA_RESOURCE_DESC::res::pitch2D::pitchInBytes specifies the pitch between two rows in bytes and has to be aligned to
    /// ::CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT. Pitch cannot exceed ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH.
    ///
    /// - ::flags must be set to zero.
    ///
    ///
    /// The ::CUDA_TEXTURE_DESC struct is defined as
    /// \code
    ///typedef struct CUDA_TEXTURE_DESC_st {
    ///CUaddress_mode addressMode[3];
    ///CUfilter_mode filterMode;
    ///unsigned int flags;
    ///unsigned int maxAnisotropy;
    ///CUfilter_mode mipmapFilterMode;
    ///float mipmapLevelBias;
    ///float minMipmapLevelClamp;
    ///float maxMipmapLevelClamp;
    ///} CUDA_TEXTURE_DESC;
    /// \endcode
    /// where
    /// - ::CUDA_TEXTURE_DESC::addressMode specifies the addressing mode for each dimension of the texture data. ::CUaddress_mode is defined as:
    ///   \code
    ///typedef enum CUaddress_mode_enum {
    ///CU_TR_ADDRESS_MODE_WRAP = 0,
    ///CU_TR_ADDRESS_MODE_CLAMP = 1,
    ///CU_TR_ADDRESS_MODE_MIRROR = 2,
    ///CU_TR_ADDRESS_MODE_BORDER = 3
    ///} CUaddress_mode;
    ///   \endcode
    ///   This is ignored if ::CUDA_RESOURCE_DESC::resType is ::CU_RESOURCE_TYPE_LINEAR. Also, if the flag, ::CU_TRSF_NORMALIZED_COORDINATES
    ///   is not set, the only supported address mode is ::CU_TR_ADDRESS_MODE_CLAMP.
    ///
    /// - ::CUDA_TEXTURE_DESC::filterMode specifies the filtering mode to be used when fetching from the texture. CUfilter_mode is defined as:
    ///   \code
    ///typedef enum CUfilter_mode_enum {
    ///CU_TR_FILTER_MODE_POINT = 0,
    ///CU_TR_FILTER_MODE_LINEAR = 1
    ///} CUfilter_mode;
    ///   \endcode
    ///   This is ignored if ::CUDA_RESOURCE_DESC::resType is ::CU_RESOURCE_TYPE_LINEAR.
    ///
    /// - ::CUDA_TEXTURE_DESC::flags can be any combination of the following:
    ///   - ::CU_TRSF_READ_AS_INTEGER, which suppresses the default behavior of having the texture promote integer data to floating point data in the
    ///     range [0, 1]. Note that texture with 32-bit integer format would not be promoted, regardless of whether or not this flag is specified.
    ///   - ::CU_TRSF_NORMALIZED_COORDINATES, which suppresses the default behavior of having the texture coordinates range from [0, Dim) where Dim is
    ///     the width or height of the CUDA array. Instead, the texture coordinates [0, 1.0) reference the entire breadth of the array dimension; Note
    ///     that for CUDA mipmapped arrays, this flag has to be set.
    ///
    /// - ::CUDA_TEXTURE_DESC::maxAnisotropy specifies the maximum anisotropy ratio to be used when doing anisotropic filtering. This value will be
    ///   clamped to the range [1,16].
    ///
    /// - ::CUDA_TEXTURE_DESC::mipmapFilterMode specifies the filter mode when the calculated mipmap level lies between two defined mipmap levels.
    ///
    /// - ::CUDA_TEXTURE_DESC::mipmapLevelBias specifies the offset to be applied to the calculated mipmap level.
    ///
    /// - ::CUDA_TEXTURE_DESC::minMipmapLevelClamp specifies the lower end of the mipmap level range to clamp access to.
    ///
    /// - ::CUDA_TEXTURE_DESC::maxMipmapLevelClamp specifies the upper end of the mipmap level range to clamp access to.
    ///
    ///
    /// The ::CUDA_RESOURCE_VIEW_DESC struct is defined as
    /// \code
    ///typedef struct CUDA_RESOURCE_VIEW_DESC_st
    ///{
    ///CUresourceViewFormat format;
    ///size_t width;
    ///size_t height;
    ///size_t depth;
    ///unsigned int firstMipmapLevel;
    ///unsigned int lastMipmapLevel;
    ///unsigned int firstLayer;
    ///unsigned int lastLayer;
    ///} CUDA_RESOURCE_VIEW_DESC;
    /// \endcode
    /// where:
    /// - ::CUDA_RESOURCE_VIEW_DESC::format specifies how the data contained in the CUDA array or CUDA mipmapped array should
    ///   be interpreted. Note that this can incur a change in size of the texture data. If the resource view format is a block
    ///   compressed format, then the underlying CUDA array or CUDA mipmapped array has to have a base of format ::CU_AD_FORMAT_UNSIGNED_INT32.
    ///   with 2 or 4 channels, depending on the block compressed format. For ex., BC1 and BC4 require the underlying CUDA array to have
    ///   a format of ::CU_AD_FORMAT_UNSIGNED_INT32 with 2 channels. The other BC formats require the underlying resource to have the same base
    ///   format but with 4 channels.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::width specifies the new width of the texture data. If the resource view format is a block
    ///   compressed format, this value has to be 4 times the original width of the resource. For non block compressed formats,
    ///   this value has to be equal to that of the original resource.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::height specifies the new height of the texture data. If the resource view format is a block
    ///   compressed format, this value has to be 4 times the original height of the resource. For non block compressed formats,
    ///   this value has to be equal to that of the original resource.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::depth specifies the new depth of the texture data. This value has to be equal to that of the
    ///   original resource.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::firstMipmapLevel specifies the most detailed mipmap level. This will be the new mipmap level zero.
    ///   For non-mipmapped resources, this value has to be zero.::CUDA_TEXTURE_DESC::minMipmapLevelClamp and ::CUDA_TEXTURE_DESC::maxMipmapLevelClamp
    ///   will be relative to this value. For ex., if the firstMipmapLevel is set to 2, and a minMipmapLevelClamp of 1.2 is specified,
    ///   then the actual minimum mipmap level clamp will be 3.2.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::lastMipmapLevel specifies the least detailed mipmap level. For non-mipmapped resources, this value
    ///   has to be zero.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::firstLayer specifies the first layer index for layered textures. This will be the new layer zero.
    ///   For non-layered resources, this value has to be zero.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::lastLayer specifies the last layer index for layered textures. For non-layered resources,
    ///   this value has to be zero.
    ///
    ///
    /// \param pTexObject   - Texture object to create
    /// \param pResDesc     - Resource descriptor
    /// \param pTexDesc     - Texture descriptor
    /// \param pResViewDesc - Resource view descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuTexObjectDestroy,
    /// ::cudaCreateTextureObject
    pub fn cuTexObjectCreate(
        pTexObject: *mut CUtexObject,
        pResDesc: *const CUDA_RESOURCE_DESC,
        pTexDesc: *const CUDA_TEXTURE_DESC,
        pResViewDesc: *const CUDA_RESOURCE_VIEW_DESC,
    ) -> CUresult;
}
extern "C" {
    /// \brief Destroys a texture object
    ///
    /// Destroys the texture object specified by \p texObject.
    ///
    /// \param texObject - Texture object to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuTexObjectCreate,
    /// ::cudaDestroyTextureObject
    pub fn cuTexObjectDestroy(texObject: CUtexObject) -> CUresult;
}
extern "C" {
    /// \brief Returns a texture object's resource descriptor
    ///
    /// Returns the resource descriptor for the texture object specified by \p texObject.
    ///
    /// \param pResDesc  - Resource descriptor
    /// \param texObject - Texture object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuTexObjectCreate,
    /// ::cudaGetTextureObjectResourceDesc,
    pub fn cuTexObjectGetResourceDesc(
        pResDesc: *mut CUDA_RESOURCE_DESC,
        texObject: CUtexObject,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a texture object's texture descriptor
    ///
    /// Returns the texture descriptor for the texture object specified by \p texObject.
    ///
    /// \param pTexDesc  - Texture descriptor
    /// \param texObject - Texture object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuTexObjectCreate,
    /// ::cudaGetTextureObjectTextureDesc
    pub fn cuTexObjectGetTextureDesc(
        pTexDesc: *mut CUDA_TEXTURE_DESC,
        texObject: CUtexObject,
    ) -> CUresult;
}
extern "C" {
    /// \brief Returns a texture object's resource view descriptor
    ///
    /// Returns the resource view descriptor for the texture object specified by \p texObject.
    /// If no resource view was set for \p texObject, the ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    /// \param pResViewDesc - Resource view descriptor
    /// \param texObject    - Texture object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuTexObjectCreate,
    /// ::cudaGetTextureObjectResourceViewDesc
    pub fn cuTexObjectGetResourceViewDesc(
        pResViewDesc: *mut CUDA_RESOURCE_VIEW_DESC,
        texObject: CUtexObject,
    ) -> CUresult;
}
extern "C" {
    /// \brief Creates a surface object
    ///
    /// Creates a surface object and returns it in \p pSurfObject. \p pResDesc describes
    /// the data to perform surface load/stores on. ::CUDA_RESOURCE_DESC::resType must be
    /// ::CU_RESOURCE_TYPE_ARRAY and  ::CUDA_RESOURCE_DESC::res::array::hArray
    /// must be set to a valid CUDA array handle. ::CUDA_RESOURCE_DESC::flags must be set to zero.
    ///
    /// Surface objects are only supported on devices of compute capability 3.0 or higher.
    /// Additionally, a surface object is an opaque value, and, as such, should only be
    /// accessed through CUDA API calls.
    ///
    /// \param pSurfObject - Surface object to create
    /// \param pResDesc    - Resource descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuSurfObjectDestroy,
    /// ::cudaCreateSurfaceObject
    pub fn cuSurfObjectCreate(
        pSurfObject: *mut CUsurfObject,
        pResDesc: *const CUDA_RESOURCE_DESC,
    ) -> CUresult;
}
extern "C" {
    /// \brief Destroys a surface object
    ///
    /// Destroys the surface object specified by \p surfObject.
    ///
    /// \param surfObject - Surface object to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuSurfObjectCreate,
    /// ::cudaDestroySurfaceObject
    pub fn cuSurfObjectDestroy(surfObject: CUsurfObject) -> CUresult;
}
extern "C" {
    /// \brief Returns a surface object's resource descriptor
    ///
    /// Returns the resource descriptor for the surface object specified by \p surfObject.
    ///
    /// \param pResDesc   - Resource descriptor
    /// \param surfObject - Surface object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa
    /// ::cuSurfObjectCreate,
    /// ::cudaGetSurfaceObjectResourceDesc
    pub fn cuSurfObjectGetResourceDesc(
        pResDesc: *mut CUDA_RESOURCE_DESC,
        surfObject: CUsurfObject,
    ) -> CUresult;
}
extern "C" {
    /// \brief Queries if a device may directly access a peer device's memory.
    ///
    /// Returns in \p *canAccessPeer a value of 1 if contexts on \p dev are capable of
    /// directly accessing memory from contexts on \p peerDev and 0 otherwise.
    /// If direct access of \p peerDev from \p dev is possible, then access may be
    /// enabled on two specific contexts by calling ::cuCtxEnablePeerAccess().
    ///
    /// \param canAccessPeer - Returned access capability
    /// \param dev           - Device from which allocations on \p peerDev are to
    ///                        be directly accessed.
    /// \param peerDev       - Device on which the allocations to be directly accessed
    ///                        by \p dev reside.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuCtxEnablePeerAccess,
    /// ::cuCtxDisablePeerAccess,
    /// ::cudaDeviceCanAccessPeer
    pub fn cuDeviceCanAccessPeer(
        canAccessPeer: *mut ::std::os::raw::c_int,
        dev: CUdevice,
        peerDev: CUdevice,
    ) -> CUresult;
}
extern "C" {
    /// \brief Enables direct access to memory allocations in a peer context.
    ///
    /// If both the current context and \p peerContext are on devices which support unified
    /// addressing (as may be queried using ::CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING) and same
    /// major compute capability, then on success all allocations from \p peerContext will
    /// immediately be accessible by the current context.  See \ref CUDA_UNIFIED for additional
    /// details.
    ///
    /// Note that access granted by this call is unidirectional and that in order to access
    /// memory from the current context in \p peerContext, a separate symmetric call
    /// to ::cuCtxEnablePeerAccess() is required.
    ///
    /// There is a system-wide maximum of eight peer connections per device.
    ///
    /// Returns ::CUDA_ERROR_PEER_ACCESS_UNSUPPORTED if ::cuDeviceCanAccessPeer() indicates
    /// that the ::CUdevice of the current context cannot directly access memory
    /// from the ::CUdevice of \p peerContext.
    ///
    /// Returns ::CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED if direct access of
    /// \p peerContext from the current context has already been enabled.
    ///
    /// Returns ::CUDA_ERROR_TOO_MANY_PEERS if direct peer access is not possible
    /// because hardware resources required for peer access have been exhausted.
    ///
    /// Returns ::CUDA_ERROR_INVALID_CONTEXT if there is no current context, \p peerContext
    /// is not a valid context, or if the current context is \p peerContext.
    ///
    /// Returns ::CUDA_ERROR_INVALID_VALUE if \p Flags is not 0.
    ///
    /// \param peerContext - Peer context to enable direct access to from the current context
    /// \param Flags       - Reserved for future use and must be set to 0
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED,
    /// ::CUDA_ERROR_TOO_MANY_PEERS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_PEER_ACCESS_UNSUPPORTED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceCanAccessPeer,
    /// ::cuCtxDisablePeerAccess,
    /// ::cudaDeviceEnablePeerAccess
    pub fn cuCtxEnablePeerAccess(peerContext: CUcontext, Flags: ::std::os::raw::c_uint)
        -> CUresult;
}
extern "C" {
    /// \brief Disables direct access to memory allocations in a peer context and
    /// unregisters any registered allocations.
    ///
    ///Returns ::CUDA_ERROR_PEER_ACCESS_NOT_ENABLED if direct peer access has
    /// not yet been enabled from \p peerContext to the current context.
    ///
    /// Returns ::CUDA_ERROR_INVALID_CONTEXT if there is no current context, or if
    /// \p peerContext is not a valid context.
    ///
    /// \param peerContext - Peer context to disable direct access to
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_PEER_ACCESS_NOT_ENABLED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceCanAccessPeer,
    /// ::cuCtxEnablePeerAccess,
    /// ::cudaDeviceDisablePeerAccess
    pub fn cuCtxDisablePeerAccess(peerContext: CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Queries attributes of the link between two devices.
    ///
    /// Returns in \p *value the value of the requested attribute \p attrib of the
    /// link between \p srcDevice and \p dstDevice. The supported attributes are:
    /// - ::CU_DEVICE_P2P_ATTRIBUTE_PERFORMANCE_RANK: A relative value indicating the
    ///   performance of the link between two devices.
    /// - ::CU_DEVICE_P2P_ATTRIBUTE_ACCESS_SUPPORTED P2P: 1 if P2P Access is enable.
    /// - ::CU_DEVICE_P2P_ATTRIBUTE_NATIVE_ATOMIC_SUPPORTED: 1 if Atomic operations over
    ///   the link are supported.
    /// - ::CU_DEVICE_P2P_ATTRIBUTE_CUDA_ARRAY_ACCESS_SUPPORTED: 1 if cudaArray can
    ///   be accessed over the link.
    ///
    /// Returns ::CUDA_ERROR_INVALID_DEVICE if \p srcDevice or \p dstDevice are not valid
    /// or if they represent the same device.
    ///
    /// Returns ::CUDA_ERROR_INVALID_VALUE if \p attrib is not valid or if \p value is
    /// a null pointer.
    ///
    /// \param value         - Returned value of the requested attribute
    /// \param attrib        - The requested attribute of the link between \p srcDevice and \p dstDevice.
    /// \param srcDevice     - The source device of the target link.
    /// \param dstDevice     - The destination device of the target link.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuCtxEnablePeerAccess,
    /// ::cuCtxDisablePeerAccess,
    /// ::cuDeviceCanAccessPeer,
    /// ::cudaDeviceGetP2PAttribute
    pub fn cuDeviceGetP2PAttribute(
        value: *mut ::std::os::raw::c_int,
        attrib: CUdevice_P2PAttribute,
        srcDevice: CUdevice,
        dstDevice: CUdevice,
    ) -> CUresult;
}
extern "C" {
    /// \brief Unregisters a graphics resource for access by CUDA
    ///
    /// Unregisters the graphics resource \p resource so it is not accessible by
    /// CUDA unless registered again.
    ///
    /// If \p resource is invalid then ::CUDA_ERROR_INVALID_HANDLE is
    /// returned.
    ///
    /// \param resource - Resource to unregister
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsD3D9RegisterResource,
    /// ::cuGraphicsD3D10RegisterResource,
    /// ::cuGraphicsD3D11RegisterResource,
    /// ::cuGraphicsGLRegisterBuffer,
    /// ::cuGraphicsGLRegisterImage,
    /// ::cudaGraphicsUnregisterResource
    pub fn cuGraphicsUnregisterResource(resource: CUgraphicsResource) -> CUresult;
}
extern "C" {
    /// \brief Get an array through which to access a subresource of a mapped graphics resource.
    ///
    /// Returns in \p *pArray an array through which the subresource of the mapped
    /// graphics resource \p resource which corresponds to array index \p arrayIndex
    /// and mipmap level \p mipLevel may be accessed.  The value set in \p *pArray may
    /// change every time that \p resource is mapped.
    ///
    /// If \p resource is not a texture then it cannot be accessed via an array and
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY is returned.
    /// If \p arrayIndex is not a valid array index for \p resource then
    /// ::CUDA_ERROR_INVALID_VALUE is returned.
    /// If \p mipLevel is not a valid mipmap level for \p resource then
    /// ::CUDA_ERROR_INVALID_VALUE is returned.
    /// If \p resource is not mapped then ::CUDA_ERROR_NOT_MAPPED is returned.
    ///
    /// \param pArray      - Returned array through which a subresource of \p resource may be accessed
    /// \param resource    - Mapped resource to access
    /// \param arrayIndex  - Array index for array textures or cubemap face
    ///                      index as defined by ::CUarray_cubemap_face for
    ///                      cubemap textures for the subresource to access
    /// \param mipLevel    - Mipmap level for the subresource to access
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_MAPPED,
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsResourceGetMappedPointer,
    /// ::cudaGraphicsSubResourceGetMappedArray
    pub fn cuGraphicsSubResourceGetMappedArray(
        pArray: *mut CUarray,
        resource: CUgraphicsResource,
        arrayIndex: ::std::os::raw::c_uint,
        mipLevel: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Get a mipmapped array through which to access a mapped graphics resource.
    ///
    /// Returns in \p *pMipmappedArray a mipmapped array through which the mapped graphics
    /// resource \p resource. The value set in \p *pMipmappedArray may change every time
    /// that \p resource is mapped.
    ///
    /// If \p resource is not a texture then it cannot be accessed via a mipmapped array and
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY is returned.
    /// If \p resource is not mapped then ::CUDA_ERROR_NOT_MAPPED is returned.
    ///
    /// \param pMipmappedArray - Returned mipmapped array through which \p resource may be accessed
    /// \param resource        - Mapped resource to access
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_MAPPED,
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsResourceGetMappedPointer,
    /// ::cudaGraphicsResourceGetMappedMipmappedArray
    pub fn cuGraphicsResourceGetMappedMipmappedArray(
        pMipmappedArray: *mut CUmipmappedArray,
        resource: CUgraphicsResource,
    ) -> CUresult;
}
extern "C" {
    pub fn cuGraphicsResourceGetMappedPointer_v2(
        pDevPtr: *mut CUdeviceptr,
        pSize: *mut usize,
        resource: CUgraphicsResource,
    ) -> CUresult;
}
extern "C" {
    pub fn cuGraphicsResourceSetMapFlags_v2(
        resource: CUgraphicsResource,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    /// \brief Map graphics resources for access by CUDA
    ///
    /// Maps the \p count graphics resources in \p resources for access by CUDA.
    ///
    /// The resources in \p resources may be accessed by CUDA until they
    /// are unmapped. The graphics API from which \p resources were registered
    /// should not access any resources while they are mapped by CUDA. If an
    /// application does so, the results are undefined.
    ///
    /// This function provides the synchronization guarantee that any graphics calls
    /// issued before ::cuGraphicsMapResources() will complete before any subsequent CUDA
    /// work issued in \p stream begins.
    ///
    /// If \p resources includes any duplicate entries then ::CUDA_ERROR_INVALID_HANDLE is returned.
    /// If any of \p resources are presently mapped for access by CUDA then ::CUDA_ERROR_ALREADY_MAPPED is returned.
    ///
    /// \param count      - Number of resources to map
    /// \param resources  - Resources to map for CUDA usage
    /// \param hStream    - Stream with which to synchronize
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_ALREADY_MAPPED,
    /// ::CUDA_ERROR_UNKNOWN
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsResourceGetMappedPointer,
    /// ::cuGraphicsSubResourceGetMappedArray,
    /// ::cuGraphicsUnmapResources,
    /// ::cudaGraphicsMapResources
    pub fn cuGraphicsMapResources(
        count: ::std::os::raw::c_uint,
        resources: *mut CUgraphicsResource,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// \brief Unmap graphics resources.
    ///
    /// Unmaps the \p count graphics resources in \p resources.
    ///
    /// Once unmapped, the resources in \p resources may not be accessed by CUDA
    /// until they are mapped again.
    ///
    /// This function provides the synchronization guarantee that any CUDA work issued
    /// in \p stream before ::cuGraphicsUnmapResources() will complete before any
    /// subsequently issued graphics work begins.
    ///
    ///
    /// If \p resources includes any duplicate entries then ::CUDA_ERROR_INVALID_HANDLE is returned.
    /// If any of \p resources are not presently mapped for access by CUDA then ::CUDA_ERROR_NOT_MAPPED is returned.
    ///
    /// \param count      - Number of resources to unmap
    /// \param resources  - Resources to unmap
    /// \param hStream    - Stream with which to synchronize
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_MAPPED,
    /// ::CUDA_ERROR_UNKNOWN
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsMapResources,
    /// ::cudaGraphicsUnmapResources
    pub fn cuGraphicsUnmapResources(
        count: ::std::os::raw::c_uint,
        resources: *mut CUgraphicsResource,
        hStream: CUstream,
    ) -> CUresult;
}
extern "C" {
    /// @}
    pub fn cuGetExportTable(
        ppExportTable: *mut *const ::std::os::raw::c_void,
        pExportTableId: *const CUuuid,
    ) -> CUresult;
}
